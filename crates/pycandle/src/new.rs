use anyhow::{Context, Result};
use std::fs;
use std::path::Path;

pub fn run_new(name: String, model_arch: Option<String>) -> Result<()> {
    let project_path = Path::new(&name);
    if project_path.exists() {
        anyhow::bail!("Directory '{}' already exists", name);
    }

    println!("âœ¨ Creating new PyCandle project: {}", name);
    fs::create_dir(project_path).context("Failed to create project directory")?;

    // Create Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "{}"
version = "0.1.0"
edition = "2021"

[dependencies]
candle-core = {{ version = "0.8.0", features = ["cuda"] }}
candle-nn = "0.8.0"
candle-transformers = "0.8.0"
candle-flash-attn = {{ version = "0.8.0", optional = true }}
anyhow = "1.0"
clap = {{ version = "4.4", features = ["derive"] }}
hf-hub = "0.3.2"
tokenizers = "0.15"
serde = {{ version = "1.0", features = ["derive"] }}
serde_json = "1.0"
log = "0.4"
env_logger = "0.11"

[features]
default = []
flash-attn = ["dep:candle-flash-attn"]
"#,
        name
    );
    fs::write(project_path.join("Cargo.toml"), cargo_toml)?;

    // Create folder structure
    fs::create_dir_all(project_path.join("src"))?;
    fs::create_dir_all(project_path.join("py")).context("Failed to create py folder")?;

    // Create src/main.rs
    let main_rs = r#"use clap::Parser;
use anyhow::Result;
use candle_core::{Device, Tensor};

#[derive(Parser)]
#[command(version, about, long_about = None)]
struct Args {
    #[arg(long, default_value = "Hello PyCandle")]
    prompt: String,

    #[arg(long)]
    cpu: bool,
}

fn main() -> Result<()> {
    env_logger::init();
    let args = Args::parse();
    
    let device = if args.cpu {
        Device::Cpu
    } else {
        Device::new_cuda(0).unwrap_or(Device::Cpu)
    };

    println!("Running on device: {:?}", device);
    println!("Prompt: {}", args.prompt);

    // TODO: Instantiate model here
    // let weights = ...
    // let model = my_project::Model::new(weights)?;
    // let output = model.forward(...)?;

    Ok(())
}
"#;
    fs::write(project_path.join("src/main.rs"), main_rs)?;

    // Create src/lib.rs
    let architecture = model_arch.unwrap_or_else(|| "Model".to_string());
    let lib_rs = format!(
        r#"use candle_core::{{Result, Tensor, Device}};
use candle_nn::{{VarBuilder, Module, ModuleT}};

pub struct {} {{
    // TODO: Add layers
}}

impl {} {{
    pub fn new(vb: VarBuilder) -> Result<Self> {{
        Ok(Self {{ }})
    }}

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {{
        // TODO: Implement forward pass
        Ok(x.clone())
    }}
}}
"#,
        architecture, architecture
    );
    fs::write(project_path.join("src/lib.rs"), lib_rs)?;

    // Create README.md
    let readme = format!(
        r#"# {}

Generated by PyCandle.

## Setup
1. `pycandle init` to set up the Python environment.
2. `pycandle record --script py/model.py --name {}`
3. `pycandle codegen --manifest pycandle_trace/{}_manifest.json`

## Running
```bash
cargo run --release -- --prompt "Hello"
```
"#,
        name, name, name
    );
    fs::write(project_path.join("README.md"), readme)?;

    // Create Makefile
    let makefile = format!(
        r#"setup:
	pycandle init

record:
	pycandle record --script py/model.py --name {}

codegen:
	pycandle codegen --manifest pycandle_trace/{}_manifest.json

run:
	cargo run --release
"#,
        name, name
    );
    fs::write(project_path.join("Makefile"), makefile)?;

    // .gitignore
    let gitignore = r#"/target
/pycandle_trace
.pycandle/venv
.pycandle/tmp
"#;
    fs::write(project_path.join(".gitignore"), gitignore)?;

    println!("âœ… Project ready at ./{}", name);
    println!("ðŸ‘‰ To get started:");
    println!("   cd {}", name);
    println!("   pycandle init");

    Ok(())
}
