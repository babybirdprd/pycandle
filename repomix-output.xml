This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/workflows/parity-check.yml
.gitignore
.repomixignore
Cargo.toml
crates/pycandle-audio/Cargo.toml
crates/pycandle-audio/src/lib.rs
crates/pycandle-core/Cargo.toml
crates/pycandle-core/failures/debug_node_linear.py
crates/pycandle-core/src/checker.rs
crates/pycandle-core/src/codegen/gpt2.rs
crates/pycandle-core/src/codegen/mod.rs
crates/pycandle-core/src/gpt2.rs
crates/pycandle-core/src/layers.rs
crates/pycandle-core/src/lib.rs
crates/pycandle-core/src/samplers.rs
crates/pycandle-core/src/weights.rs
crates/pycandle-core/tests/dummy_test.rs
crates/pycandle-core/tests/quantization_drift.rs
crates/pycandle-core/verification_results.jsonl
crates/pycandle/Cargo.toml
crates/pycandle/src/dashboard.rs
crates/pycandle/src/init.rs
crates/pycandle/src/main.rs
crates/pycandle/src/report.rs
crates/pycandle/src/test_gen.rs
crates/pycandle/src/todos.rs
docs/meta_trace_guide.md
docs/PORTING_SOP.md
dummy_manifest.json
dx_simulation/Cargo.toml
dx_simulation/src/bin/list_keys.rs
dx_simulation/src/generated_s3gen_flow.rs
dx_simulation/src/generated_t3_meta.rs
dx_simulation/src/generated_t3_transformer.rs
dx_simulation/src/generated_voice_encoder.rs
dx_simulation/src/main.rs
dx_simulation/src/punc_norm.rs
dx_simulation/src/s3gen_flow.rs
dx_simulation/src/t3_transformer.rs
dx_simulation/src/voice_encoder.rs
gen_dummy_results.rs
generated_hints.rs
generated_symbolic.rs
py/.python-version
py/dag_model.py
py/generated_complex.rs
py/generated_residual.rs
py/hello.py
py/onnx_to_fx.py
py/pyproject.toml
py/spy.py
py/test_hints.py
py/test_model.py
py/weight_extractor.py
README.md
recorder.py
s3gen_keys.txt
specs/melspectrogram_parity.md
test_symbolic.py
test_trace_hints/hints_test_manifest.json
test_trace/symbolic_test_manifest.json
tests/parity.rs
tests/quantization_drift.rs
tests/simple_onnx_parity.rs
tts_turbo_temp.py
verification_results.jsonl
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="dx_simulation/Cargo.toml">
[package]
name = "dx_simulation"
version.workspace = true
edition.workspace = true
license.workspace = true

[dependencies]
candle-core = { workspace = true }
candle-nn = { workspace = true }
candle-transformers = { workspace = true }
pycandle-core = { path = "../crates/pycandle-core" }
pycandle-audio = { path = "../crates/pycandle-audio" }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
hf-hub = { workspace = true }
safetensors = { workspace = true }
tokenizers = { workspace = true }
hound = { workspace = true }
clap = { workspace = true }
regex = { workspace = true }
</file>

<file path="dx_simulation/src/bin/list_keys.rs">
use candle_core::{Device, Result};
use candle_core::safetensors::load;
use std::path::PathBuf;

fn main() -> Result<()> {
    let path = PathBuf::from("D:/huggingface/hub/models--ResembleAI--chatterbox-turbo/snapshots/749d1c1a46eb10492095d68fbcf55691ccf137cd/t3_turbo_v1.safetensors");
    let tensors = load(path, &Device::Cpu)?;
    
    let mut keys: Vec<_> = tensors.keys().collect();
    keys.sort();
    
    println!("Keys in t3_turbo_v1.safetensors:");
    for key in keys {
        let tensor = tensors.get(key).unwrap();
        println!("{}: {:?}", key, tensor.shape());
    }
    
    Ok(())
}
</file>

<file path="dx_simulation/src/generated_s3gen_flow.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct MyModel {
    pub decoder_estimator_down_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_down_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_down_blocks_0_0_block1_block_2: LayerNorm,
    pub decoder_estimator_down_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_down_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_down_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_down_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_down_blocks_0_0_block2_block_2: LayerNorm,
    pub decoder_estimator_down_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_down_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_down_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_down_blocks_0_0_mlp_1: Linear,
    pub decoder_estimator_down_blocks_0_0_res_conv: Conv1d,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_k: Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_q: Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_v: Linear,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_2: Linear,
    pub decoder_estimator_down_blocks_0_1_0_norm1: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_0_norm3: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_k: Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_q: Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_v: Linear,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_2: Linear,
    pub decoder_estimator_down_blocks_0_1_1_norm1: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_1_norm3: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_k: Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_q: Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_v: Linear,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_2: Linear,
    pub decoder_estimator_down_blocks_0_1_2_norm1: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_2_norm3: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_k: Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_q: Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_v: Linear,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_2: Linear,
    pub decoder_estimator_down_blocks_0_1_3_norm1: LayerNorm,
    pub decoder_estimator_down_blocks_0_1_3_norm3: LayerNorm,
    pub decoder_estimator_down_blocks_0_2: CausalConv1d,
    pub decoder_estimator_final_block_block_0: CausalConv1d,
    pub decoder_estimator_final_block_block_1: Transpose,
    pub decoder_estimator_final_block_block_2: LayerNorm,
    pub decoder_estimator_final_block_block_3: Transpose,
    pub decoder_estimator_final_block_block_4: Mish,
    pub decoder_estimator_final_proj: Conv1d,
    pub decoder_estimator_mid_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_0_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_0_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_0_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_0_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_0_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_0_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_1_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_1_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_1_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_1_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_1_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_1_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_1_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_1_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_1_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_1_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_10_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_10_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_10_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_10_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_10_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_10_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_10_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_10_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_10_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_10_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_11_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_11_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_11_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_11_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_11_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_11_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_11_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_11_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_11_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_11_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_2_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_2_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_2_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_2_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_2_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_2_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_2_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_2_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_2_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_2_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_3_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_3_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_3_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_3_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_3_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_3_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_3_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_3_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_3_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_3_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_4_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_4_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_4_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_4_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_4_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_4_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_4_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_4_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_4_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_4_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_5_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_5_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_5_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_5_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_5_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_5_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_5_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_5_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_5_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_5_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_6_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_6_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_6_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_6_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_6_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_6_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_6_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_6_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_6_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_6_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_7_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_7_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_7_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_7_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_7_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_7_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_7_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_7_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_7_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_7_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_8_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_8_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_8_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_8_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_8_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_8_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_8_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_8_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_8_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_8_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_3_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_9_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block1_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_9_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_9_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block2_block_2: LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_9_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_9_0_mlp_1: Linear,
    pub decoder_estimator_mid_blocks_9_0_res_conv: Conv1d,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_9_1_0_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_0_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_9_1_1_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_1_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_9_1_2_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_2_norm3: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_k: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_q: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_v: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_2: Linear,
    pub decoder_estimator_mid_blocks_9_1_3_norm1: LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_3_norm3: LayerNorm,
    pub decoder_estimator_time_embeddings: SinusoidalPosEmb,
    pub decoder_estimator_time_mlp_act: SiLU,
    pub decoder_estimator_time_mlp_linear_1: Linear,
    pub decoder_estimator_time_mlp_linear_2: Linear,
    pub decoder_estimator_up_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_up_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_up_blocks_0_0_block1_block_2: LayerNorm,
    pub decoder_estimator_up_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_up_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_up_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_up_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_up_blocks_0_0_block2_block_2: LayerNorm,
    pub decoder_estimator_up_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_up_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_up_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_up_blocks_0_0_mlp_1: Linear,
    pub decoder_estimator_up_blocks_0_0_res_conv: Conv1d,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_k: Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_out_0: Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_q: Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_v: Linear,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_0_proj: Linear,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_2: Linear,
    pub decoder_estimator_up_blocks_0_1_0_norm1: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_0_norm3: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_k: Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_out_0: Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_q: Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_v: Linear,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_0_proj: Linear,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_2: Linear,
    pub decoder_estimator_up_blocks_0_1_1_norm1: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_1_norm3: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_k: Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_out_0: Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_q: Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_v: Linear,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_0_proj: Linear,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_2: Linear,
    pub decoder_estimator_up_blocks_0_1_2_norm1: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_2_norm3: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_k: Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_out_0: Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_q: Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_v: Linear,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_0_proj: Linear,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_2: Linear,
    pub decoder_estimator_up_blocks_0_1_3_norm1: LayerNorm,
    pub decoder_estimator_up_blocks_0_1_3_norm3: LayerNorm,
    pub decoder_estimator_up_blocks_0_2: CausalConv1d,
    pub encoder_after_norm: LayerNorm,
    pub encoder_embed_out_0: Linear,
    pub encoder_embed_out_1: LayerNorm,
    pub encoder_embed_out_2: Dropout,
    pub encoder_embed_pos_enc_dropout: Dropout,
    pub encoder_embed_pos_enc_dropout_1: Dropout,
    pub encoder_encoders_0_dropout: Dropout,
    pub encoder_encoders_0_dropout_1: Dropout,
    pub encoder_encoders_0_feed_forward_activation: SiLU,
    pub encoder_encoders_0_feed_forward_activation_1: SiLU,
    pub encoder_encoders_0_feed_forward_activation_2: SiLU,
    pub encoder_encoders_0_feed_forward_activation_3: SiLU,
    pub encoder_encoders_0_feed_forward_activation_4: SiLU,
    pub encoder_encoders_0_feed_forward_activation_5: SiLU,
    pub encoder_encoders_0_feed_forward_activation_6: SiLU,
    pub encoder_encoders_0_feed_forward_activation_7: SiLU,
    pub encoder_encoders_0_feed_forward_activation_8: SiLU,
    pub encoder_encoders_0_feed_forward_activation_9: SiLU,
    pub encoder_encoders_0_feed_forward_dropout: Dropout,
    pub encoder_encoders_0_feed_forward_w_1: Linear,
    pub encoder_encoders_0_feed_forward_w_2: Linear,
    pub encoder_encoders_0_norm_ff: LayerNorm,
    pub encoder_encoders_0_norm_mha: LayerNorm,
    pub encoder_encoders_0_self_attn_dropout: Dropout,
    pub encoder_encoders_0_self_attn_linear_k: Linear,
    pub encoder_encoders_0_self_attn_linear_out: Linear,
    pub encoder_encoders_0_self_attn_linear_pos: Linear,
    pub encoder_encoders_0_self_attn_linear_q: Linear,
    pub encoder_encoders_0_self_attn_linear_v: Linear,
    pub encoder_encoders_1_dropout: Dropout,
    pub encoder_encoders_1_dropout_1: Dropout,
    pub encoder_encoders_1_feed_forward_dropout: Dropout,
    pub encoder_encoders_1_feed_forward_w_1: Linear,
    pub encoder_encoders_1_feed_forward_w_2: Linear,
    pub encoder_encoders_1_norm_ff: LayerNorm,
    pub encoder_encoders_1_norm_mha: LayerNorm,
    pub encoder_encoders_1_self_attn_dropout: Dropout,
    pub encoder_encoders_1_self_attn_linear_k: Linear,
    pub encoder_encoders_1_self_attn_linear_out: Linear,
    pub encoder_encoders_1_self_attn_linear_pos: Linear,
    pub encoder_encoders_1_self_attn_linear_q: Linear,
    pub encoder_encoders_1_self_attn_linear_v: Linear,
    pub encoder_encoders_2_dropout: Dropout,
    pub encoder_encoders_2_dropout_1: Dropout,
    pub encoder_encoders_2_feed_forward_dropout: Dropout,
    pub encoder_encoders_2_feed_forward_w_1: Linear,
    pub encoder_encoders_2_feed_forward_w_2: Linear,
    pub encoder_encoders_2_norm_ff: LayerNorm,
    pub encoder_encoders_2_norm_mha: LayerNorm,
    pub encoder_encoders_2_self_attn_dropout: Dropout,
    pub encoder_encoders_2_self_attn_linear_k: Linear,
    pub encoder_encoders_2_self_attn_linear_out: Linear,
    pub encoder_encoders_2_self_attn_linear_pos: Linear,
    pub encoder_encoders_2_self_attn_linear_q: Linear,
    pub encoder_encoders_2_self_attn_linear_v: Linear,
    pub encoder_encoders_3_dropout: Dropout,
    pub encoder_encoders_3_dropout_1: Dropout,
    pub encoder_encoders_3_feed_forward_dropout: Dropout,
    pub encoder_encoders_3_feed_forward_w_1: Linear,
    pub encoder_encoders_3_feed_forward_w_2: Linear,
    pub encoder_encoders_3_norm_ff: LayerNorm,
    pub encoder_encoders_3_norm_mha: LayerNorm,
    pub encoder_encoders_3_self_attn_dropout: Dropout,
    pub encoder_encoders_3_self_attn_linear_k: Linear,
    pub encoder_encoders_3_self_attn_linear_out: Linear,
    pub encoder_encoders_3_self_attn_linear_pos: Linear,
    pub encoder_encoders_3_self_attn_linear_q: Linear,
    pub encoder_encoders_3_self_attn_linear_v: Linear,
    pub encoder_encoders_4_dropout: Dropout,
    pub encoder_encoders_4_dropout_1: Dropout,
    pub encoder_encoders_4_feed_forward_dropout: Dropout,
    pub encoder_encoders_4_feed_forward_w_1: Linear,
    pub encoder_encoders_4_feed_forward_w_2: Linear,
    pub encoder_encoders_4_norm_ff: LayerNorm,
    pub encoder_encoders_4_norm_mha: LayerNorm,
    pub encoder_encoders_4_self_attn_dropout: Dropout,
    pub encoder_encoders_4_self_attn_linear_k: Linear,
    pub encoder_encoders_4_self_attn_linear_out: Linear,
    pub encoder_encoders_4_self_attn_linear_pos: Linear,
    pub encoder_encoders_4_self_attn_linear_q: Linear,
    pub encoder_encoders_4_self_attn_linear_v: Linear,
    pub encoder_encoders_5_dropout: Dropout,
    pub encoder_encoders_5_dropout_1: Dropout,
    pub encoder_encoders_5_feed_forward_dropout: Dropout,
    pub encoder_encoders_5_feed_forward_w_1: Linear,
    pub encoder_encoders_5_feed_forward_w_2: Linear,
    pub encoder_encoders_5_norm_ff: LayerNorm,
    pub encoder_encoders_5_norm_mha: LayerNorm,
    pub encoder_encoders_5_self_attn_dropout: Dropout,
    pub encoder_encoders_5_self_attn_linear_k: Linear,
    pub encoder_encoders_5_self_attn_linear_out: Linear,
    pub encoder_encoders_5_self_attn_linear_pos: Linear,
    pub encoder_encoders_5_self_attn_linear_q: Linear,
    pub encoder_encoders_5_self_attn_linear_v: Linear,
    pub encoder_pre_lookahead_layer_conv1: Conv1d,
    pub encoder_pre_lookahead_layer_conv2: Conv1d,
    pub encoder_up_embed_out_0: Linear,
    pub encoder_up_embed_out_1: LayerNorm,
    pub encoder_up_embed_out_2: Dropout,
    pub encoder_up_embed_pos_enc_dropout: Dropout,
    pub encoder_up_embed_pos_enc_dropout_1: Dropout,
    pub encoder_up_encoders_0_dropout: Dropout,
    pub encoder_up_encoders_0_dropout_1: Dropout,
    pub encoder_up_encoders_0_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_0_feed_forward_w_1: Linear,
    pub encoder_up_encoders_0_feed_forward_w_2: Linear,
    pub encoder_up_encoders_0_norm_ff: LayerNorm,
    pub encoder_up_encoders_0_norm_mha: LayerNorm,
    pub encoder_up_encoders_0_self_attn_dropout: Dropout,
    pub encoder_up_encoders_0_self_attn_linear_k: Linear,
    pub encoder_up_encoders_0_self_attn_linear_out: Linear,
    pub encoder_up_encoders_0_self_attn_linear_pos: Linear,
    pub encoder_up_encoders_0_self_attn_linear_q: Linear,
    pub encoder_up_encoders_0_self_attn_linear_v: Linear,
    pub encoder_up_encoders_1_dropout: Dropout,
    pub encoder_up_encoders_1_dropout_1: Dropout,
    pub encoder_up_encoders_1_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_1_feed_forward_w_1: Linear,
    pub encoder_up_encoders_1_feed_forward_w_2: Linear,
    pub encoder_up_encoders_1_norm_ff: LayerNorm,
    pub encoder_up_encoders_1_norm_mha: LayerNorm,
    pub encoder_up_encoders_1_self_attn_dropout: Dropout,
    pub encoder_up_encoders_1_self_attn_linear_k: Linear,
    pub encoder_up_encoders_1_self_attn_linear_out: Linear,
    pub encoder_up_encoders_1_self_attn_linear_pos: Linear,
    pub encoder_up_encoders_1_self_attn_linear_q: Linear,
    pub encoder_up_encoders_1_self_attn_linear_v: Linear,
    pub encoder_up_encoders_2_dropout: Dropout,
    pub encoder_up_encoders_2_dropout_1: Dropout,
    pub encoder_up_encoders_2_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_2_feed_forward_w_1: Linear,
    pub encoder_up_encoders_2_feed_forward_w_2: Linear,
    pub encoder_up_encoders_2_norm_ff: LayerNorm,
    pub encoder_up_encoders_2_norm_mha: LayerNorm,
    pub encoder_up_encoders_2_self_attn_dropout: Dropout,
    pub encoder_up_encoders_2_self_attn_linear_k: Linear,
    pub encoder_up_encoders_2_self_attn_linear_out: Linear,
    pub encoder_up_encoders_2_self_attn_linear_pos: Linear,
    pub encoder_up_encoders_2_self_attn_linear_q: Linear,
    pub encoder_up_encoders_2_self_attn_linear_v: Linear,
    pub encoder_up_encoders_3_dropout: Dropout,
    pub encoder_up_encoders_3_dropout_1: Dropout,
    pub encoder_up_encoders_3_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_3_feed_forward_w_1: Linear,
    pub encoder_up_encoders_3_feed_forward_w_2: Linear,
    pub encoder_up_encoders_3_norm_ff: LayerNorm,
    pub encoder_up_encoders_3_norm_mha: LayerNorm,
    pub encoder_up_encoders_3_self_attn_dropout: Dropout,
    pub encoder_up_encoders_3_self_attn_linear_k: Linear,
    pub encoder_up_encoders_3_self_attn_linear_out: Linear,
    pub encoder_up_encoders_3_self_attn_linear_pos: Linear,
    pub encoder_up_encoders_3_self_attn_linear_q: Linear,
    pub encoder_up_encoders_3_self_attn_linear_v: Linear,
    pub encoder_up_layer_conv: Conv1d,
    pub encoder_proj: Linear,
    pub input_embedding: Embedding,
    pub spk_embed_affine_layer: Linear,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let decoder_estimator_down_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.0.block1.block.0"), 320, 256, 3, 1, true)?;
        let decoder_estimator_down_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_down_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_down_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_down_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_down_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_down_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_down_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.0.mlp.1"))?;
        let decoder_estimator_down_blocks_0_0_res_conv = candle_nn::conv1d(320, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.res_conv"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.0.norm1"))?;
        let decoder_estimator_down_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.0.norm3"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.1.norm1"))?;
        let decoder_estimator_down_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.1.norm3"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.2.norm1"))?;
        let decoder_estimator_down_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.2.norm3"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.3.norm1"))?;
        let decoder_estimator_down_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.3.norm3"))?;
        let decoder_estimator_down_blocks_0_2 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.2"), 256, 256, 3, 1, true)?;
        let decoder_estimator_final_block_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.final_block.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_final_block_block_1 = Transpose::new(1, 2);
        let decoder_estimator_final_block_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.final_block.block.2"))?;
        let decoder_estimator_final_block_block_3 = Transpose::new(1, 2);
        let decoder_estimator_final_block_block_4 = Mish;
        let decoder_estimator_final_proj = candle_nn::conv1d(256, 80, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.final_proj"))?;
        let decoder_estimator_mid_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.0.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_0_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.res_conv"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_1_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.1.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_1_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_1_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_1_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.1.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_1_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_1_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_1_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_1_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_1_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.res_conv"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_10_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.10.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_10_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_10_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_10_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.10.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_10_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_10_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_10_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_10_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_10_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.res_conv"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_11_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.11.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_11_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_11_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_11_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.11.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_11_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_11_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_11_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_11_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_11_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.res_conv"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_2_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.2.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_2_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_2_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_2_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.2.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_2_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_2_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_2_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_2_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_2_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.res_conv"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_3_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.3.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_3_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_3_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_3_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.3.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_3_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_3_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_3_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_3_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_3_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.res_conv"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_4_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.4.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_4_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_4_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_4_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.4.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_4_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_4_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_4_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_4_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_4_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.res_conv"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_5_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.5.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_5_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_5_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_5_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.5.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_5_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_5_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_5_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_5_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_5_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.res_conv"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_6_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.6.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_6_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_6_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_6_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.6.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_6_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_6_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_6_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_6_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_6_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.res_conv"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_7_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.7.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_7_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_7_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_7_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.7.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_7_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_7_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_7_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_7_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_7_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.res_conv"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_8_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.8.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_8_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_8_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_8_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.8.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_8_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_8_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_8_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_8_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_8_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.res_conv"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_9_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.9.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_9_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_9_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_9_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.9.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_9_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_9_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_9_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_9_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_9_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.res_conv"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.3.norm3"))?;
        let decoder_estimator_time_embeddings = SinusoidalPosEmb::new(320);
        let decoder_estimator_time_mlp_act = SiLU;
        let decoder_estimator_time_mlp_linear_1 = candle_nn::linear(320, 1024, vb.pp("decoder.estimator.time_mlp.linear_1"))?;
        let decoder_estimator_time_mlp_linear_2 = { let w = vb.pp("decoder.estimator.time_mlp.linear_2").get((1024, 1024), "weight")?.t()?; let b = Some(vb.pp("decoder.estimator.time_mlp.linear_2").get(1024, "bias")?); Linear::new(w, b) };
        let decoder_estimator_up_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.0.block1.block.0"), 512, 256, 3, 1, true)?;
        let decoder_estimator_up_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_up_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_up_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_up_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_up_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_up_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_up_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.0.mlp.1"))?;
        let decoder_estimator_up_blocks_0_0_res_conv = candle_nn::conv1d(512, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.res_conv"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.0.norm1"))?;
        let decoder_estimator_up_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.0.norm3"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.1.norm1"))?;
        let decoder_estimator_up_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.1.norm3"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.2.norm1"))?;
        let decoder_estimator_up_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.2.norm3"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(512, 256, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, 512, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.3.norm1"))?;
        let decoder_estimator_up_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.3.norm3"))?;
        let decoder_estimator_up_blocks_0_2 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.2"), 256, 256, 3, 1, true)?;
        let encoder_after_norm = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.after_norm"))?;
        let encoder_embed_out_0 = { let w = vb.pp("encoder.embed.out.0").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.embed.out.0").get(512, "bias")?); Linear::new(w, b) };
        let encoder_embed_out_1 = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.embed.out.1"))?;
        let encoder_embed_out_2 = Dropout::new();
        let encoder_embed_pos_enc_dropout = Dropout::new();
        let encoder_embed_pos_enc_dropout_1 = Dropout::new();
        let encoder_encoders_0_dropout = Dropout::new();
        let encoder_encoders_0_dropout_1 = Dropout::new();
        let encoder_encoders_0_feed_forward_activation = SiLU;
        let encoder_encoders_0_feed_forward_activation_1 = SiLU;
        let encoder_encoders_0_feed_forward_activation_2 = SiLU;
        let encoder_encoders_0_feed_forward_activation_3 = SiLU;
        let encoder_encoders_0_feed_forward_activation_4 = SiLU;
        let encoder_encoders_0_feed_forward_activation_5 = SiLU;
        let encoder_encoders_0_feed_forward_activation_6 = SiLU;
        let encoder_encoders_0_feed_forward_activation_7 = SiLU;
        let encoder_encoders_0_feed_forward_activation_8 = SiLU;
        let encoder_encoders_0_feed_forward_activation_9 = SiLU;
        let encoder_encoders_0_feed_forward_dropout = Dropout::new();
        let encoder_encoders_0_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.0.feed_forward.w_1"))?;
        let encoder_encoders_0_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.0.feed_forward.w_2"))?;
        let encoder_encoders_0_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.0.norm_ff"))?;
        let encoder_encoders_0_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.0.norm_mha"))?;
        let encoder_encoders_0_self_attn_dropout = Dropout::new();
        let encoder_encoders_0_self_attn_linear_k = { let w = vb.pp("encoder.encoders.0.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_out = { let w = vb.pp("encoder.encoders.0.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.0.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_q = { let w = vb.pp("encoder.encoders.0.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_v = { let w = vb.pp("encoder.encoders.0.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_1_dropout = Dropout::new();
        let encoder_encoders_1_dropout_1 = Dropout::new();
        let encoder_encoders_1_feed_forward_dropout = Dropout::new();
        let encoder_encoders_1_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.1.feed_forward.w_1"))?;
        let encoder_encoders_1_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.1.feed_forward.w_2"))?;
        let encoder_encoders_1_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.1.norm_ff"))?;
        let encoder_encoders_1_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.1.norm_mha"))?;
        let encoder_encoders_1_self_attn_dropout = Dropout::new();
        let encoder_encoders_1_self_attn_linear_k = { let w = vb.pp("encoder.encoders.1.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_out = { let w = vb.pp("encoder.encoders.1.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.1.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_q = { let w = vb.pp("encoder.encoders.1.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_v = { let w = vb.pp("encoder.encoders.1.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_2_dropout = Dropout::new();
        let encoder_encoders_2_dropout_1 = Dropout::new();
        let encoder_encoders_2_feed_forward_dropout = Dropout::new();
        let encoder_encoders_2_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.2.feed_forward.w_1"))?;
        let encoder_encoders_2_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.2.feed_forward.w_2"))?;
        let encoder_encoders_2_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.2.norm_ff"))?;
        let encoder_encoders_2_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.2.norm_mha"))?;
        let encoder_encoders_2_self_attn_dropout = Dropout::new();
        let encoder_encoders_2_self_attn_linear_k = { let w = vb.pp("encoder.encoders.2.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_out = { let w = vb.pp("encoder.encoders.2.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.2.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_q = { let w = vb.pp("encoder.encoders.2.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_v = { let w = vb.pp("encoder.encoders.2.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_3_dropout = Dropout::new();
        let encoder_encoders_3_dropout_1 = Dropout::new();
        let encoder_encoders_3_feed_forward_dropout = Dropout::new();
        let encoder_encoders_3_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.3.feed_forward.w_1"))?;
        let encoder_encoders_3_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.3.feed_forward.w_2"))?;
        let encoder_encoders_3_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.3.norm_ff"))?;
        let encoder_encoders_3_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.3.norm_mha"))?;
        let encoder_encoders_3_self_attn_dropout = Dropout::new();
        let encoder_encoders_3_self_attn_linear_k = { let w = vb.pp("encoder.encoders.3.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_out = { let w = vb.pp("encoder.encoders.3.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.3.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_q = { let w = vb.pp("encoder.encoders.3.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_v = { let w = vb.pp("encoder.encoders.3.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_4_dropout = Dropout::new();
        let encoder_encoders_4_dropout_1 = Dropout::new();
        let encoder_encoders_4_feed_forward_dropout = Dropout::new();
        let encoder_encoders_4_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.4.feed_forward.w_1"))?;
        let encoder_encoders_4_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.4.feed_forward.w_2"))?;
        let encoder_encoders_4_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.4.norm_ff"))?;
        let encoder_encoders_4_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.4.norm_mha"))?;
        let encoder_encoders_4_self_attn_dropout = Dropout::new();
        let encoder_encoders_4_self_attn_linear_k = { let w = vb.pp("encoder.encoders.4.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_out = { let w = vb.pp("encoder.encoders.4.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.4.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_q = { let w = vb.pp("encoder.encoders.4.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_v = { let w = vb.pp("encoder.encoders.4.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_5_dropout = Dropout::new();
        let encoder_encoders_5_dropout_1 = Dropout::new();
        let encoder_encoders_5_feed_forward_dropout = Dropout::new();
        let encoder_encoders_5_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.encoders.5.feed_forward.w_1"))?;
        let encoder_encoders_5_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.encoders.5.feed_forward.w_2"))?;
        let encoder_encoders_5_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.5.norm_ff"))?;
        let encoder_encoders_5_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.5.norm_mha"))?;
        let encoder_encoders_5_self_attn_dropout = Dropout::new();
        let encoder_encoders_5_self_attn_linear_k = { let w = vb.pp("encoder.encoders.5.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_out = { let w = vb.pp("encoder.encoders.5.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.5.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_q = { let w = vb.pp("encoder.encoders.5.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_v = { let w = vb.pp("encoder.encoders.5.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_pre_lookahead_layer_conv1 = candle_nn::conv1d(512, 512, 4, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.pre_lookahead_layer.conv1"))?;
        let encoder_pre_lookahead_layer_conv2 = candle_nn::conv1d(512, 512, 3, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.pre_lookahead_layer.conv2"))?;
        let encoder_up_embed_out_0 = { let w = vb.pp("encoder.up_embed.out.0").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_embed.out.0").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_embed_out_1 = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.up_embed.out.1"))?;
        let encoder_up_embed_out_2 = Dropout::new();
        let encoder_up_embed_pos_enc_dropout = Dropout::new();
        let encoder_up_embed_pos_enc_dropout_1 = Dropout::new();
        let encoder_up_encoders_0_dropout = Dropout::new();
        let encoder_up_encoders_0_dropout_1 = Dropout::new();
        let encoder_up_encoders_0_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_0_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.up_encoders.0.feed_forward.w_1"))?;
        let encoder_up_encoders_0_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.up_encoders.0.feed_forward.w_2"))?;
        let encoder_up_encoders_0_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.0.norm_ff"))?;
        let encoder_up_encoders_0_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.0.norm_mha"))?;
        let encoder_up_encoders_0_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_0_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_1_dropout = Dropout::new();
        let encoder_up_encoders_1_dropout_1 = Dropout::new();
        let encoder_up_encoders_1_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_1_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.up_encoders.1.feed_forward.w_1"))?;
        let encoder_up_encoders_1_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.up_encoders.1.feed_forward.w_2"))?;
        let encoder_up_encoders_1_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.1.norm_ff"))?;
        let encoder_up_encoders_1_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.1.norm_mha"))?;
        let encoder_up_encoders_1_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_1_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_2_dropout = Dropout::new();
        let encoder_up_encoders_2_dropout_1 = Dropout::new();
        let encoder_up_encoders_2_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_2_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.up_encoders.2.feed_forward.w_1"))?;
        let encoder_up_encoders_2_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.up_encoders.2.feed_forward.w_2"))?;
        let encoder_up_encoders_2_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.2.norm_ff"))?;
        let encoder_up_encoders_2_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.2.norm_mha"))?;
        let encoder_up_encoders_2_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_2_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_3_dropout = Dropout::new();
        let encoder_up_encoders_3_dropout_1 = Dropout::new();
        let encoder_up_encoders_3_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_3_feed_forward_w_1 = candle_nn::linear(512, 2048, vb.pp("encoder.up_encoders.3.feed_forward.w_1"))?;
        let encoder_up_encoders_3_feed_forward_w_2 = candle_nn::linear(2048, 512, vb.pp("encoder.up_encoders.3.feed_forward.w_2"))?;
        let encoder_up_encoders_3_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.3.norm_ff"))?;
        let encoder_up_encoders_3_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.3.norm_mha"))?;
        let encoder_up_encoders_3_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_3_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_k").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_k").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_out").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_out").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_pos").get((512, 512), "weight")?.t()?; let b = None; Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_q").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_q").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_v").get((512, 512), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_v").get(512, "bias")?); Linear::new(w, b) };
        let encoder_up_layer_conv = candle_nn::conv1d(512, 512, 5, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.up_layer.conv"))?;
        let encoder_proj = candle_nn::linear(512, 80, vb.pp("encoder_proj"))?;
        let input_embedding = candle_nn::embedding(6561, 512, vb.pp("input_embedding"))?;
        let spk_embed_affine_layer = candle_nn::linear(192, 80, vb.pp("spk_embed_affine_layer"))?;

        Ok(Self {
            decoder_estimator_down_blocks_0_0_block1_block_0,
            decoder_estimator_down_blocks_0_0_block1_block_1,
            decoder_estimator_down_blocks_0_0_block1_block_2,
            decoder_estimator_down_blocks_0_0_block1_block_3,
            decoder_estimator_down_blocks_0_0_block1_block_4,
            decoder_estimator_down_blocks_0_0_block2_block_0,
            decoder_estimator_down_blocks_0_0_block2_block_1,
            decoder_estimator_down_blocks_0_0_block2_block_2,
            decoder_estimator_down_blocks_0_0_block2_block_3,
            decoder_estimator_down_blocks_0_0_block2_block_4,
            decoder_estimator_down_blocks_0_0_mlp_0,
            decoder_estimator_down_blocks_0_0_mlp_1,
            decoder_estimator_down_blocks_0_0_res_conv,
            decoder_estimator_down_blocks_0_1_0_attn1_to_k,
            decoder_estimator_down_blocks_0_1_0_attn1_to_out_0,
            decoder_estimator_down_blocks_0_1_0_attn1_to_out_1,
            decoder_estimator_down_blocks_0_1_0_attn1_to_q,
            decoder_estimator_down_blocks_0_1_0_attn1_to_v,
            decoder_estimator_down_blocks_0_1_0_ff_net_0_proj,
            decoder_estimator_down_blocks_0_1_0_ff_net_1,
            decoder_estimator_down_blocks_0_1_0_ff_net_2,
            decoder_estimator_down_blocks_0_1_0_norm1,
            decoder_estimator_down_blocks_0_1_0_norm3,
            decoder_estimator_down_blocks_0_1_1_attn1_to_k,
            decoder_estimator_down_blocks_0_1_1_attn1_to_out_0,
            decoder_estimator_down_blocks_0_1_1_attn1_to_out_1,
            decoder_estimator_down_blocks_0_1_1_attn1_to_q,
            decoder_estimator_down_blocks_0_1_1_attn1_to_v,
            decoder_estimator_down_blocks_0_1_1_ff_net_0_proj,
            decoder_estimator_down_blocks_0_1_1_ff_net_1,
            decoder_estimator_down_blocks_0_1_1_ff_net_2,
            decoder_estimator_down_blocks_0_1_1_norm1,
            decoder_estimator_down_blocks_0_1_1_norm3,
            decoder_estimator_down_blocks_0_1_2_attn1_to_k,
            decoder_estimator_down_blocks_0_1_2_attn1_to_out_0,
            decoder_estimator_down_blocks_0_1_2_attn1_to_out_1,
            decoder_estimator_down_blocks_0_1_2_attn1_to_q,
            decoder_estimator_down_blocks_0_1_2_attn1_to_v,
            decoder_estimator_down_blocks_0_1_2_ff_net_0_proj,
            decoder_estimator_down_blocks_0_1_2_ff_net_1,
            decoder_estimator_down_blocks_0_1_2_ff_net_2,
            decoder_estimator_down_blocks_0_1_2_norm1,
            decoder_estimator_down_blocks_0_1_2_norm3,
            decoder_estimator_down_blocks_0_1_3_attn1_to_k,
            decoder_estimator_down_blocks_0_1_3_attn1_to_out_0,
            decoder_estimator_down_blocks_0_1_3_attn1_to_out_1,
            decoder_estimator_down_blocks_0_1_3_attn1_to_q,
            decoder_estimator_down_blocks_0_1_3_attn1_to_v,
            decoder_estimator_down_blocks_0_1_3_ff_net_0_proj,
            decoder_estimator_down_blocks_0_1_3_ff_net_1,
            decoder_estimator_down_blocks_0_1_3_ff_net_2,
            decoder_estimator_down_blocks_0_1_3_norm1,
            decoder_estimator_down_blocks_0_1_3_norm3,
            decoder_estimator_down_blocks_0_2,
            decoder_estimator_final_block_block_0,
            decoder_estimator_final_block_block_1,
            decoder_estimator_final_block_block_2,
            decoder_estimator_final_block_block_3,
            decoder_estimator_final_block_block_4,
            decoder_estimator_final_proj,
            decoder_estimator_mid_blocks_0_0_block1_block_0,
            decoder_estimator_mid_blocks_0_0_block1_block_1,
            decoder_estimator_mid_blocks_0_0_block1_block_2,
            decoder_estimator_mid_blocks_0_0_block1_block_3,
            decoder_estimator_mid_blocks_0_0_block1_block_4,
            decoder_estimator_mid_blocks_0_0_block2_block_0,
            decoder_estimator_mid_blocks_0_0_block2_block_1,
            decoder_estimator_mid_blocks_0_0_block2_block_2,
            decoder_estimator_mid_blocks_0_0_block2_block_3,
            decoder_estimator_mid_blocks_0_0_block2_block_4,
            decoder_estimator_mid_blocks_0_0_mlp_0,
            decoder_estimator_mid_blocks_0_0_mlp_1,
            decoder_estimator_mid_blocks_0_0_res_conv,
            decoder_estimator_mid_blocks_0_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_0_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_0_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_0_1_0_ff_net_1,
            decoder_estimator_mid_blocks_0_1_0_ff_net_2,
            decoder_estimator_mid_blocks_0_1_0_norm1,
            decoder_estimator_mid_blocks_0_1_0_norm3,
            decoder_estimator_mid_blocks_0_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_0_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_0_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_0_1_1_ff_net_1,
            decoder_estimator_mid_blocks_0_1_1_ff_net_2,
            decoder_estimator_mid_blocks_0_1_1_norm1,
            decoder_estimator_mid_blocks_0_1_1_norm3,
            decoder_estimator_mid_blocks_0_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_0_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_0_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_0_1_2_ff_net_1,
            decoder_estimator_mid_blocks_0_1_2_ff_net_2,
            decoder_estimator_mid_blocks_0_1_2_norm1,
            decoder_estimator_mid_blocks_0_1_2_norm3,
            decoder_estimator_mid_blocks_0_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_0_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_0_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_0_1_3_ff_net_1,
            decoder_estimator_mid_blocks_0_1_3_ff_net_2,
            decoder_estimator_mid_blocks_0_1_3_norm1,
            decoder_estimator_mid_blocks_0_1_3_norm3,
            decoder_estimator_mid_blocks_1_0_block1_block_0,
            decoder_estimator_mid_blocks_1_0_block1_block_1,
            decoder_estimator_mid_blocks_1_0_block1_block_2,
            decoder_estimator_mid_blocks_1_0_block1_block_3,
            decoder_estimator_mid_blocks_1_0_block1_block_4,
            decoder_estimator_mid_blocks_1_0_block2_block_0,
            decoder_estimator_mid_blocks_1_0_block2_block_1,
            decoder_estimator_mid_blocks_1_0_block2_block_2,
            decoder_estimator_mid_blocks_1_0_block2_block_3,
            decoder_estimator_mid_blocks_1_0_block2_block_4,
            decoder_estimator_mid_blocks_1_0_mlp_0,
            decoder_estimator_mid_blocks_1_0_mlp_1,
            decoder_estimator_mid_blocks_1_0_res_conv,
            decoder_estimator_mid_blocks_1_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_1_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_1_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_1_1_0_ff_net_1,
            decoder_estimator_mid_blocks_1_1_0_ff_net_2,
            decoder_estimator_mid_blocks_1_1_0_norm1,
            decoder_estimator_mid_blocks_1_1_0_norm3,
            decoder_estimator_mid_blocks_1_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_1_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_1_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_1_1_1_ff_net_1,
            decoder_estimator_mid_blocks_1_1_1_ff_net_2,
            decoder_estimator_mid_blocks_1_1_1_norm1,
            decoder_estimator_mid_blocks_1_1_1_norm3,
            decoder_estimator_mid_blocks_1_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_1_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_1_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_1_1_2_ff_net_1,
            decoder_estimator_mid_blocks_1_1_2_ff_net_2,
            decoder_estimator_mid_blocks_1_1_2_norm1,
            decoder_estimator_mid_blocks_1_1_2_norm3,
            decoder_estimator_mid_blocks_1_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_1_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_1_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_1_1_3_ff_net_1,
            decoder_estimator_mid_blocks_1_1_3_ff_net_2,
            decoder_estimator_mid_blocks_1_1_3_norm1,
            decoder_estimator_mid_blocks_1_1_3_norm3,
            decoder_estimator_mid_blocks_10_0_block1_block_0,
            decoder_estimator_mid_blocks_10_0_block1_block_1,
            decoder_estimator_mid_blocks_10_0_block1_block_2,
            decoder_estimator_mid_blocks_10_0_block1_block_3,
            decoder_estimator_mid_blocks_10_0_block1_block_4,
            decoder_estimator_mid_blocks_10_0_block2_block_0,
            decoder_estimator_mid_blocks_10_0_block2_block_1,
            decoder_estimator_mid_blocks_10_0_block2_block_2,
            decoder_estimator_mid_blocks_10_0_block2_block_3,
            decoder_estimator_mid_blocks_10_0_block2_block_4,
            decoder_estimator_mid_blocks_10_0_mlp_0,
            decoder_estimator_mid_blocks_10_0_mlp_1,
            decoder_estimator_mid_blocks_10_0_res_conv,
            decoder_estimator_mid_blocks_10_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_10_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_10_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_10_1_0_ff_net_1,
            decoder_estimator_mid_blocks_10_1_0_ff_net_2,
            decoder_estimator_mid_blocks_10_1_0_norm1,
            decoder_estimator_mid_blocks_10_1_0_norm3,
            decoder_estimator_mid_blocks_10_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_10_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_10_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_10_1_1_ff_net_1,
            decoder_estimator_mid_blocks_10_1_1_ff_net_2,
            decoder_estimator_mid_blocks_10_1_1_norm1,
            decoder_estimator_mid_blocks_10_1_1_norm3,
            decoder_estimator_mid_blocks_10_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_10_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_10_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_10_1_2_ff_net_1,
            decoder_estimator_mid_blocks_10_1_2_ff_net_2,
            decoder_estimator_mid_blocks_10_1_2_norm1,
            decoder_estimator_mid_blocks_10_1_2_norm3,
            decoder_estimator_mid_blocks_10_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_10_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_10_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_10_1_3_ff_net_1,
            decoder_estimator_mid_blocks_10_1_3_ff_net_2,
            decoder_estimator_mid_blocks_10_1_3_norm1,
            decoder_estimator_mid_blocks_10_1_3_norm3,
            decoder_estimator_mid_blocks_11_0_block1_block_0,
            decoder_estimator_mid_blocks_11_0_block1_block_1,
            decoder_estimator_mid_blocks_11_0_block1_block_2,
            decoder_estimator_mid_blocks_11_0_block1_block_3,
            decoder_estimator_mid_blocks_11_0_block1_block_4,
            decoder_estimator_mid_blocks_11_0_block2_block_0,
            decoder_estimator_mid_blocks_11_0_block2_block_1,
            decoder_estimator_mid_blocks_11_0_block2_block_2,
            decoder_estimator_mid_blocks_11_0_block2_block_3,
            decoder_estimator_mid_blocks_11_0_block2_block_4,
            decoder_estimator_mid_blocks_11_0_mlp_0,
            decoder_estimator_mid_blocks_11_0_mlp_1,
            decoder_estimator_mid_blocks_11_0_res_conv,
            decoder_estimator_mid_blocks_11_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_11_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_11_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_11_1_0_ff_net_1,
            decoder_estimator_mid_blocks_11_1_0_ff_net_2,
            decoder_estimator_mid_blocks_11_1_0_norm1,
            decoder_estimator_mid_blocks_11_1_0_norm3,
            decoder_estimator_mid_blocks_11_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_11_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_11_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_11_1_1_ff_net_1,
            decoder_estimator_mid_blocks_11_1_1_ff_net_2,
            decoder_estimator_mid_blocks_11_1_1_norm1,
            decoder_estimator_mid_blocks_11_1_1_norm3,
            decoder_estimator_mid_blocks_11_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_11_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_11_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_11_1_2_ff_net_1,
            decoder_estimator_mid_blocks_11_1_2_ff_net_2,
            decoder_estimator_mid_blocks_11_1_2_norm1,
            decoder_estimator_mid_blocks_11_1_2_norm3,
            decoder_estimator_mid_blocks_11_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_11_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_11_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_11_1_3_ff_net_1,
            decoder_estimator_mid_blocks_11_1_3_ff_net_2,
            decoder_estimator_mid_blocks_11_1_3_norm1,
            decoder_estimator_mid_blocks_11_1_3_norm3,
            decoder_estimator_mid_blocks_2_0_block1_block_0,
            decoder_estimator_mid_blocks_2_0_block1_block_1,
            decoder_estimator_mid_blocks_2_0_block1_block_2,
            decoder_estimator_mid_blocks_2_0_block1_block_3,
            decoder_estimator_mid_blocks_2_0_block1_block_4,
            decoder_estimator_mid_blocks_2_0_block2_block_0,
            decoder_estimator_mid_blocks_2_0_block2_block_1,
            decoder_estimator_mid_blocks_2_0_block2_block_2,
            decoder_estimator_mid_blocks_2_0_block2_block_3,
            decoder_estimator_mid_blocks_2_0_block2_block_4,
            decoder_estimator_mid_blocks_2_0_mlp_0,
            decoder_estimator_mid_blocks_2_0_mlp_1,
            decoder_estimator_mid_blocks_2_0_res_conv,
            decoder_estimator_mid_blocks_2_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_2_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_2_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_2_1_0_ff_net_1,
            decoder_estimator_mid_blocks_2_1_0_ff_net_2,
            decoder_estimator_mid_blocks_2_1_0_norm1,
            decoder_estimator_mid_blocks_2_1_0_norm3,
            decoder_estimator_mid_blocks_2_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_2_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_2_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_2_1_1_ff_net_1,
            decoder_estimator_mid_blocks_2_1_1_ff_net_2,
            decoder_estimator_mid_blocks_2_1_1_norm1,
            decoder_estimator_mid_blocks_2_1_1_norm3,
            decoder_estimator_mid_blocks_2_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_2_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_2_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_2_1_2_ff_net_1,
            decoder_estimator_mid_blocks_2_1_2_ff_net_2,
            decoder_estimator_mid_blocks_2_1_2_norm1,
            decoder_estimator_mid_blocks_2_1_2_norm3,
            decoder_estimator_mid_blocks_2_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_2_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_2_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_2_1_3_ff_net_1,
            decoder_estimator_mid_blocks_2_1_3_ff_net_2,
            decoder_estimator_mid_blocks_2_1_3_norm1,
            decoder_estimator_mid_blocks_2_1_3_norm3,
            decoder_estimator_mid_blocks_3_0_block1_block_0,
            decoder_estimator_mid_blocks_3_0_block1_block_1,
            decoder_estimator_mid_blocks_3_0_block1_block_2,
            decoder_estimator_mid_blocks_3_0_block1_block_3,
            decoder_estimator_mid_blocks_3_0_block1_block_4,
            decoder_estimator_mid_blocks_3_0_block2_block_0,
            decoder_estimator_mid_blocks_3_0_block2_block_1,
            decoder_estimator_mid_blocks_3_0_block2_block_2,
            decoder_estimator_mid_blocks_3_0_block2_block_3,
            decoder_estimator_mid_blocks_3_0_block2_block_4,
            decoder_estimator_mid_blocks_3_0_mlp_0,
            decoder_estimator_mid_blocks_3_0_mlp_1,
            decoder_estimator_mid_blocks_3_0_res_conv,
            decoder_estimator_mid_blocks_3_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_3_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_3_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_3_1_0_ff_net_1,
            decoder_estimator_mid_blocks_3_1_0_ff_net_2,
            decoder_estimator_mid_blocks_3_1_0_norm1,
            decoder_estimator_mid_blocks_3_1_0_norm3,
            decoder_estimator_mid_blocks_3_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_3_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_3_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_3_1_1_ff_net_1,
            decoder_estimator_mid_blocks_3_1_1_ff_net_2,
            decoder_estimator_mid_blocks_3_1_1_norm1,
            decoder_estimator_mid_blocks_3_1_1_norm3,
            decoder_estimator_mid_blocks_3_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_3_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_3_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_3_1_2_ff_net_1,
            decoder_estimator_mid_blocks_3_1_2_ff_net_2,
            decoder_estimator_mid_blocks_3_1_2_norm1,
            decoder_estimator_mid_blocks_3_1_2_norm3,
            decoder_estimator_mid_blocks_3_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_3_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_3_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_3_1_3_ff_net_1,
            decoder_estimator_mid_blocks_3_1_3_ff_net_2,
            decoder_estimator_mid_blocks_3_1_3_norm1,
            decoder_estimator_mid_blocks_3_1_3_norm3,
            decoder_estimator_mid_blocks_4_0_block1_block_0,
            decoder_estimator_mid_blocks_4_0_block1_block_1,
            decoder_estimator_mid_blocks_4_0_block1_block_2,
            decoder_estimator_mid_blocks_4_0_block1_block_3,
            decoder_estimator_mid_blocks_4_0_block1_block_4,
            decoder_estimator_mid_blocks_4_0_block2_block_0,
            decoder_estimator_mid_blocks_4_0_block2_block_1,
            decoder_estimator_mid_blocks_4_0_block2_block_2,
            decoder_estimator_mid_blocks_4_0_block2_block_3,
            decoder_estimator_mid_blocks_4_0_block2_block_4,
            decoder_estimator_mid_blocks_4_0_mlp_0,
            decoder_estimator_mid_blocks_4_0_mlp_1,
            decoder_estimator_mid_blocks_4_0_res_conv,
            decoder_estimator_mid_blocks_4_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_4_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_4_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_4_1_0_ff_net_1,
            decoder_estimator_mid_blocks_4_1_0_ff_net_2,
            decoder_estimator_mid_blocks_4_1_0_norm1,
            decoder_estimator_mid_blocks_4_1_0_norm3,
            decoder_estimator_mid_blocks_4_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_4_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_4_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_4_1_1_ff_net_1,
            decoder_estimator_mid_blocks_4_1_1_ff_net_2,
            decoder_estimator_mid_blocks_4_1_1_norm1,
            decoder_estimator_mid_blocks_4_1_1_norm3,
            decoder_estimator_mid_blocks_4_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_4_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_4_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_4_1_2_ff_net_1,
            decoder_estimator_mid_blocks_4_1_2_ff_net_2,
            decoder_estimator_mid_blocks_4_1_2_norm1,
            decoder_estimator_mid_blocks_4_1_2_norm3,
            decoder_estimator_mid_blocks_4_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_4_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_4_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_4_1_3_ff_net_1,
            decoder_estimator_mid_blocks_4_1_3_ff_net_2,
            decoder_estimator_mid_blocks_4_1_3_norm1,
            decoder_estimator_mid_blocks_4_1_3_norm3,
            decoder_estimator_mid_blocks_5_0_block1_block_0,
            decoder_estimator_mid_blocks_5_0_block1_block_1,
            decoder_estimator_mid_blocks_5_0_block1_block_2,
            decoder_estimator_mid_blocks_5_0_block1_block_3,
            decoder_estimator_mid_blocks_5_0_block1_block_4,
            decoder_estimator_mid_blocks_5_0_block2_block_0,
            decoder_estimator_mid_blocks_5_0_block2_block_1,
            decoder_estimator_mid_blocks_5_0_block2_block_2,
            decoder_estimator_mid_blocks_5_0_block2_block_3,
            decoder_estimator_mid_blocks_5_0_block2_block_4,
            decoder_estimator_mid_blocks_5_0_mlp_0,
            decoder_estimator_mid_blocks_5_0_mlp_1,
            decoder_estimator_mid_blocks_5_0_res_conv,
            decoder_estimator_mid_blocks_5_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_5_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_5_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_5_1_0_ff_net_1,
            decoder_estimator_mid_blocks_5_1_0_ff_net_2,
            decoder_estimator_mid_blocks_5_1_0_norm1,
            decoder_estimator_mid_blocks_5_1_0_norm3,
            decoder_estimator_mid_blocks_5_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_5_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_5_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_5_1_1_ff_net_1,
            decoder_estimator_mid_blocks_5_1_1_ff_net_2,
            decoder_estimator_mid_blocks_5_1_1_norm1,
            decoder_estimator_mid_blocks_5_1_1_norm3,
            decoder_estimator_mid_blocks_5_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_5_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_5_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_5_1_2_ff_net_1,
            decoder_estimator_mid_blocks_5_1_2_ff_net_2,
            decoder_estimator_mid_blocks_5_1_2_norm1,
            decoder_estimator_mid_blocks_5_1_2_norm3,
            decoder_estimator_mid_blocks_5_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_5_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_5_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_5_1_3_ff_net_1,
            decoder_estimator_mid_blocks_5_1_3_ff_net_2,
            decoder_estimator_mid_blocks_5_1_3_norm1,
            decoder_estimator_mid_blocks_5_1_3_norm3,
            decoder_estimator_mid_blocks_6_0_block1_block_0,
            decoder_estimator_mid_blocks_6_0_block1_block_1,
            decoder_estimator_mid_blocks_6_0_block1_block_2,
            decoder_estimator_mid_blocks_6_0_block1_block_3,
            decoder_estimator_mid_blocks_6_0_block1_block_4,
            decoder_estimator_mid_blocks_6_0_block2_block_0,
            decoder_estimator_mid_blocks_6_0_block2_block_1,
            decoder_estimator_mid_blocks_6_0_block2_block_2,
            decoder_estimator_mid_blocks_6_0_block2_block_3,
            decoder_estimator_mid_blocks_6_0_block2_block_4,
            decoder_estimator_mid_blocks_6_0_mlp_0,
            decoder_estimator_mid_blocks_6_0_mlp_1,
            decoder_estimator_mid_blocks_6_0_res_conv,
            decoder_estimator_mid_blocks_6_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_6_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_6_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_6_1_0_ff_net_1,
            decoder_estimator_mid_blocks_6_1_0_ff_net_2,
            decoder_estimator_mid_blocks_6_1_0_norm1,
            decoder_estimator_mid_blocks_6_1_0_norm3,
            decoder_estimator_mid_blocks_6_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_6_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_6_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_6_1_1_ff_net_1,
            decoder_estimator_mid_blocks_6_1_1_ff_net_2,
            decoder_estimator_mid_blocks_6_1_1_norm1,
            decoder_estimator_mid_blocks_6_1_1_norm3,
            decoder_estimator_mid_blocks_6_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_6_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_6_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_6_1_2_ff_net_1,
            decoder_estimator_mid_blocks_6_1_2_ff_net_2,
            decoder_estimator_mid_blocks_6_1_2_norm1,
            decoder_estimator_mid_blocks_6_1_2_norm3,
            decoder_estimator_mid_blocks_6_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_6_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_6_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_6_1_3_ff_net_1,
            decoder_estimator_mid_blocks_6_1_3_ff_net_2,
            decoder_estimator_mid_blocks_6_1_3_norm1,
            decoder_estimator_mid_blocks_6_1_3_norm3,
            decoder_estimator_mid_blocks_7_0_block1_block_0,
            decoder_estimator_mid_blocks_7_0_block1_block_1,
            decoder_estimator_mid_blocks_7_0_block1_block_2,
            decoder_estimator_mid_blocks_7_0_block1_block_3,
            decoder_estimator_mid_blocks_7_0_block1_block_4,
            decoder_estimator_mid_blocks_7_0_block2_block_0,
            decoder_estimator_mid_blocks_7_0_block2_block_1,
            decoder_estimator_mid_blocks_7_0_block2_block_2,
            decoder_estimator_mid_blocks_7_0_block2_block_3,
            decoder_estimator_mid_blocks_7_0_block2_block_4,
            decoder_estimator_mid_blocks_7_0_mlp_0,
            decoder_estimator_mid_blocks_7_0_mlp_1,
            decoder_estimator_mid_blocks_7_0_res_conv,
            decoder_estimator_mid_blocks_7_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_7_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_7_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_7_1_0_ff_net_1,
            decoder_estimator_mid_blocks_7_1_0_ff_net_2,
            decoder_estimator_mid_blocks_7_1_0_norm1,
            decoder_estimator_mid_blocks_7_1_0_norm3,
            decoder_estimator_mid_blocks_7_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_7_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_7_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_7_1_1_ff_net_1,
            decoder_estimator_mid_blocks_7_1_1_ff_net_2,
            decoder_estimator_mid_blocks_7_1_1_norm1,
            decoder_estimator_mid_blocks_7_1_1_norm3,
            decoder_estimator_mid_blocks_7_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_7_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_7_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_7_1_2_ff_net_1,
            decoder_estimator_mid_blocks_7_1_2_ff_net_2,
            decoder_estimator_mid_blocks_7_1_2_norm1,
            decoder_estimator_mid_blocks_7_1_2_norm3,
            decoder_estimator_mid_blocks_7_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_7_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_7_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_7_1_3_ff_net_1,
            decoder_estimator_mid_blocks_7_1_3_ff_net_2,
            decoder_estimator_mid_blocks_7_1_3_norm1,
            decoder_estimator_mid_blocks_7_1_3_norm3,
            decoder_estimator_mid_blocks_8_0_block1_block_0,
            decoder_estimator_mid_blocks_8_0_block1_block_1,
            decoder_estimator_mid_blocks_8_0_block1_block_2,
            decoder_estimator_mid_blocks_8_0_block1_block_3,
            decoder_estimator_mid_blocks_8_0_block1_block_4,
            decoder_estimator_mid_blocks_8_0_block2_block_0,
            decoder_estimator_mid_blocks_8_0_block2_block_1,
            decoder_estimator_mid_blocks_8_0_block2_block_2,
            decoder_estimator_mid_blocks_8_0_block2_block_3,
            decoder_estimator_mid_blocks_8_0_block2_block_4,
            decoder_estimator_mid_blocks_8_0_mlp_0,
            decoder_estimator_mid_blocks_8_0_mlp_1,
            decoder_estimator_mid_blocks_8_0_res_conv,
            decoder_estimator_mid_blocks_8_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_8_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_8_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_8_1_0_ff_net_1,
            decoder_estimator_mid_blocks_8_1_0_ff_net_2,
            decoder_estimator_mid_blocks_8_1_0_norm1,
            decoder_estimator_mid_blocks_8_1_0_norm3,
            decoder_estimator_mid_blocks_8_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_8_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_8_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_8_1_1_ff_net_1,
            decoder_estimator_mid_blocks_8_1_1_ff_net_2,
            decoder_estimator_mid_blocks_8_1_1_norm1,
            decoder_estimator_mid_blocks_8_1_1_norm3,
            decoder_estimator_mid_blocks_8_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_8_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_8_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_8_1_2_ff_net_1,
            decoder_estimator_mid_blocks_8_1_2_ff_net_2,
            decoder_estimator_mid_blocks_8_1_2_norm1,
            decoder_estimator_mid_blocks_8_1_2_norm3,
            decoder_estimator_mid_blocks_8_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_8_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_8_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_8_1_3_ff_net_1,
            decoder_estimator_mid_blocks_8_1_3_ff_net_2,
            decoder_estimator_mid_blocks_8_1_3_norm1,
            decoder_estimator_mid_blocks_8_1_3_norm3,
            decoder_estimator_mid_blocks_9_0_block1_block_0,
            decoder_estimator_mid_blocks_9_0_block1_block_1,
            decoder_estimator_mid_blocks_9_0_block1_block_2,
            decoder_estimator_mid_blocks_9_0_block1_block_3,
            decoder_estimator_mid_blocks_9_0_block1_block_4,
            decoder_estimator_mid_blocks_9_0_block2_block_0,
            decoder_estimator_mid_blocks_9_0_block2_block_1,
            decoder_estimator_mid_blocks_9_0_block2_block_2,
            decoder_estimator_mid_blocks_9_0_block2_block_3,
            decoder_estimator_mid_blocks_9_0_block2_block_4,
            decoder_estimator_mid_blocks_9_0_mlp_0,
            decoder_estimator_mid_blocks_9_0_mlp_1,
            decoder_estimator_mid_blocks_9_0_res_conv,
            decoder_estimator_mid_blocks_9_1_0_attn1_to_k,
            decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0,
            decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1,
            decoder_estimator_mid_blocks_9_1_0_attn1_to_q,
            decoder_estimator_mid_blocks_9_1_0_attn1_to_v,
            decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj,
            decoder_estimator_mid_blocks_9_1_0_ff_net_1,
            decoder_estimator_mid_blocks_9_1_0_ff_net_2,
            decoder_estimator_mid_blocks_9_1_0_norm1,
            decoder_estimator_mid_blocks_9_1_0_norm3,
            decoder_estimator_mid_blocks_9_1_1_attn1_to_k,
            decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0,
            decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1,
            decoder_estimator_mid_blocks_9_1_1_attn1_to_q,
            decoder_estimator_mid_blocks_9_1_1_attn1_to_v,
            decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj,
            decoder_estimator_mid_blocks_9_1_1_ff_net_1,
            decoder_estimator_mid_blocks_9_1_1_ff_net_2,
            decoder_estimator_mid_blocks_9_1_1_norm1,
            decoder_estimator_mid_blocks_9_1_1_norm3,
            decoder_estimator_mid_blocks_9_1_2_attn1_to_k,
            decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0,
            decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1,
            decoder_estimator_mid_blocks_9_1_2_attn1_to_q,
            decoder_estimator_mid_blocks_9_1_2_attn1_to_v,
            decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj,
            decoder_estimator_mid_blocks_9_1_2_ff_net_1,
            decoder_estimator_mid_blocks_9_1_2_ff_net_2,
            decoder_estimator_mid_blocks_9_1_2_norm1,
            decoder_estimator_mid_blocks_9_1_2_norm3,
            decoder_estimator_mid_blocks_9_1_3_attn1_to_k,
            decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0,
            decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1,
            decoder_estimator_mid_blocks_9_1_3_attn1_to_q,
            decoder_estimator_mid_blocks_9_1_3_attn1_to_v,
            decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj,
            decoder_estimator_mid_blocks_9_1_3_ff_net_1,
            decoder_estimator_mid_blocks_9_1_3_ff_net_2,
            decoder_estimator_mid_blocks_9_1_3_norm1,
            decoder_estimator_mid_blocks_9_1_3_norm3,
            decoder_estimator_time_embeddings,
            decoder_estimator_time_mlp_act,
            decoder_estimator_time_mlp_linear_1,
            decoder_estimator_time_mlp_linear_2,
            decoder_estimator_up_blocks_0_0_block1_block_0,
            decoder_estimator_up_blocks_0_0_block1_block_1,
            decoder_estimator_up_blocks_0_0_block1_block_2,
            decoder_estimator_up_blocks_0_0_block1_block_3,
            decoder_estimator_up_blocks_0_0_block1_block_4,
            decoder_estimator_up_blocks_0_0_block2_block_0,
            decoder_estimator_up_blocks_0_0_block2_block_1,
            decoder_estimator_up_blocks_0_0_block2_block_2,
            decoder_estimator_up_blocks_0_0_block2_block_3,
            decoder_estimator_up_blocks_0_0_block2_block_4,
            decoder_estimator_up_blocks_0_0_mlp_0,
            decoder_estimator_up_blocks_0_0_mlp_1,
            decoder_estimator_up_blocks_0_0_res_conv,
            decoder_estimator_up_blocks_0_1_0_attn1_to_k,
            decoder_estimator_up_blocks_0_1_0_attn1_to_out_0,
            decoder_estimator_up_blocks_0_1_0_attn1_to_out_1,
            decoder_estimator_up_blocks_0_1_0_attn1_to_q,
            decoder_estimator_up_blocks_0_1_0_attn1_to_v,
            decoder_estimator_up_blocks_0_1_0_ff_net_0_proj,
            decoder_estimator_up_blocks_0_1_0_ff_net_1,
            decoder_estimator_up_blocks_0_1_0_ff_net_2,
            decoder_estimator_up_blocks_0_1_0_norm1,
            decoder_estimator_up_blocks_0_1_0_norm3,
            decoder_estimator_up_blocks_0_1_1_attn1_to_k,
            decoder_estimator_up_blocks_0_1_1_attn1_to_out_0,
            decoder_estimator_up_blocks_0_1_1_attn1_to_out_1,
            decoder_estimator_up_blocks_0_1_1_attn1_to_q,
            decoder_estimator_up_blocks_0_1_1_attn1_to_v,
            decoder_estimator_up_blocks_0_1_1_ff_net_0_proj,
            decoder_estimator_up_blocks_0_1_1_ff_net_1,
            decoder_estimator_up_blocks_0_1_1_ff_net_2,
            decoder_estimator_up_blocks_0_1_1_norm1,
            decoder_estimator_up_blocks_0_1_1_norm3,
            decoder_estimator_up_blocks_0_1_2_attn1_to_k,
            decoder_estimator_up_blocks_0_1_2_attn1_to_out_0,
            decoder_estimator_up_blocks_0_1_2_attn1_to_out_1,
            decoder_estimator_up_blocks_0_1_2_attn1_to_q,
            decoder_estimator_up_blocks_0_1_2_attn1_to_v,
            decoder_estimator_up_blocks_0_1_2_ff_net_0_proj,
            decoder_estimator_up_blocks_0_1_2_ff_net_1,
            decoder_estimator_up_blocks_0_1_2_ff_net_2,
            decoder_estimator_up_blocks_0_1_2_norm1,
            decoder_estimator_up_blocks_0_1_2_norm3,
            decoder_estimator_up_blocks_0_1_3_attn1_to_k,
            decoder_estimator_up_blocks_0_1_3_attn1_to_out_0,
            decoder_estimator_up_blocks_0_1_3_attn1_to_out_1,
            decoder_estimator_up_blocks_0_1_3_attn1_to_q,
            decoder_estimator_up_blocks_0_1_3_attn1_to_v,
            decoder_estimator_up_blocks_0_1_3_ff_net_0_proj,
            decoder_estimator_up_blocks_0_1_3_ff_net_1,
            decoder_estimator_up_blocks_0_1_3_ff_net_2,
            decoder_estimator_up_blocks_0_1_3_norm1,
            decoder_estimator_up_blocks_0_1_3_norm3,
            decoder_estimator_up_blocks_0_2,
            encoder_after_norm,
            encoder_embed_out_0,
            encoder_embed_out_1,
            encoder_embed_out_2,
            encoder_embed_pos_enc_dropout,
            encoder_embed_pos_enc_dropout_1,
            encoder_encoders_0_dropout,
            encoder_encoders_0_dropout_1,
            encoder_encoders_0_feed_forward_activation,
            encoder_encoders_0_feed_forward_activation_1,
            encoder_encoders_0_feed_forward_activation_2,
            encoder_encoders_0_feed_forward_activation_3,
            encoder_encoders_0_feed_forward_activation_4,
            encoder_encoders_0_feed_forward_activation_5,
            encoder_encoders_0_feed_forward_activation_6,
            encoder_encoders_0_feed_forward_activation_7,
            encoder_encoders_0_feed_forward_activation_8,
            encoder_encoders_0_feed_forward_activation_9,
            encoder_encoders_0_feed_forward_dropout,
            encoder_encoders_0_feed_forward_w_1,
            encoder_encoders_0_feed_forward_w_2,
            encoder_encoders_0_norm_ff,
            encoder_encoders_0_norm_mha,
            encoder_encoders_0_self_attn_dropout,
            encoder_encoders_0_self_attn_linear_k,
            encoder_encoders_0_self_attn_linear_out,
            encoder_encoders_0_self_attn_linear_pos,
            encoder_encoders_0_self_attn_linear_q,
            encoder_encoders_0_self_attn_linear_v,
            encoder_encoders_1_dropout,
            encoder_encoders_1_dropout_1,
            encoder_encoders_1_feed_forward_dropout,
            encoder_encoders_1_feed_forward_w_1,
            encoder_encoders_1_feed_forward_w_2,
            encoder_encoders_1_norm_ff,
            encoder_encoders_1_norm_mha,
            encoder_encoders_1_self_attn_dropout,
            encoder_encoders_1_self_attn_linear_k,
            encoder_encoders_1_self_attn_linear_out,
            encoder_encoders_1_self_attn_linear_pos,
            encoder_encoders_1_self_attn_linear_q,
            encoder_encoders_1_self_attn_linear_v,
            encoder_encoders_2_dropout,
            encoder_encoders_2_dropout_1,
            encoder_encoders_2_feed_forward_dropout,
            encoder_encoders_2_feed_forward_w_1,
            encoder_encoders_2_feed_forward_w_2,
            encoder_encoders_2_norm_ff,
            encoder_encoders_2_norm_mha,
            encoder_encoders_2_self_attn_dropout,
            encoder_encoders_2_self_attn_linear_k,
            encoder_encoders_2_self_attn_linear_out,
            encoder_encoders_2_self_attn_linear_pos,
            encoder_encoders_2_self_attn_linear_q,
            encoder_encoders_2_self_attn_linear_v,
            encoder_encoders_3_dropout,
            encoder_encoders_3_dropout_1,
            encoder_encoders_3_feed_forward_dropout,
            encoder_encoders_3_feed_forward_w_1,
            encoder_encoders_3_feed_forward_w_2,
            encoder_encoders_3_norm_ff,
            encoder_encoders_3_norm_mha,
            encoder_encoders_3_self_attn_dropout,
            encoder_encoders_3_self_attn_linear_k,
            encoder_encoders_3_self_attn_linear_out,
            encoder_encoders_3_self_attn_linear_pos,
            encoder_encoders_3_self_attn_linear_q,
            encoder_encoders_3_self_attn_linear_v,
            encoder_encoders_4_dropout,
            encoder_encoders_4_dropout_1,
            encoder_encoders_4_feed_forward_dropout,
            encoder_encoders_4_feed_forward_w_1,
            encoder_encoders_4_feed_forward_w_2,
            encoder_encoders_4_norm_ff,
            encoder_encoders_4_norm_mha,
            encoder_encoders_4_self_attn_dropout,
            encoder_encoders_4_self_attn_linear_k,
            encoder_encoders_4_self_attn_linear_out,
            encoder_encoders_4_self_attn_linear_pos,
            encoder_encoders_4_self_attn_linear_q,
            encoder_encoders_4_self_attn_linear_v,
            encoder_encoders_5_dropout,
            encoder_encoders_5_dropout_1,
            encoder_encoders_5_feed_forward_dropout,
            encoder_encoders_5_feed_forward_w_1,
            encoder_encoders_5_feed_forward_w_2,
            encoder_encoders_5_norm_ff,
            encoder_encoders_5_norm_mha,
            encoder_encoders_5_self_attn_dropout,
            encoder_encoders_5_self_attn_linear_k,
            encoder_encoders_5_self_attn_linear_out,
            encoder_encoders_5_self_attn_linear_pos,
            encoder_encoders_5_self_attn_linear_q,
            encoder_encoders_5_self_attn_linear_v,
            encoder_pre_lookahead_layer_conv1,
            encoder_pre_lookahead_layer_conv2,
            encoder_up_embed_out_0,
            encoder_up_embed_out_1,
            encoder_up_embed_out_2,
            encoder_up_embed_pos_enc_dropout,
            encoder_up_embed_pos_enc_dropout_1,
            encoder_up_encoders_0_dropout,
            encoder_up_encoders_0_dropout_1,
            encoder_up_encoders_0_feed_forward_dropout,
            encoder_up_encoders_0_feed_forward_w_1,
            encoder_up_encoders_0_feed_forward_w_2,
            encoder_up_encoders_0_norm_ff,
            encoder_up_encoders_0_norm_mha,
            encoder_up_encoders_0_self_attn_dropout,
            encoder_up_encoders_0_self_attn_linear_k,
            encoder_up_encoders_0_self_attn_linear_out,
            encoder_up_encoders_0_self_attn_linear_pos,
            encoder_up_encoders_0_self_attn_linear_q,
            encoder_up_encoders_0_self_attn_linear_v,
            encoder_up_encoders_1_dropout,
            encoder_up_encoders_1_dropout_1,
            encoder_up_encoders_1_feed_forward_dropout,
            encoder_up_encoders_1_feed_forward_w_1,
            encoder_up_encoders_1_feed_forward_w_2,
            encoder_up_encoders_1_norm_ff,
            encoder_up_encoders_1_norm_mha,
            encoder_up_encoders_1_self_attn_dropout,
            encoder_up_encoders_1_self_attn_linear_k,
            encoder_up_encoders_1_self_attn_linear_out,
            encoder_up_encoders_1_self_attn_linear_pos,
            encoder_up_encoders_1_self_attn_linear_q,
            encoder_up_encoders_1_self_attn_linear_v,
            encoder_up_encoders_2_dropout,
            encoder_up_encoders_2_dropout_1,
            encoder_up_encoders_2_feed_forward_dropout,
            encoder_up_encoders_2_feed_forward_w_1,
            encoder_up_encoders_2_feed_forward_w_2,
            encoder_up_encoders_2_norm_ff,
            encoder_up_encoders_2_norm_mha,
            encoder_up_encoders_2_self_attn_dropout,
            encoder_up_encoders_2_self_attn_linear_k,
            encoder_up_encoders_2_self_attn_linear_out,
            encoder_up_encoders_2_self_attn_linear_pos,
            encoder_up_encoders_2_self_attn_linear_q,
            encoder_up_encoders_2_self_attn_linear_v,
            encoder_up_encoders_3_dropout,
            encoder_up_encoders_3_dropout_1,
            encoder_up_encoders_3_feed_forward_dropout,
            encoder_up_encoders_3_feed_forward_w_1,
            encoder_up_encoders_3_feed_forward_w_2,
            encoder_up_encoders_3_norm_ff,
            encoder_up_encoders_3_norm_mha,
            encoder_up_encoders_3_self_attn_dropout,
            encoder_up_encoders_3_self_attn_linear_k,
            encoder_up_encoders_3_self_attn_linear_out,
            encoder_up_encoders_3_self_attn_linear_pos,
            encoder_up_encoders_3_self_attn_linear_q,
            encoder_up_encoders_3_self_attn_linear_v,
            encoder_up_layer_conv,
            encoder_proj,
            input_embedding,
            spk_embed_affine_layer,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.0
        x = self.decoder_estimator_down_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.1
        x = self.decoder_estimator_down_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.2
        x = self.decoder_estimator_down_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.3
        x = self.decoder_estimator_down_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.4
        x = self.decoder_estimator_down_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.0
        x = self.decoder_estimator_down_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.1
        x = self.decoder_estimator_down_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.2
        x = self.decoder_estimator_down_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.3
        x = self.decoder_estimator_down_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.4
        x = self.decoder_estimator_down_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.down_blocks.0.0.mlp.0
        x = self.decoder_estimator_down_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.mlp.1
        x = self.decoder_estimator_down_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.res_conv
        x = self.decoder_estimator_down_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.norm1
        x = self.decoder_estimator_down_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.norm3
        x = self.decoder_estimator_down_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.norm1
        x = self.decoder_estimator_down_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.norm3
        x = self.decoder_estimator_down_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.norm1
        x = self.decoder_estimator_down_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.norm3
        x = self.decoder_estimator_down_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.norm1
        x = self.decoder_estimator_down_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.norm3
        x = self.decoder_estimator_down_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.2
        x = self.decoder_estimator_down_blocks_0_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.2", &x);

        // Layer: decoder.estimator.final_block.block.0
        x = self.decoder_estimator_final_block_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.0", &x);

        // Layer: decoder.estimator.final_block.block.1
        x = self.decoder_estimator_final_block_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.1", &x);

        // Layer: decoder.estimator.final_block.block.2
        x = self.decoder_estimator_final_block_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.2", &x);

        // Layer: decoder.estimator.final_block.block.3
        x = self.decoder_estimator_final_block_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.3", &x);

        // Layer: decoder.estimator.final_block.block.4
        x = self.decoder_estimator_final_block_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.4", &x);

        // Layer: decoder.estimator.final_proj
        x = self.decoder_estimator_final_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.mlp.0
        x = self.decoder_estimator_mid_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.mlp.1
        x = self.decoder_estimator_mid_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.res_conv
        x = self.decoder_estimator_mid_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.norm1
        x = self.decoder_estimator_mid_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.norm3
        x = self.decoder_estimator_mid_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.norm1
        x = self.decoder_estimator_mid_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.norm3
        x = self.decoder_estimator_mid_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.norm1
        x = self.decoder_estimator_mid_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.norm3
        x = self.decoder_estimator_mid_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.norm1
        x = self.decoder_estimator_mid_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.norm3
        x = self.decoder_estimator_mid_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.mlp.0
        x = self.decoder_estimator_mid_blocks_1_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.mlp.1
        x = self.decoder_estimator_mid_blocks_1_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.res_conv
        x = self.decoder_estimator_mid_blocks_1_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.norm1
        x = self.decoder_estimator_mid_blocks_1_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.norm3
        x = self.decoder_estimator_mid_blocks_1_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.norm1
        x = self.decoder_estimator_mid_blocks_1_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.norm3
        x = self.decoder_estimator_mid_blocks_1_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.norm1
        x = self.decoder_estimator_mid_blocks_1_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.norm3
        x = self.decoder_estimator_mid_blocks_1_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.norm1
        x = self.decoder_estimator_mid_blocks_1_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.norm3
        x = self.decoder_estimator_mid_blocks_1_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.mlp.0
        x = self.decoder_estimator_mid_blocks_10_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.mlp.1
        x = self.decoder_estimator_mid_blocks_10_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.res_conv
        x = self.decoder_estimator_mid_blocks_10_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.norm1
        x = self.decoder_estimator_mid_blocks_10_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.norm3
        x = self.decoder_estimator_mid_blocks_10_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.norm1
        x = self.decoder_estimator_mid_blocks_10_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.norm3
        x = self.decoder_estimator_mid_blocks_10_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.norm1
        x = self.decoder_estimator_mid_blocks_10_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.norm3
        x = self.decoder_estimator_mid_blocks_10_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.norm1
        x = self.decoder_estimator_mid_blocks_10_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.norm3
        x = self.decoder_estimator_mid_blocks_10_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.mlp.0
        x = self.decoder_estimator_mid_blocks_11_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.mlp.1
        x = self.decoder_estimator_mid_blocks_11_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.res_conv
        x = self.decoder_estimator_mid_blocks_11_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.norm1
        x = self.decoder_estimator_mid_blocks_11_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.norm3
        x = self.decoder_estimator_mid_blocks_11_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.norm1
        x = self.decoder_estimator_mid_blocks_11_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.norm3
        x = self.decoder_estimator_mid_blocks_11_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.norm1
        x = self.decoder_estimator_mid_blocks_11_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.norm3
        x = self.decoder_estimator_mid_blocks_11_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.norm1
        x = self.decoder_estimator_mid_blocks_11_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.norm3
        x = self.decoder_estimator_mid_blocks_11_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.mlp.0
        x = self.decoder_estimator_mid_blocks_2_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.mlp.1
        x = self.decoder_estimator_mid_blocks_2_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.res_conv
        x = self.decoder_estimator_mid_blocks_2_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.norm1
        x = self.decoder_estimator_mid_blocks_2_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.norm3
        x = self.decoder_estimator_mid_blocks_2_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.norm1
        x = self.decoder_estimator_mid_blocks_2_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.norm3
        x = self.decoder_estimator_mid_blocks_2_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.norm1
        x = self.decoder_estimator_mid_blocks_2_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.norm3
        x = self.decoder_estimator_mid_blocks_2_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.norm1
        x = self.decoder_estimator_mid_blocks_2_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.norm3
        x = self.decoder_estimator_mid_blocks_2_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.mlp.0
        x = self.decoder_estimator_mid_blocks_3_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.mlp.1
        x = self.decoder_estimator_mid_blocks_3_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.res_conv
        x = self.decoder_estimator_mid_blocks_3_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.norm1
        x = self.decoder_estimator_mid_blocks_3_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.norm3
        x = self.decoder_estimator_mid_blocks_3_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.norm1
        x = self.decoder_estimator_mid_blocks_3_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.norm3
        x = self.decoder_estimator_mid_blocks_3_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.norm1
        x = self.decoder_estimator_mid_blocks_3_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.norm3
        x = self.decoder_estimator_mid_blocks_3_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.norm1
        x = self.decoder_estimator_mid_blocks_3_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.norm3
        x = self.decoder_estimator_mid_blocks_3_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.mlp.0
        x = self.decoder_estimator_mid_blocks_4_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.mlp.1
        x = self.decoder_estimator_mid_blocks_4_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.res_conv
        x = self.decoder_estimator_mid_blocks_4_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.norm1
        x = self.decoder_estimator_mid_blocks_4_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.norm3
        x = self.decoder_estimator_mid_blocks_4_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.norm1
        x = self.decoder_estimator_mid_blocks_4_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.norm3
        x = self.decoder_estimator_mid_blocks_4_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.norm1
        x = self.decoder_estimator_mid_blocks_4_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.norm3
        x = self.decoder_estimator_mid_blocks_4_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.norm1
        x = self.decoder_estimator_mid_blocks_4_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.norm3
        x = self.decoder_estimator_mid_blocks_4_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.mlp.0
        x = self.decoder_estimator_mid_blocks_5_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.mlp.1
        x = self.decoder_estimator_mid_blocks_5_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.res_conv
        x = self.decoder_estimator_mid_blocks_5_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.norm1
        x = self.decoder_estimator_mid_blocks_5_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.norm3
        x = self.decoder_estimator_mid_blocks_5_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.norm1
        x = self.decoder_estimator_mid_blocks_5_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.norm3
        x = self.decoder_estimator_mid_blocks_5_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.norm1
        x = self.decoder_estimator_mid_blocks_5_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.norm3
        x = self.decoder_estimator_mid_blocks_5_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.norm1
        x = self.decoder_estimator_mid_blocks_5_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.norm3
        x = self.decoder_estimator_mid_blocks_5_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.mlp.0
        x = self.decoder_estimator_mid_blocks_6_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.mlp.1
        x = self.decoder_estimator_mid_blocks_6_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.res_conv
        x = self.decoder_estimator_mid_blocks_6_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.norm1
        x = self.decoder_estimator_mid_blocks_6_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.norm3
        x = self.decoder_estimator_mid_blocks_6_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.norm1
        x = self.decoder_estimator_mid_blocks_6_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.norm3
        x = self.decoder_estimator_mid_blocks_6_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.norm1
        x = self.decoder_estimator_mid_blocks_6_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.norm3
        x = self.decoder_estimator_mid_blocks_6_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.norm1
        x = self.decoder_estimator_mid_blocks_6_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.norm3
        x = self.decoder_estimator_mid_blocks_6_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.mlp.0
        x = self.decoder_estimator_mid_blocks_7_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.mlp.1
        x = self.decoder_estimator_mid_blocks_7_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.res_conv
        x = self.decoder_estimator_mid_blocks_7_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.norm1
        x = self.decoder_estimator_mid_blocks_7_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.norm3
        x = self.decoder_estimator_mid_blocks_7_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.norm1
        x = self.decoder_estimator_mid_blocks_7_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.norm3
        x = self.decoder_estimator_mid_blocks_7_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.norm1
        x = self.decoder_estimator_mid_blocks_7_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.norm3
        x = self.decoder_estimator_mid_blocks_7_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.norm1
        x = self.decoder_estimator_mid_blocks_7_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.norm3
        x = self.decoder_estimator_mid_blocks_7_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.mlp.0
        x = self.decoder_estimator_mid_blocks_8_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.mlp.1
        x = self.decoder_estimator_mid_blocks_8_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.res_conv
        x = self.decoder_estimator_mid_blocks_8_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.norm1
        x = self.decoder_estimator_mid_blocks_8_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.norm3
        x = self.decoder_estimator_mid_blocks_8_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.norm1
        x = self.decoder_estimator_mid_blocks_8_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.norm3
        x = self.decoder_estimator_mid_blocks_8_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.norm1
        x = self.decoder_estimator_mid_blocks_8_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.norm3
        x = self.decoder_estimator_mid_blocks_8_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.norm1
        x = self.decoder_estimator_mid_blocks_8_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.norm3
        x = self.decoder_estimator_mid_blocks_8_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.mlp.0
        x = self.decoder_estimator_mid_blocks_9_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.mlp.1
        x = self.decoder_estimator_mid_blocks_9_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.res_conv
        x = self.decoder_estimator_mid_blocks_9_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.norm1
        x = self.decoder_estimator_mid_blocks_9_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.norm3
        x = self.decoder_estimator_mid_blocks_9_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.norm1
        x = self.decoder_estimator_mid_blocks_9_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.norm3
        x = self.decoder_estimator_mid_blocks_9_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.norm1
        x = self.decoder_estimator_mid_blocks_9_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.norm3
        x = self.decoder_estimator_mid_blocks_9_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.norm1
        x = self.decoder_estimator_mid_blocks_9_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.norm3
        x = self.decoder_estimator_mid_blocks_9_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.norm3", &x);

        // Layer: decoder.estimator.time_embeddings
        x = self.decoder_estimator_time_embeddings.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_embeddings", &x);

        // Layer: decoder.estimator.time_mlp.act
        x = self.decoder_estimator_time_mlp_act.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.act", &x);

        // Layer: decoder.estimator.time_mlp.linear_1
        x = self.decoder_estimator_time_mlp_linear_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.linear_1", &x);

        // Layer: decoder.estimator.time_mlp.linear_2
        x = self.decoder_estimator_time_mlp_linear_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.linear_2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.0
        x = self.decoder_estimator_up_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.1
        x = self.decoder_estimator_up_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.2
        x = self.decoder_estimator_up_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.3
        x = self.decoder_estimator_up_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.4
        x = self.decoder_estimator_up_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.0
        x = self.decoder_estimator_up_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.1
        x = self.decoder_estimator_up_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.2
        x = self.decoder_estimator_up_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.3
        x = self.decoder_estimator_up_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.4
        x = self.decoder_estimator_up_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.up_blocks.0.0.mlp.0
        x = self.decoder_estimator_up_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.mlp.1
        x = self.decoder_estimator_up_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.res_conv
        x = self.decoder_estimator_up_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.norm1
        x = self.decoder_estimator_up_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.norm3
        x = self.decoder_estimator_up_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.norm1
        x = self.decoder_estimator_up_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.norm3
        x = self.decoder_estimator_up_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.norm1
        x = self.decoder_estimator_up_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.norm3
        x = self.decoder_estimator_up_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.norm1
        x = self.decoder_estimator_up_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.norm3
        x = self.decoder_estimator_up_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.2
        x = self.decoder_estimator_up_blocks_0_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.2", &x);

        // Layer: encoder.after_norm
        x = self.encoder_after_norm.forward(&x)?;
        py_check!(self.checker, "encoder.after_norm", &x);

        // Layer: encoder.embed.out.0
        x = self.encoder_embed_out_0.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.0", &x);

        // Layer: encoder.embed.out.1
        x = self.encoder_embed_out_1.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.1", &x);

        // Layer: encoder.embed.out.2
        x = self.encoder_embed_out_2.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.2", &x);

        // Layer: encoder.embed.pos_enc.dropout
        x = self.encoder_embed_pos_enc_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.embed.pos_enc.dropout", &x);

        // Layer: encoder.embed.pos_enc.dropout.1
        x = self.encoder_embed_pos_enc_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.embed.pos_enc.dropout.1", &x);

        // Layer: encoder.encoders.0.dropout
        x = self.encoder_encoders_0_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.dropout", &x);

        // Layer: encoder.encoders.0.dropout.1
        x = self.encoder_encoders_0_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.dropout.1", &x);

        // Layer: encoder.encoders.0.feed_forward.activation
        x = self.encoder_encoders_0_feed_forward_activation.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.1
        x = self.encoder_encoders_0_feed_forward_activation_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.1", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.2
        x = self.encoder_encoders_0_feed_forward_activation_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.2", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.3
        x = self.encoder_encoders_0_feed_forward_activation_3.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.3", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.4
        x = self.encoder_encoders_0_feed_forward_activation_4.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.4", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.5
        x = self.encoder_encoders_0_feed_forward_activation_5.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.5", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.6
        x = self.encoder_encoders_0_feed_forward_activation_6.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.6", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.7
        x = self.encoder_encoders_0_feed_forward_activation_7.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.7", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.8
        x = self.encoder_encoders_0_feed_forward_activation_8.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.8", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.9
        x = self.encoder_encoders_0_feed_forward_activation_9.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.9", &x);

        // Layer: encoder.encoders.0.feed_forward.dropout
        x = self.encoder_encoders_0_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.dropout", &x);

        // Layer: encoder.encoders.0.feed_forward.w_1
        x = self.encoder_encoders_0_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.w_1", &x);

        // Layer: encoder.encoders.0.feed_forward.w_2
        x = self.encoder_encoders_0_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.w_2", &x);

        // Layer: encoder.encoders.0.norm_ff
        x = self.encoder_encoders_0_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.norm_ff", &x);

        // Layer: encoder.encoders.0.norm_mha
        x = self.encoder_encoders_0_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.norm_mha", &x);

        // Layer: encoder.encoders.0.self_attn.dropout
        x = self.encoder_encoders_0_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.dropout", &x);

        // Layer: encoder.encoders.0.self_attn.linear_k
        x = self.encoder_encoders_0_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_k", &x);

        // Layer: encoder.encoders.0.self_attn.linear_out
        x = self.encoder_encoders_0_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_out", &x);

        // Layer: encoder.encoders.0.self_attn.linear_pos
        x = self.encoder_encoders_0_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.0.self_attn.linear_q
        x = self.encoder_encoders_0_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_q", &x);

        // Layer: encoder.encoders.0.self_attn.linear_v
        x = self.encoder_encoders_0_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_v", &x);

        // Layer: encoder.encoders.1.dropout
        x = self.encoder_encoders_1_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.dropout", &x);

        // Layer: encoder.encoders.1.dropout.1
        x = self.encoder_encoders_1_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.dropout.1", &x);

        // Layer: encoder.encoders.1.feed_forward.dropout
        x = self.encoder_encoders_1_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.dropout", &x);

        // Layer: encoder.encoders.1.feed_forward.w_1
        x = self.encoder_encoders_1_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.w_1", &x);

        // Layer: encoder.encoders.1.feed_forward.w_2
        x = self.encoder_encoders_1_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.w_2", &x);

        // Layer: encoder.encoders.1.norm_ff
        x = self.encoder_encoders_1_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.norm_ff", &x);

        // Layer: encoder.encoders.1.norm_mha
        x = self.encoder_encoders_1_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.norm_mha", &x);

        // Layer: encoder.encoders.1.self_attn.dropout
        x = self.encoder_encoders_1_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.dropout", &x);

        // Layer: encoder.encoders.1.self_attn.linear_k
        x = self.encoder_encoders_1_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_k", &x);

        // Layer: encoder.encoders.1.self_attn.linear_out
        x = self.encoder_encoders_1_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_out", &x);

        // Layer: encoder.encoders.1.self_attn.linear_pos
        x = self.encoder_encoders_1_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.1.self_attn.linear_q
        x = self.encoder_encoders_1_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_q", &x);

        // Layer: encoder.encoders.1.self_attn.linear_v
        x = self.encoder_encoders_1_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_v", &x);

        // Layer: encoder.encoders.2.dropout
        x = self.encoder_encoders_2_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.dropout", &x);

        // Layer: encoder.encoders.2.dropout.1
        x = self.encoder_encoders_2_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.dropout.1", &x);

        // Layer: encoder.encoders.2.feed_forward.dropout
        x = self.encoder_encoders_2_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.dropout", &x);

        // Layer: encoder.encoders.2.feed_forward.w_1
        x = self.encoder_encoders_2_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.w_1", &x);

        // Layer: encoder.encoders.2.feed_forward.w_2
        x = self.encoder_encoders_2_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.w_2", &x);

        // Layer: encoder.encoders.2.norm_ff
        x = self.encoder_encoders_2_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.norm_ff", &x);

        // Layer: encoder.encoders.2.norm_mha
        x = self.encoder_encoders_2_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.norm_mha", &x);

        // Layer: encoder.encoders.2.self_attn.dropout
        x = self.encoder_encoders_2_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.dropout", &x);

        // Layer: encoder.encoders.2.self_attn.linear_k
        x = self.encoder_encoders_2_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_k", &x);

        // Layer: encoder.encoders.2.self_attn.linear_out
        x = self.encoder_encoders_2_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_out", &x);

        // Layer: encoder.encoders.2.self_attn.linear_pos
        x = self.encoder_encoders_2_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.2.self_attn.linear_q
        x = self.encoder_encoders_2_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_q", &x);

        // Layer: encoder.encoders.2.self_attn.linear_v
        x = self.encoder_encoders_2_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_v", &x);

        // Layer: encoder.encoders.3.dropout
        x = self.encoder_encoders_3_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.dropout", &x);

        // Layer: encoder.encoders.3.dropout.1
        x = self.encoder_encoders_3_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.dropout.1", &x);

        // Layer: encoder.encoders.3.feed_forward.dropout
        x = self.encoder_encoders_3_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.dropout", &x);

        // Layer: encoder.encoders.3.feed_forward.w_1
        x = self.encoder_encoders_3_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.w_1", &x);

        // Layer: encoder.encoders.3.feed_forward.w_2
        x = self.encoder_encoders_3_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.w_2", &x);

        // Layer: encoder.encoders.3.norm_ff
        x = self.encoder_encoders_3_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.norm_ff", &x);

        // Layer: encoder.encoders.3.norm_mha
        x = self.encoder_encoders_3_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.norm_mha", &x);

        // Layer: encoder.encoders.3.self_attn.dropout
        x = self.encoder_encoders_3_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.dropout", &x);

        // Layer: encoder.encoders.3.self_attn.linear_k
        x = self.encoder_encoders_3_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_k", &x);

        // Layer: encoder.encoders.3.self_attn.linear_out
        x = self.encoder_encoders_3_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_out", &x);

        // Layer: encoder.encoders.3.self_attn.linear_pos
        x = self.encoder_encoders_3_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.3.self_attn.linear_q
        x = self.encoder_encoders_3_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_q", &x);

        // Layer: encoder.encoders.3.self_attn.linear_v
        x = self.encoder_encoders_3_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_v", &x);

        // Layer: encoder.encoders.4.dropout
        x = self.encoder_encoders_4_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.dropout", &x);

        // Layer: encoder.encoders.4.dropout.1
        x = self.encoder_encoders_4_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.dropout.1", &x);

        // Layer: encoder.encoders.4.feed_forward.dropout
        x = self.encoder_encoders_4_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.dropout", &x);

        // Layer: encoder.encoders.4.feed_forward.w_1
        x = self.encoder_encoders_4_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.w_1", &x);

        // Layer: encoder.encoders.4.feed_forward.w_2
        x = self.encoder_encoders_4_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.w_2", &x);

        // Layer: encoder.encoders.4.norm_ff
        x = self.encoder_encoders_4_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.norm_ff", &x);

        // Layer: encoder.encoders.4.norm_mha
        x = self.encoder_encoders_4_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.norm_mha", &x);

        // Layer: encoder.encoders.4.self_attn.dropout
        x = self.encoder_encoders_4_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.dropout", &x);

        // Layer: encoder.encoders.4.self_attn.linear_k
        x = self.encoder_encoders_4_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_k", &x);

        // Layer: encoder.encoders.4.self_attn.linear_out
        x = self.encoder_encoders_4_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_out", &x);

        // Layer: encoder.encoders.4.self_attn.linear_pos
        x = self.encoder_encoders_4_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.4.self_attn.linear_q
        x = self.encoder_encoders_4_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_q", &x);

        // Layer: encoder.encoders.4.self_attn.linear_v
        x = self.encoder_encoders_4_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_v", &x);

        // Layer: encoder.encoders.5.dropout
        x = self.encoder_encoders_5_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.dropout", &x);

        // Layer: encoder.encoders.5.dropout.1
        x = self.encoder_encoders_5_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.dropout.1", &x);

        // Layer: encoder.encoders.5.feed_forward.dropout
        x = self.encoder_encoders_5_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.dropout", &x);

        // Layer: encoder.encoders.5.feed_forward.w_1
        x = self.encoder_encoders_5_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.w_1", &x);

        // Layer: encoder.encoders.5.feed_forward.w_2
        x = self.encoder_encoders_5_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.w_2", &x);

        // Layer: encoder.encoders.5.norm_ff
        x = self.encoder_encoders_5_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.norm_ff", &x);

        // Layer: encoder.encoders.5.norm_mha
        x = self.encoder_encoders_5_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.norm_mha", &x);

        // Layer: encoder.encoders.5.self_attn.dropout
        x = self.encoder_encoders_5_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.dropout", &x);

        // Layer: encoder.encoders.5.self_attn.linear_k
        x = self.encoder_encoders_5_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_k", &x);

        // Layer: encoder.encoders.5.self_attn.linear_out
        x = self.encoder_encoders_5_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_out", &x);

        // Layer: encoder.encoders.5.self_attn.linear_pos
        x = self.encoder_encoders_5_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.5.self_attn.linear_q
        x = self.encoder_encoders_5_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_q", &x);

        // Layer: encoder.encoders.5.self_attn.linear_v
        x = self.encoder_encoders_5_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_v", &x);

        // Layer: encoder.pre_lookahead_layer.conv1
        x = self.encoder_pre_lookahead_layer_conv1.forward(&x)?;
        py_check!(self.checker, "encoder.pre_lookahead_layer.conv1", &x);

        // Layer: encoder.pre_lookahead_layer.conv2
        x = self.encoder_pre_lookahead_layer_conv2.forward(&x)?;
        py_check!(self.checker, "encoder.pre_lookahead_layer.conv2", &x);

        // Layer: encoder.up_embed.out.0
        x = self.encoder_up_embed_out_0.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.0", &x);

        // Layer: encoder.up_embed.out.1
        x = self.encoder_up_embed_out_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.1", &x);

        // Layer: encoder.up_embed.out.2
        x = self.encoder_up_embed_out_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.2", &x);

        // Layer: encoder.up_embed.pos_enc.dropout
        x = self.encoder_up_embed_pos_enc_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.pos_enc.dropout", &x);

        // Layer: encoder.up_embed.pos_enc.dropout.1
        x = self.encoder_up_embed_pos_enc_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.pos_enc.dropout.1", &x);

        // Layer: encoder.up_encoders.0.dropout
        x = self.encoder_up_encoders_0_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.dropout", &x);

        // Layer: encoder.up_encoders.0.dropout.1
        x = self.encoder_up_encoders_0_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.dropout.1", &x);

        // Layer: encoder.up_encoders.0.feed_forward.dropout
        x = self.encoder_up_encoders_0_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.0.feed_forward.w_1
        x = self.encoder_up_encoders_0_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.0.feed_forward.w_2
        x = self.encoder_up_encoders_0_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.0.norm_ff
        x = self.encoder_up_encoders_0_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.norm_ff", &x);

        // Layer: encoder.up_encoders.0.norm_mha
        x = self.encoder_up_encoders_0_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.norm_mha", &x);

        // Layer: encoder.up_encoders.0.self_attn.dropout
        x = self.encoder_up_encoders_0_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_k
        x = self.encoder_up_encoders_0_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_out
        x = self.encoder_up_encoders_0_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_pos
        x = self.encoder_up_encoders_0_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_q
        x = self.encoder_up_encoders_0_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_v
        x = self.encoder_up_encoders_0_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.1.dropout
        x = self.encoder_up_encoders_1_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.dropout", &x);

        // Layer: encoder.up_encoders.1.dropout.1
        x = self.encoder_up_encoders_1_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.dropout.1", &x);

        // Layer: encoder.up_encoders.1.feed_forward.dropout
        x = self.encoder_up_encoders_1_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.1.feed_forward.w_1
        x = self.encoder_up_encoders_1_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.1.feed_forward.w_2
        x = self.encoder_up_encoders_1_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.1.norm_ff
        x = self.encoder_up_encoders_1_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.norm_ff", &x);

        // Layer: encoder.up_encoders.1.norm_mha
        x = self.encoder_up_encoders_1_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.norm_mha", &x);

        // Layer: encoder.up_encoders.1.self_attn.dropout
        x = self.encoder_up_encoders_1_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_k
        x = self.encoder_up_encoders_1_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_out
        x = self.encoder_up_encoders_1_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_pos
        x = self.encoder_up_encoders_1_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_q
        x = self.encoder_up_encoders_1_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_v
        x = self.encoder_up_encoders_1_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.2.dropout
        x = self.encoder_up_encoders_2_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.dropout", &x);

        // Layer: encoder.up_encoders.2.dropout.1
        x = self.encoder_up_encoders_2_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.dropout.1", &x);

        // Layer: encoder.up_encoders.2.feed_forward.dropout
        x = self.encoder_up_encoders_2_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.2.feed_forward.w_1
        x = self.encoder_up_encoders_2_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.2.feed_forward.w_2
        x = self.encoder_up_encoders_2_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.2.norm_ff
        x = self.encoder_up_encoders_2_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.norm_ff", &x);

        // Layer: encoder.up_encoders.2.norm_mha
        x = self.encoder_up_encoders_2_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.norm_mha", &x);

        // Layer: encoder.up_encoders.2.self_attn.dropout
        x = self.encoder_up_encoders_2_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_k
        x = self.encoder_up_encoders_2_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_out
        x = self.encoder_up_encoders_2_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_pos
        x = self.encoder_up_encoders_2_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_q
        x = self.encoder_up_encoders_2_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_v
        x = self.encoder_up_encoders_2_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.3.dropout
        x = self.encoder_up_encoders_3_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.dropout", &x);

        // Layer: encoder.up_encoders.3.dropout.1
        x = self.encoder_up_encoders_3_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.dropout.1", &x);

        // Layer: encoder.up_encoders.3.feed_forward.dropout
        x = self.encoder_up_encoders_3_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.3.feed_forward.w_1
        x = self.encoder_up_encoders_3_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.3.feed_forward.w_2
        x = self.encoder_up_encoders_3_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.3.norm_ff
        x = self.encoder_up_encoders_3_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.norm_ff", &x);

        // Layer: encoder.up_encoders.3.norm_mha
        x = self.encoder_up_encoders_3_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.norm_mha", &x);

        // Layer: encoder.up_encoders.3.self_attn.dropout
        x = self.encoder_up_encoders_3_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_k
        x = self.encoder_up_encoders_3_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_out
        x = self.encoder_up_encoders_3_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_pos
        x = self.encoder_up_encoders_3_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_q
        x = self.encoder_up_encoders_3_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_v
        x = self.encoder_up_encoders_3_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_v", &x);

        // Layer: encoder.up_layer.conv
        x = self.encoder_up_layer_conv.forward(&x)?;
        py_check!(self.checker, "encoder.up_layer.conv", &x);

        // Layer: encoder_proj
        x = self.encoder_proj.forward(&x)?;
        py_check!(self.checker, "encoder_proj", &x);

        // Layer: input_embedding
        x = self.input_embedding.forward(&x)?;
        py_check!(self.checker, "input_embedding", &x);

        // Layer: spk_embed_affine_layer
        x = self.spk_embed_affine_layer.forward(&x)?;
        py_check!(self.checker, "spk_embed_affine_layer", &x);

        Ok(x)
    }
}
</file>

<file path="dx_simulation/src/generated_t3_meta.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};
use pycandle_core::gpt2;

pub struct MyModel {
    pub drop: Dropout,
    pub h_0_attn_c_attn: Linear,
    pub h_0_attn_c_proj: Linear,
    pub h_0_attn_resid_dropout: Dropout,
    pub h_0_ln_1: LayerNorm,
    pub h_0_ln_2: LayerNorm,
    pub h_0_mlp_act: candle_nn::Activation,
    pub h_0_mlp_c_fc: Linear,
    pub h_0_mlp_c_proj: Linear,
    pub h_0_mlp_dropout: Dropout,
    pub h_1_attn_c_attn: Linear,
    pub h_1_attn_c_proj: Linear,
    pub h_1_attn_resid_dropout: Dropout,
    pub h_1_ln_1: LayerNorm,
    pub h_1_ln_2: LayerNorm,
    pub h_1_mlp_act: candle_nn::Activation,
    pub h_1_mlp_c_fc: Linear,
    pub h_1_mlp_c_proj: Linear,
    pub h_1_mlp_dropout: Dropout,
    pub h_10_attn_c_attn: Linear,
    pub h_10_attn_c_proj: Linear,
    pub h_10_attn_resid_dropout: Dropout,
    pub h_10_ln_1: LayerNorm,
    pub h_10_ln_2: LayerNorm,
    pub h_10_mlp_act: candle_nn::Activation,
    pub h_10_mlp_c_fc: Linear,
    pub h_10_mlp_c_proj: Linear,
    pub h_10_mlp_dropout: Dropout,
    pub h_11_attn_c_attn: Linear,
    pub h_11_attn_c_proj: Linear,
    pub h_11_attn_resid_dropout: Dropout,
    pub h_11_ln_1: LayerNorm,
    pub h_11_ln_2: LayerNorm,
    pub h_11_mlp_act: candle_nn::Activation,
    pub h_11_mlp_c_fc: Linear,
    pub h_11_mlp_c_proj: Linear,
    pub h_11_mlp_dropout: Dropout,
    pub h_12_attn_c_attn: Linear,
    pub h_12_attn_c_proj: Linear,
    pub h_12_attn_resid_dropout: Dropout,
    pub h_12_ln_1: LayerNorm,
    pub h_12_ln_2: LayerNorm,
    pub h_12_mlp_act: candle_nn::Activation,
    pub h_12_mlp_c_fc: Linear,
    pub h_12_mlp_c_proj: Linear,
    pub h_12_mlp_dropout: Dropout,
    pub h_13_attn_c_attn: Linear,
    pub h_13_attn_c_proj: Linear,
    pub h_13_attn_resid_dropout: Dropout,
    pub h_13_ln_1: LayerNorm,
    pub h_13_ln_2: LayerNorm,
    pub h_13_mlp_act: candle_nn::Activation,
    pub h_13_mlp_c_fc: Linear,
    pub h_13_mlp_c_proj: Linear,
    pub h_13_mlp_dropout: Dropout,
    pub h_14_attn_c_attn: Linear,
    pub h_14_attn_c_proj: Linear,
    pub h_14_attn_resid_dropout: Dropout,
    pub h_14_ln_1: LayerNorm,
    pub h_14_ln_2: LayerNorm,
    pub h_14_mlp_act: candle_nn::Activation,
    pub h_14_mlp_c_fc: Linear,
    pub h_14_mlp_c_proj: Linear,
    pub h_14_mlp_dropout: Dropout,
    pub h_15_attn_c_attn: Linear,
    pub h_15_attn_c_proj: Linear,
    pub h_15_attn_resid_dropout: Dropout,
    pub h_15_ln_1: LayerNorm,
    pub h_15_ln_2: LayerNorm,
    pub h_15_mlp_act: candle_nn::Activation,
    pub h_15_mlp_c_fc: Linear,
    pub h_15_mlp_c_proj: Linear,
    pub h_15_mlp_dropout: Dropout,
    pub h_16_attn_c_attn: Linear,
    pub h_16_attn_c_proj: Linear,
    pub h_16_attn_resid_dropout: Dropout,
    pub h_16_ln_1: LayerNorm,
    pub h_16_ln_2: LayerNorm,
    pub h_16_mlp_act: candle_nn::Activation,
    pub h_16_mlp_c_fc: Linear,
    pub h_16_mlp_c_proj: Linear,
    pub h_16_mlp_dropout: Dropout,
    pub h_17_attn_c_attn: Linear,
    pub h_17_attn_c_proj: Linear,
    pub h_17_attn_resid_dropout: Dropout,
    pub h_17_ln_1: LayerNorm,
    pub h_17_ln_2: LayerNorm,
    pub h_17_mlp_act: candle_nn::Activation,
    pub h_17_mlp_c_fc: Linear,
    pub h_17_mlp_c_proj: Linear,
    pub h_17_mlp_dropout: Dropout,
    pub h_18_attn_c_attn: Linear,
    pub h_18_attn_c_proj: Linear,
    pub h_18_attn_resid_dropout: Dropout,
    pub h_18_ln_1: LayerNorm,
    pub h_18_ln_2: LayerNorm,
    pub h_18_mlp_act: candle_nn::Activation,
    pub h_18_mlp_c_fc: Linear,
    pub h_18_mlp_c_proj: Linear,
    pub h_18_mlp_dropout: Dropout,
    pub h_19_attn_c_attn: Linear,
    pub h_19_attn_c_proj: Linear,
    pub h_19_attn_resid_dropout: Dropout,
    pub h_19_ln_1: LayerNorm,
    pub h_19_ln_2: LayerNorm,
    pub h_19_mlp_act: candle_nn::Activation,
    pub h_19_mlp_c_fc: Linear,
    pub h_19_mlp_c_proj: Linear,
    pub h_19_mlp_dropout: Dropout,
    pub h_2_attn_c_attn: Linear,
    pub h_2_attn_c_proj: Linear,
    pub h_2_attn_resid_dropout: Dropout,
    pub h_2_ln_1: LayerNorm,
    pub h_2_ln_2: LayerNorm,
    pub h_2_mlp_act: candle_nn::Activation,
    pub h_2_mlp_c_fc: Linear,
    pub h_2_mlp_c_proj: Linear,
    pub h_2_mlp_dropout: Dropout,
    pub h_20_attn_c_attn: Linear,
    pub h_20_attn_c_proj: Linear,
    pub h_20_attn_resid_dropout: Dropout,
    pub h_20_ln_1: LayerNorm,
    pub h_20_ln_2: LayerNorm,
    pub h_20_mlp_act: candle_nn::Activation,
    pub h_20_mlp_c_fc: Linear,
    pub h_20_mlp_c_proj: Linear,
    pub h_20_mlp_dropout: Dropout,
    pub h_21_attn_c_attn: Linear,
    pub h_21_attn_c_proj: Linear,
    pub h_21_attn_resid_dropout: Dropout,
    pub h_21_ln_1: LayerNorm,
    pub h_21_ln_2: LayerNorm,
    pub h_21_mlp_act: candle_nn::Activation,
    pub h_21_mlp_c_fc: Linear,
    pub h_21_mlp_c_proj: Linear,
    pub h_21_mlp_dropout: Dropout,
    pub h_22_attn_c_attn: Linear,
    pub h_22_attn_c_proj: Linear,
    pub h_22_attn_resid_dropout: Dropout,
    pub h_22_ln_1: LayerNorm,
    pub h_22_ln_2: LayerNorm,
    pub h_22_mlp_act: candle_nn::Activation,
    pub h_22_mlp_c_fc: Linear,
    pub h_22_mlp_c_proj: Linear,
    pub h_22_mlp_dropout: Dropout,
    pub h_23_attn_c_attn: Linear,
    pub h_23_attn_c_proj: Linear,
    pub h_23_attn_resid_dropout: Dropout,
    pub h_23_ln_1: LayerNorm,
    pub h_23_ln_2: LayerNorm,
    pub h_23_mlp_act: candle_nn::Activation,
    pub h_23_mlp_c_fc: Linear,
    pub h_23_mlp_c_proj: Linear,
    pub h_23_mlp_dropout: Dropout,
    pub h_3_attn_c_attn: Linear,
    pub h_3_attn_c_proj: Linear,
    pub h_3_attn_resid_dropout: Dropout,
    pub h_3_ln_1: LayerNorm,
    pub h_3_ln_2: LayerNorm,
    pub h_3_mlp_act: candle_nn::Activation,
    pub h_3_mlp_c_fc: Linear,
    pub h_3_mlp_c_proj: Linear,
    pub h_3_mlp_dropout: Dropout,
    pub h_4_attn_c_attn: Linear,
    pub h_4_attn_c_proj: Linear,
    pub h_4_attn_resid_dropout: Dropout,
    pub h_4_ln_1: LayerNorm,
    pub h_4_ln_2: LayerNorm,
    pub h_4_mlp_act: candle_nn::Activation,
    pub h_4_mlp_c_fc: Linear,
    pub h_4_mlp_c_proj: Linear,
    pub h_4_mlp_dropout: Dropout,
    pub h_5_attn_c_attn: Linear,
    pub h_5_attn_c_proj: Linear,
    pub h_5_attn_resid_dropout: Dropout,
    pub h_5_ln_1: LayerNorm,
    pub h_5_ln_2: LayerNorm,
    pub h_5_mlp_act: candle_nn::Activation,
    pub h_5_mlp_c_fc: Linear,
    pub h_5_mlp_c_proj: Linear,
    pub h_5_mlp_dropout: Dropout,
    pub h_6_attn_c_attn: Linear,
    pub h_6_attn_c_proj: Linear,
    pub h_6_attn_resid_dropout: Dropout,
    pub h_6_ln_1: LayerNorm,
    pub h_6_ln_2: LayerNorm,
    pub h_6_mlp_act: candle_nn::Activation,
    pub h_6_mlp_c_fc: Linear,
    pub h_6_mlp_c_proj: Linear,
    pub h_6_mlp_dropout: Dropout,
    pub h_7_attn_c_attn: Linear,
    pub h_7_attn_c_proj: Linear,
    pub h_7_attn_resid_dropout: Dropout,
    pub h_7_ln_1: LayerNorm,
    pub h_7_ln_2: LayerNorm,
    pub h_7_mlp_act: candle_nn::Activation,
    pub h_7_mlp_c_fc: Linear,
    pub h_7_mlp_c_proj: Linear,
    pub h_7_mlp_dropout: Dropout,
    pub h_8_attn_c_attn: Linear,
    pub h_8_attn_c_proj: Linear,
    pub h_8_attn_resid_dropout: Dropout,
    pub h_8_ln_1: LayerNorm,
    pub h_8_ln_2: LayerNorm,
    pub h_8_mlp_act: candle_nn::Activation,
    pub h_8_mlp_c_fc: Linear,
    pub h_8_mlp_c_proj: Linear,
    pub h_8_mlp_dropout: Dropout,
    pub h_9_attn_c_attn: Linear,
    pub h_9_attn_c_proj: Linear,
    pub h_9_attn_resid_dropout: Dropout,
    pub h_9_ln_1: LayerNorm,
    pub h_9_ln_2: LayerNorm,
    pub h_9_mlp_act: candle_nn::Activation,
    pub h_9_mlp_c_fc: Linear,
    pub h_9_mlp_c_proj: Linear,
    pub h_9_mlp_dropout: Dropout,
    pub ln_f: LayerNorm,
    pub wpe: Embedding,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let drop = Dropout::new();
        let h_0_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.0.attn.c_attn"))?;
        let h_0_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.0.attn.c_proj"))?;
        let h_0_attn_resid_dropout = Dropout::new();
        let h_0_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_1"))?;
        let h_0_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_2"))?;
        let h_0_mlp_act = candle_nn::Activation::NewGelu;
        let h_0_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.0.mlp.c_fc"))?;
        let h_0_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.0.mlp.c_proj"))?;
        let h_0_mlp_dropout = Dropout::new();
        let h_1_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.1.attn.c_attn"))?;
        let h_1_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.1.attn.c_proj"))?;
        let h_1_attn_resid_dropout = Dropout::new();
        let h_1_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_1"))?;
        let h_1_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_2"))?;
        let h_1_mlp_act = candle_nn::Activation::NewGelu;
        let h_1_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.1.mlp.c_fc"))?;
        let h_1_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.1.mlp.c_proj"))?;
        let h_1_mlp_dropout = Dropout::new();
        let h_10_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.10.attn.c_attn"))?;
        let h_10_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.10.attn.c_proj"))?;
        let h_10_attn_resid_dropout = Dropout::new();
        let h_10_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_1"))?;
        let h_10_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_2"))?;
        let h_10_mlp_act = candle_nn::Activation::NewGelu;
        let h_10_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.10.mlp.c_fc"))?;
        let h_10_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.10.mlp.c_proj"))?;
        let h_10_mlp_dropout = Dropout::new();
        let h_11_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.11.attn.c_attn"))?;
        let h_11_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.11.attn.c_proj"))?;
        let h_11_attn_resid_dropout = Dropout::new();
        let h_11_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_1"))?;
        let h_11_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_2"))?;
        let h_11_mlp_act = candle_nn::Activation::NewGelu;
        let h_11_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.11.mlp.c_fc"))?;
        let h_11_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.11.mlp.c_proj"))?;
        let h_11_mlp_dropout = Dropout::new();
        let h_12_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.12.attn.c_attn"))?;
        let h_12_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.12.attn.c_proj"))?;
        let h_12_attn_resid_dropout = Dropout::new();
        let h_12_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_1"))?;
        let h_12_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_2"))?;
        let h_12_mlp_act = candle_nn::Activation::NewGelu;
        let h_12_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.12.mlp.c_fc"))?;
        let h_12_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.12.mlp.c_proj"))?;
        let h_12_mlp_dropout = Dropout::new();
        let h_13_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.13.attn.c_attn"))?;
        let h_13_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.13.attn.c_proj"))?;
        let h_13_attn_resid_dropout = Dropout::new();
        let h_13_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_1"))?;
        let h_13_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_2"))?;
        let h_13_mlp_act = candle_nn::Activation::NewGelu;
        let h_13_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.13.mlp.c_fc"))?;
        let h_13_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.13.mlp.c_proj"))?;
        let h_13_mlp_dropout = Dropout::new();
        let h_14_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.14.attn.c_attn"))?;
        let h_14_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.14.attn.c_proj"))?;
        let h_14_attn_resid_dropout = Dropout::new();
        let h_14_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_1"))?;
        let h_14_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_2"))?;
        let h_14_mlp_act = candle_nn::Activation::NewGelu;
        let h_14_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.14.mlp.c_fc"))?;
        let h_14_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.14.mlp.c_proj"))?;
        let h_14_mlp_dropout = Dropout::new();
        let h_15_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.15.attn.c_attn"))?;
        let h_15_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.15.attn.c_proj"))?;
        let h_15_attn_resid_dropout = Dropout::new();
        let h_15_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_1"))?;
        let h_15_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_2"))?;
        let h_15_mlp_act = candle_nn::Activation::NewGelu;
        let h_15_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.15.mlp.c_fc"))?;
        let h_15_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.15.mlp.c_proj"))?;
        let h_15_mlp_dropout = Dropout::new();
        let h_16_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.16.attn.c_attn"))?;
        let h_16_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.16.attn.c_proj"))?;
        let h_16_attn_resid_dropout = Dropout::new();
        let h_16_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_1"))?;
        let h_16_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_2"))?;
        let h_16_mlp_act = candle_nn::Activation::NewGelu;
        let h_16_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.16.mlp.c_fc"))?;
        let h_16_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.16.mlp.c_proj"))?;
        let h_16_mlp_dropout = Dropout::new();
        let h_17_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.17.attn.c_attn"))?;
        let h_17_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.17.attn.c_proj"))?;
        let h_17_attn_resid_dropout = Dropout::new();
        let h_17_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_1"))?;
        let h_17_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_2"))?;
        let h_17_mlp_act = candle_nn::Activation::NewGelu;
        let h_17_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.17.mlp.c_fc"))?;
        let h_17_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.17.mlp.c_proj"))?;
        let h_17_mlp_dropout = Dropout::new();
        let h_18_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.18.attn.c_attn"))?;
        let h_18_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.18.attn.c_proj"))?;
        let h_18_attn_resid_dropout = Dropout::new();
        let h_18_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_1"))?;
        let h_18_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_2"))?;
        let h_18_mlp_act = candle_nn::Activation::NewGelu;
        let h_18_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.18.mlp.c_fc"))?;
        let h_18_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.18.mlp.c_proj"))?;
        let h_18_mlp_dropout = Dropout::new();
        let h_19_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.19.attn.c_attn"))?;
        let h_19_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.19.attn.c_proj"))?;
        let h_19_attn_resid_dropout = Dropout::new();
        let h_19_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_1"))?;
        let h_19_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_2"))?;
        let h_19_mlp_act = candle_nn::Activation::NewGelu;
        let h_19_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.19.mlp.c_fc"))?;
        let h_19_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.19.mlp.c_proj"))?;
        let h_19_mlp_dropout = Dropout::new();
        let h_2_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.2.attn.c_attn"))?;
        let h_2_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.2.attn.c_proj"))?;
        let h_2_attn_resid_dropout = Dropout::new();
        let h_2_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_1"))?;
        let h_2_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_2"))?;
        let h_2_mlp_act = candle_nn::Activation::NewGelu;
        let h_2_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.2.mlp.c_fc"))?;
        let h_2_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.2.mlp.c_proj"))?;
        let h_2_mlp_dropout = Dropout::new();
        let h_20_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.20.attn.c_attn"))?;
        let h_20_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.20.attn.c_proj"))?;
        let h_20_attn_resid_dropout = Dropout::new();
        let h_20_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_1"))?;
        let h_20_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_2"))?;
        let h_20_mlp_act = candle_nn::Activation::NewGelu;
        let h_20_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.20.mlp.c_fc"))?;
        let h_20_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.20.mlp.c_proj"))?;
        let h_20_mlp_dropout = Dropout::new();
        let h_21_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.21.attn.c_attn"))?;
        let h_21_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.21.attn.c_proj"))?;
        let h_21_attn_resid_dropout = Dropout::new();
        let h_21_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_1"))?;
        let h_21_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_2"))?;
        let h_21_mlp_act = candle_nn::Activation::NewGelu;
        let h_21_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.21.mlp.c_fc"))?;
        let h_21_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.21.mlp.c_proj"))?;
        let h_21_mlp_dropout = Dropout::new();
        let h_22_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.22.attn.c_attn"))?;
        let h_22_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.22.attn.c_proj"))?;
        let h_22_attn_resid_dropout = Dropout::new();
        let h_22_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_1"))?;
        let h_22_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_2"))?;
        let h_22_mlp_act = candle_nn::Activation::NewGelu;
        let h_22_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.22.mlp.c_fc"))?;
        let h_22_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.22.mlp.c_proj"))?;
        let h_22_mlp_dropout = Dropout::new();
        let h_23_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.23.attn.c_attn"))?;
        let h_23_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.23.attn.c_proj"))?;
        let h_23_attn_resid_dropout = Dropout::new();
        let h_23_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_1"))?;
        let h_23_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_2"))?;
        let h_23_mlp_act = candle_nn::Activation::NewGelu;
        let h_23_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.23.mlp.c_fc"))?;
        let h_23_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.23.mlp.c_proj"))?;
        let h_23_mlp_dropout = Dropout::new();
        let h_3_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.3.attn.c_attn"))?;
        let h_3_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.3.attn.c_proj"))?;
        let h_3_attn_resid_dropout = Dropout::new();
        let h_3_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_1"))?;
        let h_3_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_2"))?;
        let h_3_mlp_act = candle_nn::Activation::NewGelu;
        let h_3_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.3.mlp.c_fc"))?;
        let h_3_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.3.mlp.c_proj"))?;
        let h_3_mlp_dropout = Dropout::new();
        let h_4_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.4.attn.c_attn"))?;
        let h_4_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.4.attn.c_proj"))?;
        let h_4_attn_resid_dropout = Dropout::new();
        let h_4_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_1"))?;
        let h_4_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_2"))?;
        let h_4_mlp_act = candle_nn::Activation::NewGelu;
        let h_4_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.4.mlp.c_fc"))?;
        let h_4_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.4.mlp.c_proj"))?;
        let h_4_mlp_dropout = Dropout::new();
        let h_5_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.5.attn.c_attn"))?;
        let h_5_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.5.attn.c_proj"))?;
        let h_5_attn_resid_dropout = Dropout::new();
        let h_5_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_1"))?;
        let h_5_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_2"))?;
        let h_5_mlp_act = candle_nn::Activation::NewGelu;
        let h_5_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.5.mlp.c_fc"))?;
        let h_5_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.5.mlp.c_proj"))?;
        let h_5_mlp_dropout = Dropout::new();
        let h_6_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.6.attn.c_attn"))?;
        let h_6_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.6.attn.c_proj"))?;
        let h_6_attn_resid_dropout = Dropout::new();
        let h_6_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_1"))?;
        let h_6_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_2"))?;
        let h_6_mlp_act = candle_nn::Activation::NewGelu;
        let h_6_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.6.mlp.c_fc"))?;
        let h_6_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.6.mlp.c_proj"))?;
        let h_6_mlp_dropout = Dropout::new();
        let h_7_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.7.attn.c_attn"))?;
        let h_7_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.7.attn.c_proj"))?;
        let h_7_attn_resid_dropout = Dropout::new();
        let h_7_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_1"))?;
        let h_7_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_2"))?;
        let h_7_mlp_act = candle_nn::Activation::NewGelu;
        let h_7_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.7.mlp.c_fc"))?;
        let h_7_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.7.mlp.c_proj"))?;
        let h_7_mlp_dropout = Dropout::new();
        let h_8_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.8.attn.c_attn"))?;
        let h_8_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.8.attn.c_proj"))?;
        let h_8_attn_resid_dropout = Dropout::new();
        let h_8_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_1"))?;
        let h_8_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_2"))?;
        let h_8_mlp_act = candle_nn::Activation::NewGelu;
        let h_8_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.8.mlp.c_fc"))?;
        let h_8_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.8.mlp.c_proj"))?;
        let h_8_mlp_dropout = Dropout::new();
        let h_9_attn_c_attn = candle_nn::linear(1024, 0, vb.pp("h.9.attn.c_attn"))?;
        let h_9_attn_c_proj = candle_nn::linear(1024, 0, vb.pp("h.9.attn.c_proj"))?;
        let h_9_attn_resid_dropout = Dropout::new();
        let h_9_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_1"))?;
        let h_9_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_2"))?;
        let h_9_mlp_act = candle_nn::Activation::NewGelu;
        let h_9_mlp_c_fc = candle_nn::linear(1024, 0, vb.pp("h.9.mlp.c_fc"))?;
        let h_9_mlp_c_proj = candle_nn::linear(4096, 0, vb.pp("h.9.mlp.c_proj"))?;
        let h_9_mlp_dropout = Dropout::new();
        let ln_f = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("ln_f"))?;
        let wpe = candle_nn::embedding(8196, 1024, vb.pp("wpe"))?;

        Ok(Self {
            drop,
            h_0_attn_c_attn,
            h_0_attn_c_proj,
            h_0_attn_resid_dropout,
            h_0_ln_1,
            h_0_ln_2,
            h_0_mlp_act,
            h_0_mlp_c_fc,
            h_0_mlp_c_proj,
            h_0_mlp_dropout,
            h_1_attn_c_attn,
            h_1_attn_c_proj,
            h_1_attn_resid_dropout,
            h_1_ln_1,
            h_1_ln_2,
            h_1_mlp_act,
            h_1_mlp_c_fc,
            h_1_mlp_c_proj,
            h_1_mlp_dropout,
            h_10_attn_c_attn,
            h_10_attn_c_proj,
            h_10_attn_resid_dropout,
            h_10_ln_1,
            h_10_ln_2,
            h_10_mlp_act,
            h_10_mlp_c_fc,
            h_10_mlp_c_proj,
            h_10_mlp_dropout,
            h_11_attn_c_attn,
            h_11_attn_c_proj,
            h_11_attn_resid_dropout,
            h_11_ln_1,
            h_11_ln_2,
            h_11_mlp_act,
            h_11_mlp_c_fc,
            h_11_mlp_c_proj,
            h_11_mlp_dropout,
            h_12_attn_c_attn,
            h_12_attn_c_proj,
            h_12_attn_resid_dropout,
            h_12_ln_1,
            h_12_ln_2,
            h_12_mlp_act,
            h_12_mlp_c_fc,
            h_12_mlp_c_proj,
            h_12_mlp_dropout,
            h_13_attn_c_attn,
            h_13_attn_c_proj,
            h_13_attn_resid_dropout,
            h_13_ln_1,
            h_13_ln_2,
            h_13_mlp_act,
            h_13_mlp_c_fc,
            h_13_mlp_c_proj,
            h_13_mlp_dropout,
            h_14_attn_c_attn,
            h_14_attn_c_proj,
            h_14_attn_resid_dropout,
            h_14_ln_1,
            h_14_ln_2,
            h_14_mlp_act,
            h_14_mlp_c_fc,
            h_14_mlp_c_proj,
            h_14_mlp_dropout,
            h_15_attn_c_attn,
            h_15_attn_c_proj,
            h_15_attn_resid_dropout,
            h_15_ln_1,
            h_15_ln_2,
            h_15_mlp_act,
            h_15_mlp_c_fc,
            h_15_mlp_c_proj,
            h_15_mlp_dropout,
            h_16_attn_c_attn,
            h_16_attn_c_proj,
            h_16_attn_resid_dropout,
            h_16_ln_1,
            h_16_ln_2,
            h_16_mlp_act,
            h_16_mlp_c_fc,
            h_16_mlp_c_proj,
            h_16_mlp_dropout,
            h_17_attn_c_attn,
            h_17_attn_c_proj,
            h_17_attn_resid_dropout,
            h_17_ln_1,
            h_17_ln_2,
            h_17_mlp_act,
            h_17_mlp_c_fc,
            h_17_mlp_c_proj,
            h_17_mlp_dropout,
            h_18_attn_c_attn,
            h_18_attn_c_proj,
            h_18_attn_resid_dropout,
            h_18_ln_1,
            h_18_ln_2,
            h_18_mlp_act,
            h_18_mlp_c_fc,
            h_18_mlp_c_proj,
            h_18_mlp_dropout,
            h_19_attn_c_attn,
            h_19_attn_c_proj,
            h_19_attn_resid_dropout,
            h_19_ln_1,
            h_19_ln_2,
            h_19_mlp_act,
            h_19_mlp_c_fc,
            h_19_mlp_c_proj,
            h_19_mlp_dropout,
            h_2_attn_c_attn,
            h_2_attn_c_proj,
            h_2_attn_resid_dropout,
            h_2_ln_1,
            h_2_ln_2,
            h_2_mlp_act,
            h_2_mlp_c_fc,
            h_2_mlp_c_proj,
            h_2_mlp_dropout,
            h_20_attn_c_attn,
            h_20_attn_c_proj,
            h_20_attn_resid_dropout,
            h_20_ln_1,
            h_20_ln_2,
            h_20_mlp_act,
            h_20_mlp_c_fc,
            h_20_mlp_c_proj,
            h_20_mlp_dropout,
            h_21_attn_c_attn,
            h_21_attn_c_proj,
            h_21_attn_resid_dropout,
            h_21_ln_1,
            h_21_ln_2,
            h_21_mlp_act,
            h_21_mlp_c_fc,
            h_21_mlp_c_proj,
            h_21_mlp_dropout,
            h_22_attn_c_attn,
            h_22_attn_c_proj,
            h_22_attn_resid_dropout,
            h_22_ln_1,
            h_22_ln_2,
            h_22_mlp_act,
            h_22_mlp_c_fc,
            h_22_mlp_c_proj,
            h_22_mlp_dropout,
            h_23_attn_c_attn,
            h_23_attn_c_proj,
            h_23_attn_resid_dropout,
            h_23_ln_1,
            h_23_ln_2,
            h_23_mlp_act,
            h_23_mlp_c_fc,
            h_23_mlp_c_proj,
            h_23_mlp_dropout,
            h_3_attn_c_attn,
            h_3_attn_c_proj,
            h_3_attn_resid_dropout,
            h_3_ln_1,
            h_3_ln_2,
            h_3_mlp_act,
            h_3_mlp_c_fc,
            h_3_mlp_c_proj,
            h_3_mlp_dropout,
            h_4_attn_c_attn,
            h_4_attn_c_proj,
            h_4_attn_resid_dropout,
            h_4_ln_1,
            h_4_ln_2,
            h_4_mlp_act,
            h_4_mlp_c_fc,
            h_4_mlp_c_proj,
            h_4_mlp_dropout,
            h_5_attn_c_attn,
            h_5_attn_c_proj,
            h_5_attn_resid_dropout,
            h_5_ln_1,
            h_5_ln_2,
            h_5_mlp_act,
            h_5_mlp_c_fc,
            h_5_mlp_c_proj,
            h_5_mlp_dropout,
            h_6_attn_c_attn,
            h_6_attn_c_proj,
            h_6_attn_resid_dropout,
            h_6_ln_1,
            h_6_ln_2,
            h_6_mlp_act,
            h_6_mlp_c_fc,
            h_6_mlp_c_proj,
            h_6_mlp_dropout,
            h_7_attn_c_attn,
            h_7_attn_c_proj,
            h_7_attn_resid_dropout,
            h_7_ln_1,
            h_7_ln_2,
            h_7_mlp_act,
            h_7_mlp_c_fc,
            h_7_mlp_c_proj,
            h_7_mlp_dropout,
            h_8_attn_c_attn,
            h_8_attn_c_proj,
            h_8_attn_resid_dropout,
            h_8_ln_1,
            h_8_ln_2,
            h_8_mlp_act,
            h_8_mlp_c_fc,
            h_8_mlp_c_proj,
            h_8_mlp_dropout,
            h_9_attn_c_attn,
            h_9_attn_c_proj,
            h_9_attn_resid_dropout,
            h_9_ln_1,
            h_9_ln_2,
            h_9_mlp_act,
            h_9_mlp_c_fc,
            h_9_mlp_c_proj,
            h_9_mlp_dropout,
            ln_f,
            wpe,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: drop
        x = self.drop.forward(&x)?;
        py_check!(self.checker, "drop", &x);

        // Layer: h.0.attn.c_attn
        x = self.h_0_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_attn", &x);

        // Layer: h.0.attn.c_proj
        x = self.h_0_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_proj", &x);

        // Layer: h.0.attn.resid_dropout
        x = self.h_0_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.attn.resid_dropout", &x);

        // Layer: h.0.ln_1
        x = self.h_0_ln_1.forward(&x)?;
        py_check!(self.checker, "h.0.ln_1", &x);

        // Layer: h.0.ln_2
        x = self.h_0_ln_2.forward(&x)?;
        py_check!(self.checker, "h.0.ln_2", &x);

        // Layer: h.0.mlp.act
        x = self.h_0_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.act", &x);

        // Layer: h.0.mlp.c_fc
        x = self.h_0_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_fc", &x);

        // Layer: h.0.mlp.c_proj
        x = self.h_0_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_proj", &x);

        // Layer: h.0.mlp.dropout
        x = self.h_0_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.dropout", &x);

        // Layer: h.1.attn.c_attn
        x = self.h_1_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_attn", &x);

        // Layer: h.1.attn.c_proj
        x = self.h_1_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_proj", &x);

        // Layer: h.1.attn.resid_dropout
        x = self.h_1_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.attn.resid_dropout", &x);

        // Layer: h.1.ln_1
        x = self.h_1_ln_1.forward(&x)?;
        py_check!(self.checker, "h.1.ln_1", &x);

        // Layer: h.1.ln_2
        x = self.h_1_ln_2.forward(&x)?;
        py_check!(self.checker, "h.1.ln_2", &x);

        // Layer: h.1.mlp.act
        x = self.h_1_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.act", &x);

        // Layer: h.1.mlp.c_fc
        x = self.h_1_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_fc", &x);

        // Layer: h.1.mlp.c_proj
        x = self.h_1_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_proj", &x);

        // Layer: h.1.mlp.dropout
        x = self.h_1_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.dropout", &x);

        // Layer: h.10.attn.c_attn
        x = self.h_10_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_attn", &x);

        // Layer: h.10.attn.c_proj
        x = self.h_10_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_proj", &x);

        // Layer: h.10.attn.resid_dropout
        x = self.h_10_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.attn.resid_dropout", &x);

        // Layer: h.10.ln_1
        x = self.h_10_ln_1.forward(&x)?;
        py_check!(self.checker, "h.10.ln_1", &x);

        // Layer: h.10.ln_2
        x = self.h_10_ln_2.forward(&x)?;
        py_check!(self.checker, "h.10.ln_2", &x);

        // Layer: h.10.mlp.act
        x = self.h_10_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.act", &x);

        // Layer: h.10.mlp.c_fc
        x = self.h_10_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_fc", &x);

        // Layer: h.10.mlp.c_proj
        x = self.h_10_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_proj", &x);

        // Layer: h.10.mlp.dropout
        x = self.h_10_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.dropout", &x);

        // Layer: h.11.attn.c_attn
        x = self.h_11_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_attn", &x);

        // Layer: h.11.attn.c_proj
        x = self.h_11_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_proj", &x);

        // Layer: h.11.attn.resid_dropout
        x = self.h_11_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.attn.resid_dropout", &x);

        // Layer: h.11.ln_1
        x = self.h_11_ln_1.forward(&x)?;
        py_check!(self.checker, "h.11.ln_1", &x);

        // Layer: h.11.ln_2
        x = self.h_11_ln_2.forward(&x)?;
        py_check!(self.checker, "h.11.ln_2", &x);

        // Layer: h.11.mlp.act
        x = self.h_11_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.act", &x);

        // Layer: h.11.mlp.c_fc
        x = self.h_11_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_fc", &x);

        // Layer: h.11.mlp.c_proj
        x = self.h_11_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_proj", &x);

        // Layer: h.11.mlp.dropout
        x = self.h_11_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.dropout", &x);

        // Layer: h.12.attn.c_attn
        x = self.h_12_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_attn", &x);

        // Layer: h.12.attn.c_proj
        x = self.h_12_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_proj", &x);

        // Layer: h.12.attn.resid_dropout
        x = self.h_12_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.attn.resid_dropout", &x);

        // Layer: h.12.ln_1
        x = self.h_12_ln_1.forward(&x)?;
        py_check!(self.checker, "h.12.ln_1", &x);

        // Layer: h.12.ln_2
        x = self.h_12_ln_2.forward(&x)?;
        py_check!(self.checker, "h.12.ln_2", &x);

        // Layer: h.12.mlp.act
        x = self.h_12_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.act", &x);

        // Layer: h.12.mlp.c_fc
        x = self.h_12_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_fc", &x);

        // Layer: h.12.mlp.c_proj
        x = self.h_12_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_proj", &x);

        // Layer: h.12.mlp.dropout
        x = self.h_12_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.dropout", &x);

        // Layer: h.13.attn.c_attn
        x = self.h_13_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_attn", &x);

        // Layer: h.13.attn.c_proj
        x = self.h_13_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_proj", &x);

        // Layer: h.13.attn.resid_dropout
        x = self.h_13_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.attn.resid_dropout", &x);

        // Layer: h.13.ln_1
        x = self.h_13_ln_1.forward(&x)?;
        py_check!(self.checker, "h.13.ln_1", &x);

        // Layer: h.13.ln_2
        x = self.h_13_ln_2.forward(&x)?;
        py_check!(self.checker, "h.13.ln_2", &x);

        // Layer: h.13.mlp.act
        x = self.h_13_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.act", &x);

        // Layer: h.13.mlp.c_fc
        x = self.h_13_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_fc", &x);

        // Layer: h.13.mlp.c_proj
        x = self.h_13_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_proj", &x);

        // Layer: h.13.mlp.dropout
        x = self.h_13_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.dropout", &x);

        // Layer: h.14.attn.c_attn
        x = self.h_14_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_attn", &x);

        // Layer: h.14.attn.c_proj
        x = self.h_14_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_proj", &x);

        // Layer: h.14.attn.resid_dropout
        x = self.h_14_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.attn.resid_dropout", &x);

        // Layer: h.14.ln_1
        x = self.h_14_ln_1.forward(&x)?;
        py_check!(self.checker, "h.14.ln_1", &x);

        // Layer: h.14.ln_2
        x = self.h_14_ln_2.forward(&x)?;
        py_check!(self.checker, "h.14.ln_2", &x);

        // Layer: h.14.mlp.act
        x = self.h_14_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.act", &x);

        // Layer: h.14.mlp.c_fc
        x = self.h_14_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_fc", &x);

        // Layer: h.14.mlp.c_proj
        x = self.h_14_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_proj", &x);

        // Layer: h.14.mlp.dropout
        x = self.h_14_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.dropout", &x);

        // Layer: h.15.attn.c_attn
        x = self.h_15_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_attn", &x);

        // Layer: h.15.attn.c_proj
        x = self.h_15_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_proj", &x);

        // Layer: h.15.attn.resid_dropout
        x = self.h_15_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.attn.resid_dropout", &x);

        // Layer: h.15.ln_1
        x = self.h_15_ln_1.forward(&x)?;
        py_check!(self.checker, "h.15.ln_1", &x);

        // Layer: h.15.ln_2
        x = self.h_15_ln_2.forward(&x)?;
        py_check!(self.checker, "h.15.ln_2", &x);

        // Layer: h.15.mlp.act
        x = self.h_15_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.act", &x);

        // Layer: h.15.mlp.c_fc
        x = self.h_15_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_fc", &x);

        // Layer: h.15.mlp.c_proj
        x = self.h_15_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_proj", &x);

        // Layer: h.15.mlp.dropout
        x = self.h_15_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.dropout", &x);

        // Layer: h.16.attn.c_attn
        x = self.h_16_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_attn", &x);

        // Layer: h.16.attn.c_proj
        x = self.h_16_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_proj", &x);

        // Layer: h.16.attn.resid_dropout
        x = self.h_16_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.attn.resid_dropout", &x);

        // Layer: h.16.ln_1
        x = self.h_16_ln_1.forward(&x)?;
        py_check!(self.checker, "h.16.ln_1", &x);

        // Layer: h.16.ln_2
        x = self.h_16_ln_2.forward(&x)?;
        py_check!(self.checker, "h.16.ln_2", &x);

        // Layer: h.16.mlp.act
        x = self.h_16_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.act", &x);

        // Layer: h.16.mlp.c_fc
        x = self.h_16_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_fc", &x);

        // Layer: h.16.mlp.c_proj
        x = self.h_16_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_proj", &x);

        // Layer: h.16.mlp.dropout
        x = self.h_16_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.dropout", &x);

        // Layer: h.17.attn.c_attn
        x = self.h_17_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_attn", &x);

        // Layer: h.17.attn.c_proj
        x = self.h_17_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_proj", &x);

        // Layer: h.17.attn.resid_dropout
        x = self.h_17_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.attn.resid_dropout", &x);

        // Layer: h.17.ln_1
        x = self.h_17_ln_1.forward(&x)?;
        py_check!(self.checker, "h.17.ln_1", &x);

        // Layer: h.17.ln_2
        x = self.h_17_ln_2.forward(&x)?;
        py_check!(self.checker, "h.17.ln_2", &x);

        // Layer: h.17.mlp.act
        x = self.h_17_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.act", &x);

        // Layer: h.17.mlp.c_fc
        x = self.h_17_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_fc", &x);

        // Layer: h.17.mlp.c_proj
        x = self.h_17_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_proj", &x);

        // Layer: h.17.mlp.dropout
        x = self.h_17_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.dropout", &x);

        // Layer: h.18.attn.c_attn
        x = self.h_18_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_attn", &x);

        // Layer: h.18.attn.c_proj
        x = self.h_18_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_proj", &x);

        // Layer: h.18.attn.resid_dropout
        x = self.h_18_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.attn.resid_dropout", &x);

        // Layer: h.18.ln_1
        x = self.h_18_ln_1.forward(&x)?;
        py_check!(self.checker, "h.18.ln_1", &x);

        // Layer: h.18.ln_2
        x = self.h_18_ln_2.forward(&x)?;
        py_check!(self.checker, "h.18.ln_2", &x);

        // Layer: h.18.mlp.act
        x = self.h_18_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.act", &x);

        // Layer: h.18.mlp.c_fc
        x = self.h_18_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_fc", &x);

        // Layer: h.18.mlp.c_proj
        x = self.h_18_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_proj", &x);

        // Layer: h.18.mlp.dropout
        x = self.h_18_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.dropout", &x);

        // Layer: h.19.attn.c_attn
        x = self.h_19_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_attn", &x);

        // Layer: h.19.attn.c_proj
        x = self.h_19_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_proj", &x);

        // Layer: h.19.attn.resid_dropout
        x = self.h_19_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.attn.resid_dropout", &x);

        // Layer: h.19.ln_1
        x = self.h_19_ln_1.forward(&x)?;
        py_check!(self.checker, "h.19.ln_1", &x);

        // Layer: h.19.ln_2
        x = self.h_19_ln_2.forward(&x)?;
        py_check!(self.checker, "h.19.ln_2", &x);

        // Layer: h.19.mlp.act
        x = self.h_19_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.act", &x);

        // Layer: h.19.mlp.c_fc
        x = self.h_19_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_fc", &x);

        // Layer: h.19.mlp.c_proj
        x = self.h_19_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_proj", &x);

        // Layer: h.19.mlp.dropout
        x = self.h_19_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.dropout", &x);

        // Layer: h.2.attn.c_attn
        x = self.h_2_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_attn", &x);

        // Layer: h.2.attn.c_proj
        x = self.h_2_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_proj", &x);

        // Layer: h.2.attn.resid_dropout
        x = self.h_2_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.attn.resid_dropout", &x);

        // Layer: h.2.ln_1
        x = self.h_2_ln_1.forward(&x)?;
        py_check!(self.checker, "h.2.ln_1", &x);

        // Layer: h.2.ln_2
        x = self.h_2_ln_2.forward(&x)?;
        py_check!(self.checker, "h.2.ln_2", &x);

        // Layer: h.2.mlp.act
        x = self.h_2_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.act", &x);

        // Layer: h.2.mlp.c_fc
        x = self.h_2_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_fc", &x);

        // Layer: h.2.mlp.c_proj
        x = self.h_2_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_proj", &x);

        // Layer: h.2.mlp.dropout
        x = self.h_2_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.dropout", &x);

        // Layer: h.20.attn.c_attn
        x = self.h_20_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_attn", &x);

        // Layer: h.20.attn.c_proj
        x = self.h_20_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_proj", &x);

        // Layer: h.20.attn.resid_dropout
        x = self.h_20_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.attn.resid_dropout", &x);

        // Layer: h.20.ln_1
        x = self.h_20_ln_1.forward(&x)?;
        py_check!(self.checker, "h.20.ln_1", &x);

        // Layer: h.20.ln_2
        x = self.h_20_ln_2.forward(&x)?;
        py_check!(self.checker, "h.20.ln_2", &x);

        // Layer: h.20.mlp.act
        x = self.h_20_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.act", &x);

        // Layer: h.20.mlp.c_fc
        x = self.h_20_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_fc", &x);

        // Layer: h.20.mlp.c_proj
        x = self.h_20_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_proj", &x);

        // Layer: h.20.mlp.dropout
        x = self.h_20_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.dropout", &x);

        // Layer: h.21.attn.c_attn
        x = self.h_21_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_attn", &x);

        // Layer: h.21.attn.c_proj
        x = self.h_21_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_proj", &x);

        // Layer: h.21.attn.resid_dropout
        x = self.h_21_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.attn.resid_dropout", &x);

        // Layer: h.21.ln_1
        x = self.h_21_ln_1.forward(&x)?;
        py_check!(self.checker, "h.21.ln_1", &x);

        // Layer: h.21.ln_2
        x = self.h_21_ln_2.forward(&x)?;
        py_check!(self.checker, "h.21.ln_2", &x);

        // Layer: h.21.mlp.act
        x = self.h_21_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.act", &x);

        // Layer: h.21.mlp.c_fc
        x = self.h_21_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_fc", &x);

        // Layer: h.21.mlp.c_proj
        x = self.h_21_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_proj", &x);

        // Layer: h.21.mlp.dropout
        x = self.h_21_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.dropout", &x);

        // Layer: h.22.attn.c_attn
        x = self.h_22_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_attn", &x);

        // Layer: h.22.attn.c_proj
        x = self.h_22_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_proj", &x);

        // Layer: h.22.attn.resid_dropout
        x = self.h_22_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.attn.resid_dropout", &x);

        // Layer: h.22.ln_1
        x = self.h_22_ln_1.forward(&x)?;
        py_check!(self.checker, "h.22.ln_1", &x);

        // Layer: h.22.ln_2
        x = self.h_22_ln_2.forward(&x)?;
        py_check!(self.checker, "h.22.ln_2", &x);

        // Layer: h.22.mlp.act
        x = self.h_22_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.act", &x);

        // Layer: h.22.mlp.c_fc
        x = self.h_22_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_fc", &x);

        // Layer: h.22.mlp.c_proj
        x = self.h_22_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_proj", &x);

        // Layer: h.22.mlp.dropout
        x = self.h_22_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.dropout", &x);

        // Layer: h.23.attn.c_attn
        x = self.h_23_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_attn", &x);

        // Layer: h.23.attn.c_proj
        x = self.h_23_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_proj", &x);

        // Layer: h.23.attn.resid_dropout
        x = self.h_23_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.attn.resid_dropout", &x);

        // Layer: h.23.ln_1
        x = self.h_23_ln_1.forward(&x)?;
        py_check!(self.checker, "h.23.ln_1", &x);

        // Layer: h.23.ln_2
        x = self.h_23_ln_2.forward(&x)?;
        py_check!(self.checker, "h.23.ln_2", &x);

        // Layer: h.23.mlp.act
        x = self.h_23_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.act", &x);

        // Layer: h.23.mlp.c_fc
        x = self.h_23_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_fc", &x);

        // Layer: h.23.mlp.c_proj
        x = self.h_23_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_proj", &x);

        // Layer: h.23.mlp.dropout
        x = self.h_23_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.dropout", &x);

        // Layer: h.3.attn.c_attn
        x = self.h_3_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_attn", &x);

        // Layer: h.3.attn.c_proj
        x = self.h_3_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_proj", &x);

        // Layer: h.3.attn.resid_dropout
        x = self.h_3_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.attn.resid_dropout", &x);

        // Layer: h.3.ln_1
        x = self.h_3_ln_1.forward(&x)?;
        py_check!(self.checker, "h.3.ln_1", &x);

        // Layer: h.3.ln_2
        x = self.h_3_ln_2.forward(&x)?;
        py_check!(self.checker, "h.3.ln_2", &x);

        // Layer: h.3.mlp.act
        x = self.h_3_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.act", &x);

        // Layer: h.3.mlp.c_fc
        x = self.h_3_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_fc", &x);

        // Layer: h.3.mlp.c_proj
        x = self.h_3_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_proj", &x);

        // Layer: h.3.mlp.dropout
        x = self.h_3_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.dropout", &x);

        // Layer: h.4.attn.c_attn
        x = self.h_4_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_attn", &x);

        // Layer: h.4.attn.c_proj
        x = self.h_4_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_proj", &x);

        // Layer: h.4.attn.resid_dropout
        x = self.h_4_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.attn.resid_dropout", &x);

        // Layer: h.4.ln_1
        x = self.h_4_ln_1.forward(&x)?;
        py_check!(self.checker, "h.4.ln_1", &x);

        // Layer: h.4.ln_2
        x = self.h_4_ln_2.forward(&x)?;
        py_check!(self.checker, "h.4.ln_2", &x);

        // Layer: h.4.mlp.act
        x = self.h_4_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.act", &x);

        // Layer: h.4.mlp.c_fc
        x = self.h_4_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_fc", &x);

        // Layer: h.4.mlp.c_proj
        x = self.h_4_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_proj", &x);

        // Layer: h.4.mlp.dropout
        x = self.h_4_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.dropout", &x);

        // Layer: h.5.attn.c_attn
        x = self.h_5_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_attn", &x);

        // Layer: h.5.attn.c_proj
        x = self.h_5_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_proj", &x);

        // Layer: h.5.attn.resid_dropout
        x = self.h_5_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.attn.resid_dropout", &x);

        // Layer: h.5.ln_1
        x = self.h_5_ln_1.forward(&x)?;
        py_check!(self.checker, "h.5.ln_1", &x);

        // Layer: h.5.ln_2
        x = self.h_5_ln_2.forward(&x)?;
        py_check!(self.checker, "h.5.ln_2", &x);

        // Layer: h.5.mlp.act
        x = self.h_5_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.act", &x);

        // Layer: h.5.mlp.c_fc
        x = self.h_5_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_fc", &x);

        // Layer: h.5.mlp.c_proj
        x = self.h_5_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_proj", &x);

        // Layer: h.5.mlp.dropout
        x = self.h_5_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.dropout", &x);

        // Layer: h.6.attn.c_attn
        x = self.h_6_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_attn", &x);

        // Layer: h.6.attn.c_proj
        x = self.h_6_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_proj", &x);

        // Layer: h.6.attn.resid_dropout
        x = self.h_6_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.attn.resid_dropout", &x);

        // Layer: h.6.ln_1
        x = self.h_6_ln_1.forward(&x)?;
        py_check!(self.checker, "h.6.ln_1", &x);

        // Layer: h.6.ln_2
        x = self.h_6_ln_2.forward(&x)?;
        py_check!(self.checker, "h.6.ln_2", &x);

        // Layer: h.6.mlp.act
        x = self.h_6_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.act", &x);

        // Layer: h.6.mlp.c_fc
        x = self.h_6_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_fc", &x);

        // Layer: h.6.mlp.c_proj
        x = self.h_6_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_proj", &x);

        // Layer: h.6.mlp.dropout
        x = self.h_6_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.dropout", &x);

        // Layer: h.7.attn.c_attn
        x = self.h_7_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_attn", &x);

        // Layer: h.7.attn.c_proj
        x = self.h_7_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_proj", &x);

        // Layer: h.7.attn.resid_dropout
        x = self.h_7_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.attn.resid_dropout", &x);

        // Layer: h.7.ln_1
        x = self.h_7_ln_1.forward(&x)?;
        py_check!(self.checker, "h.7.ln_1", &x);

        // Layer: h.7.ln_2
        x = self.h_7_ln_2.forward(&x)?;
        py_check!(self.checker, "h.7.ln_2", &x);

        // Layer: h.7.mlp.act
        x = self.h_7_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.act", &x);

        // Layer: h.7.mlp.c_fc
        x = self.h_7_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_fc", &x);

        // Layer: h.7.mlp.c_proj
        x = self.h_7_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_proj", &x);

        // Layer: h.7.mlp.dropout
        x = self.h_7_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.dropout", &x);

        // Layer: h.8.attn.c_attn
        x = self.h_8_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_attn", &x);

        // Layer: h.8.attn.c_proj
        x = self.h_8_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_proj", &x);

        // Layer: h.8.attn.resid_dropout
        x = self.h_8_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.attn.resid_dropout", &x);

        // Layer: h.8.ln_1
        x = self.h_8_ln_1.forward(&x)?;
        py_check!(self.checker, "h.8.ln_1", &x);

        // Layer: h.8.ln_2
        x = self.h_8_ln_2.forward(&x)?;
        py_check!(self.checker, "h.8.ln_2", &x);

        // Layer: h.8.mlp.act
        x = self.h_8_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.act", &x);

        // Layer: h.8.mlp.c_fc
        x = self.h_8_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_fc", &x);

        // Layer: h.8.mlp.c_proj
        x = self.h_8_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_proj", &x);

        // Layer: h.8.mlp.dropout
        x = self.h_8_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.dropout", &x);

        // Layer: h.9.attn.c_attn
        x = self.h_9_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_attn", &x);

        // Layer: h.9.attn.c_proj
        x = self.h_9_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_proj", &x);

        // Layer: h.9.attn.resid_dropout
        x = self.h_9_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.attn.resid_dropout", &x);

        // Layer: h.9.ln_1
        x = self.h_9_ln_1.forward(&x)?;
        py_check!(self.checker, "h.9.ln_1", &x);

        // Layer: h.9.ln_2
        x = self.h_9_ln_2.forward(&x)?;
        py_check!(self.checker, "h.9.ln_2", &x);

        // Layer: h.9.mlp.act
        x = self.h_9_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.act", &x);

        // Layer: h.9.mlp.c_fc
        x = self.h_9_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_fc", &x);

        // Layer: h.9.mlp.c_proj
        x = self.h_9_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_proj", &x);

        // Layer: h.9.mlp.dropout
        x = self.h_9_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.dropout", &x);

        // Layer: ln_f
        x = self.ln_f.forward(&x)?;
        py_check!(self.checker, "ln_f", &x);

        // Layer: wpe
        x = self.wpe.forward(&x)?;
        py_check!(self.checker, "wpe", &x);

        Ok(x)
    }
}
</file>

<file path="dx_simulation/src/generated_t3_transformer.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};
use pycandle_core::gpt2;

pub struct MyModel {
    pub drop: Dropout,
    pub h_0_attn_c_attn: Linear,
    pub h_0_attn_c_proj: Linear,
    pub h_0_attn_resid_dropout: Dropout,
    pub h_0_ln_1: LayerNorm,
    pub h_0_ln_2: LayerNorm,
    pub h_0_mlp_act: candle_nn::Activation,
    pub h_0_mlp_c_fc: Linear,
    pub h_0_mlp_c_proj: Linear,
    pub h_0_mlp_dropout: Dropout,
    pub h_1_attn_c_attn: Linear,
    pub h_1_attn_c_proj: Linear,
    pub h_1_attn_resid_dropout: Dropout,
    pub h_1_ln_1: LayerNorm,
    pub h_1_ln_2: LayerNorm,
    pub h_1_mlp_act: candle_nn::Activation,
    pub h_1_mlp_c_fc: Linear,
    pub h_1_mlp_c_proj: Linear,
    pub h_1_mlp_dropout: Dropout,
    pub h_10_attn_c_attn: Linear,
    pub h_10_attn_c_proj: Linear,
    pub h_10_attn_resid_dropout: Dropout,
    pub h_10_ln_1: LayerNorm,
    pub h_10_ln_2: LayerNorm,
    pub h_10_mlp_act: candle_nn::Activation,
    pub h_10_mlp_c_fc: Linear,
    pub h_10_mlp_c_proj: Linear,
    pub h_10_mlp_dropout: Dropout,
    pub h_11_attn_c_attn: Linear,
    pub h_11_attn_c_proj: Linear,
    pub h_11_attn_resid_dropout: Dropout,
    pub h_11_ln_1: LayerNorm,
    pub h_11_ln_2: LayerNorm,
    pub h_11_mlp_act: candle_nn::Activation,
    pub h_11_mlp_c_fc: Linear,
    pub h_11_mlp_c_proj: Linear,
    pub h_11_mlp_dropout: Dropout,
    pub h_12_attn_c_attn: Linear,
    pub h_12_attn_c_proj: Linear,
    pub h_12_attn_resid_dropout: Dropout,
    pub h_12_ln_1: LayerNorm,
    pub h_12_ln_2: LayerNorm,
    pub h_12_mlp_act: candle_nn::Activation,
    pub h_12_mlp_c_fc: Linear,
    pub h_12_mlp_c_proj: Linear,
    pub h_12_mlp_dropout: Dropout,
    pub h_13_attn_c_attn: Linear,
    pub h_13_attn_c_proj: Linear,
    pub h_13_attn_resid_dropout: Dropout,
    pub h_13_ln_1: LayerNorm,
    pub h_13_ln_2: LayerNorm,
    pub h_13_mlp_act: candle_nn::Activation,
    pub h_13_mlp_c_fc: Linear,
    pub h_13_mlp_c_proj: Linear,
    pub h_13_mlp_dropout: Dropout,
    pub h_14_attn_c_attn: Linear,
    pub h_14_attn_c_proj: Linear,
    pub h_14_attn_resid_dropout: Dropout,
    pub h_14_ln_1: LayerNorm,
    pub h_14_ln_2: LayerNorm,
    pub h_14_mlp_act: candle_nn::Activation,
    pub h_14_mlp_c_fc: Linear,
    pub h_14_mlp_c_proj: Linear,
    pub h_14_mlp_dropout: Dropout,
    pub h_15_attn_c_attn: Linear,
    pub h_15_attn_c_proj: Linear,
    pub h_15_attn_resid_dropout: Dropout,
    pub h_15_ln_1: LayerNorm,
    pub h_15_ln_2: LayerNorm,
    pub h_15_mlp_act: candle_nn::Activation,
    pub h_15_mlp_c_fc: Linear,
    pub h_15_mlp_c_proj: Linear,
    pub h_15_mlp_dropout: Dropout,
    pub h_16_attn_c_attn: Linear,
    pub h_16_attn_c_proj: Linear,
    pub h_16_attn_resid_dropout: Dropout,
    pub h_16_ln_1: LayerNorm,
    pub h_16_ln_2: LayerNorm,
    pub h_16_mlp_act: candle_nn::Activation,
    pub h_16_mlp_c_fc: Linear,
    pub h_16_mlp_c_proj: Linear,
    pub h_16_mlp_dropout: Dropout,
    pub h_17_attn_c_attn: Linear,
    pub h_17_attn_c_proj: Linear,
    pub h_17_attn_resid_dropout: Dropout,
    pub h_17_ln_1: LayerNorm,
    pub h_17_ln_2: LayerNorm,
    pub h_17_mlp_act: candle_nn::Activation,
    pub h_17_mlp_c_fc: Linear,
    pub h_17_mlp_c_proj: Linear,
    pub h_17_mlp_dropout: Dropout,
    pub h_18_attn_c_attn: Linear,
    pub h_18_attn_c_proj: Linear,
    pub h_18_attn_resid_dropout: Dropout,
    pub h_18_ln_1: LayerNorm,
    pub h_18_ln_2: LayerNorm,
    pub h_18_mlp_act: candle_nn::Activation,
    pub h_18_mlp_c_fc: Linear,
    pub h_18_mlp_c_proj: Linear,
    pub h_18_mlp_dropout: Dropout,
    pub h_19_attn_c_attn: Linear,
    pub h_19_attn_c_proj: Linear,
    pub h_19_attn_resid_dropout: Dropout,
    pub h_19_ln_1: LayerNorm,
    pub h_19_ln_2: LayerNorm,
    pub h_19_mlp_act: candle_nn::Activation,
    pub h_19_mlp_c_fc: Linear,
    pub h_19_mlp_c_proj: Linear,
    pub h_19_mlp_dropout: Dropout,
    pub h_2_attn_c_attn: Linear,
    pub h_2_attn_c_proj: Linear,
    pub h_2_attn_resid_dropout: Dropout,
    pub h_2_ln_1: LayerNorm,
    pub h_2_ln_2: LayerNorm,
    pub h_2_mlp_act: candle_nn::Activation,
    pub h_2_mlp_c_fc: Linear,
    pub h_2_mlp_c_proj: Linear,
    pub h_2_mlp_dropout: Dropout,
    pub h_20_attn_c_attn: Linear,
    pub h_20_attn_c_proj: Linear,
    pub h_20_attn_resid_dropout: Dropout,
    pub h_20_ln_1: LayerNorm,
    pub h_20_ln_2: LayerNorm,
    pub h_20_mlp_act: candle_nn::Activation,
    pub h_20_mlp_c_fc: Linear,
    pub h_20_mlp_c_proj: Linear,
    pub h_20_mlp_dropout: Dropout,
    pub h_21_attn_c_attn: Linear,
    pub h_21_attn_c_proj: Linear,
    pub h_21_attn_resid_dropout: Dropout,
    pub h_21_ln_1: LayerNorm,
    pub h_21_ln_2: LayerNorm,
    pub h_21_mlp_act: candle_nn::Activation,
    pub h_21_mlp_c_fc: Linear,
    pub h_21_mlp_c_proj: Linear,
    pub h_21_mlp_dropout: Dropout,
    pub h_22_attn_c_attn: Linear,
    pub h_22_attn_c_proj: Linear,
    pub h_22_attn_resid_dropout: Dropout,
    pub h_22_ln_1: LayerNorm,
    pub h_22_ln_2: LayerNorm,
    pub h_22_mlp_act: candle_nn::Activation,
    pub h_22_mlp_c_fc: Linear,
    pub h_22_mlp_c_proj: Linear,
    pub h_22_mlp_dropout: Dropout,
    pub h_23_attn_c_attn: Linear,
    pub h_23_attn_c_proj: Linear,
    pub h_23_attn_resid_dropout: Dropout,
    pub h_23_ln_1: LayerNorm,
    pub h_23_ln_2: LayerNorm,
    pub h_23_mlp_act: candle_nn::Activation,
    pub h_23_mlp_c_fc: Linear,
    pub h_23_mlp_c_proj: Linear,
    pub h_23_mlp_dropout: Dropout,
    pub h_3_attn_c_attn: Linear,
    pub h_3_attn_c_proj: Linear,
    pub h_3_attn_resid_dropout: Dropout,
    pub h_3_ln_1: LayerNorm,
    pub h_3_ln_2: LayerNorm,
    pub h_3_mlp_act: candle_nn::Activation,
    pub h_3_mlp_c_fc: Linear,
    pub h_3_mlp_c_proj: Linear,
    pub h_3_mlp_dropout: Dropout,
    pub h_4_attn_c_attn: Linear,
    pub h_4_attn_c_proj: Linear,
    pub h_4_attn_resid_dropout: Dropout,
    pub h_4_ln_1: LayerNorm,
    pub h_4_ln_2: LayerNorm,
    pub h_4_mlp_act: candle_nn::Activation,
    pub h_4_mlp_c_fc: Linear,
    pub h_4_mlp_c_proj: Linear,
    pub h_4_mlp_dropout: Dropout,
    pub h_5_attn_c_attn: Linear,
    pub h_5_attn_c_proj: Linear,
    pub h_5_attn_resid_dropout: Dropout,
    pub h_5_ln_1: LayerNorm,
    pub h_5_ln_2: LayerNorm,
    pub h_5_mlp_act: candle_nn::Activation,
    pub h_5_mlp_c_fc: Linear,
    pub h_5_mlp_c_proj: Linear,
    pub h_5_mlp_dropout: Dropout,
    pub h_6_attn_c_attn: Linear,
    pub h_6_attn_c_proj: Linear,
    pub h_6_attn_resid_dropout: Dropout,
    pub h_6_ln_1: LayerNorm,
    pub h_6_ln_2: LayerNorm,
    pub h_6_mlp_act: candle_nn::Activation,
    pub h_6_mlp_c_fc: Linear,
    pub h_6_mlp_c_proj: Linear,
    pub h_6_mlp_dropout: Dropout,
    pub h_7_attn_c_attn: Linear,
    pub h_7_attn_c_proj: Linear,
    pub h_7_attn_resid_dropout: Dropout,
    pub h_7_ln_1: LayerNorm,
    pub h_7_ln_2: LayerNorm,
    pub h_7_mlp_act: candle_nn::Activation,
    pub h_7_mlp_c_fc: Linear,
    pub h_7_mlp_c_proj: Linear,
    pub h_7_mlp_dropout: Dropout,
    pub h_8_attn_c_attn: Linear,
    pub h_8_attn_c_proj: Linear,
    pub h_8_attn_resid_dropout: Dropout,
    pub h_8_ln_1: LayerNorm,
    pub h_8_ln_2: LayerNorm,
    pub h_8_mlp_act: candle_nn::Activation,
    pub h_8_mlp_c_fc: Linear,
    pub h_8_mlp_c_proj: Linear,
    pub h_8_mlp_dropout: Dropout,
    pub h_9_attn_c_attn: Linear,
    pub h_9_attn_c_proj: Linear,
    pub h_9_attn_resid_dropout: Dropout,
    pub h_9_ln_1: LayerNorm,
    pub h_9_ln_2: LayerNorm,
    pub h_9_mlp_act: candle_nn::Activation,
    pub h_9_mlp_c_fc: Linear,
    pub h_9_mlp_c_proj: Linear,
    pub h_9_mlp_dropout: Dropout,
    pub ln_f: LayerNorm,
    pub wpe: Embedding,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let drop = Dropout::new();
        let h_0_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.0.attn.c_attn"))?;
        let h_0_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.0.attn.c_proj"))?;
        let h_0_attn_resid_dropout = Dropout::new();
        let h_0_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_1"))?;
        let h_0_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_2"))?;
        let h_0_mlp_act = candle_nn::Activation::NewGelu;
        let h_0_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.0.mlp.c_fc"))?;
        let h_0_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.0.mlp.c_proj"))?;
        let h_0_mlp_dropout = Dropout::new();
        let h_1_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.1.attn.c_attn"))?;
        let h_1_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.1.attn.c_proj"))?;
        let h_1_attn_resid_dropout = Dropout::new();
        let h_1_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_1"))?;
        let h_1_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_2"))?;
        let h_1_mlp_act = candle_nn::Activation::NewGelu;
        let h_1_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.1.mlp.c_fc"))?;
        let h_1_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.1.mlp.c_proj"))?;
        let h_1_mlp_dropout = Dropout::new();
        let h_10_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.10.attn.c_attn"))?;
        let h_10_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.10.attn.c_proj"))?;
        let h_10_attn_resid_dropout = Dropout::new();
        let h_10_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_1"))?;
        let h_10_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_2"))?;
        let h_10_mlp_act = candle_nn::Activation::NewGelu;
        let h_10_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.10.mlp.c_fc"))?;
        let h_10_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.10.mlp.c_proj"))?;
        let h_10_mlp_dropout = Dropout::new();
        let h_11_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.11.attn.c_attn"))?;
        let h_11_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.11.attn.c_proj"))?;
        let h_11_attn_resid_dropout = Dropout::new();
        let h_11_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_1"))?;
        let h_11_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_2"))?;
        let h_11_mlp_act = candle_nn::Activation::NewGelu;
        let h_11_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.11.mlp.c_fc"))?;
        let h_11_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.11.mlp.c_proj"))?;
        let h_11_mlp_dropout = Dropout::new();
        let h_12_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.12.attn.c_attn"))?;
        let h_12_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.12.attn.c_proj"))?;
        let h_12_attn_resid_dropout = Dropout::new();
        let h_12_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_1"))?;
        let h_12_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_2"))?;
        let h_12_mlp_act = candle_nn::Activation::NewGelu;
        let h_12_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.12.mlp.c_fc"))?;
        let h_12_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.12.mlp.c_proj"))?;
        let h_12_mlp_dropout = Dropout::new();
        let h_13_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.13.attn.c_attn"))?;
        let h_13_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.13.attn.c_proj"))?;
        let h_13_attn_resid_dropout = Dropout::new();
        let h_13_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_1"))?;
        let h_13_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_2"))?;
        let h_13_mlp_act = candle_nn::Activation::NewGelu;
        let h_13_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.13.mlp.c_fc"))?;
        let h_13_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.13.mlp.c_proj"))?;
        let h_13_mlp_dropout = Dropout::new();
        let h_14_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.14.attn.c_attn"))?;
        let h_14_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.14.attn.c_proj"))?;
        let h_14_attn_resid_dropout = Dropout::new();
        let h_14_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_1"))?;
        let h_14_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_2"))?;
        let h_14_mlp_act = candle_nn::Activation::NewGelu;
        let h_14_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.14.mlp.c_fc"))?;
        let h_14_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.14.mlp.c_proj"))?;
        let h_14_mlp_dropout = Dropout::new();
        let h_15_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.15.attn.c_attn"))?;
        let h_15_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.15.attn.c_proj"))?;
        let h_15_attn_resid_dropout = Dropout::new();
        let h_15_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_1"))?;
        let h_15_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_2"))?;
        let h_15_mlp_act = candle_nn::Activation::NewGelu;
        let h_15_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.15.mlp.c_fc"))?;
        let h_15_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.15.mlp.c_proj"))?;
        let h_15_mlp_dropout = Dropout::new();
        let h_16_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.16.attn.c_attn"))?;
        let h_16_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.16.attn.c_proj"))?;
        let h_16_attn_resid_dropout = Dropout::new();
        let h_16_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_1"))?;
        let h_16_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_2"))?;
        let h_16_mlp_act = candle_nn::Activation::NewGelu;
        let h_16_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.16.mlp.c_fc"))?;
        let h_16_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.16.mlp.c_proj"))?;
        let h_16_mlp_dropout = Dropout::new();
        let h_17_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.17.attn.c_attn"))?;
        let h_17_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.17.attn.c_proj"))?;
        let h_17_attn_resid_dropout = Dropout::new();
        let h_17_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_1"))?;
        let h_17_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_2"))?;
        let h_17_mlp_act = candle_nn::Activation::NewGelu;
        let h_17_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.17.mlp.c_fc"))?;
        let h_17_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.17.mlp.c_proj"))?;
        let h_17_mlp_dropout = Dropout::new();
        let h_18_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.18.attn.c_attn"))?;
        let h_18_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.18.attn.c_proj"))?;
        let h_18_attn_resid_dropout = Dropout::new();
        let h_18_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_1"))?;
        let h_18_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_2"))?;
        let h_18_mlp_act = candle_nn::Activation::NewGelu;
        let h_18_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.18.mlp.c_fc"))?;
        let h_18_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.18.mlp.c_proj"))?;
        let h_18_mlp_dropout = Dropout::new();
        let h_19_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.19.attn.c_attn"))?;
        let h_19_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.19.attn.c_proj"))?;
        let h_19_attn_resid_dropout = Dropout::new();
        let h_19_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_1"))?;
        let h_19_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_2"))?;
        let h_19_mlp_act = candle_nn::Activation::NewGelu;
        let h_19_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.19.mlp.c_fc"))?;
        let h_19_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.19.mlp.c_proj"))?;
        let h_19_mlp_dropout = Dropout::new();
        let h_2_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.2.attn.c_attn"))?;
        let h_2_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.2.attn.c_proj"))?;
        let h_2_attn_resid_dropout = Dropout::new();
        let h_2_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_1"))?;
        let h_2_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_2"))?;
        let h_2_mlp_act = candle_nn::Activation::NewGelu;
        let h_2_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.2.mlp.c_fc"))?;
        let h_2_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.2.mlp.c_proj"))?;
        let h_2_mlp_dropout = Dropout::new();
        let h_20_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.20.attn.c_attn"))?;
        let h_20_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.20.attn.c_proj"))?;
        let h_20_attn_resid_dropout = Dropout::new();
        let h_20_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_1"))?;
        let h_20_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_2"))?;
        let h_20_mlp_act = candle_nn::Activation::NewGelu;
        let h_20_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.20.mlp.c_fc"))?;
        let h_20_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.20.mlp.c_proj"))?;
        let h_20_mlp_dropout = Dropout::new();
        let h_21_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.21.attn.c_attn"))?;
        let h_21_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.21.attn.c_proj"))?;
        let h_21_attn_resid_dropout = Dropout::new();
        let h_21_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_1"))?;
        let h_21_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_2"))?;
        let h_21_mlp_act = candle_nn::Activation::NewGelu;
        let h_21_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.21.mlp.c_fc"))?;
        let h_21_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.21.mlp.c_proj"))?;
        let h_21_mlp_dropout = Dropout::new();
        let h_22_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.22.attn.c_attn"))?;
        let h_22_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.22.attn.c_proj"))?;
        let h_22_attn_resid_dropout = Dropout::new();
        let h_22_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_1"))?;
        let h_22_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_2"))?;
        let h_22_mlp_act = candle_nn::Activation::NewGelu;
        let h_22_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.22.mlp.c_fc"))?;
        let h_22_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.22.mlp.c_proj"))?;
        let h_22_mlp_dropout = Dropout::new();
        let h_23_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.23.attn.c_attn"))?;
        let h_23_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.23.attn.c_proj"))?;
        let h_23_attn_resid_dropout = Dropout::new();
        let h_23_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_1"))?;
        let h_23_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_2"))?;
        let h_23_mlp_act = candle_nn::Activation::NewGelu;
        let h_23_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.23.mlp.c_fc"))?;
        let h_23_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.23.mlp.c_proj"))?;
        let h_23_mlp_dropout = Dropout::new();
        let h_3_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.3.attn.c_attn"))?;
        let h_3_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.3.attn.c_proj"))?;
        let h_3_attn_resid_dropout = Dropout::new();
        let h_3_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_1"))?;
        let h_3_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_2"))?;
        let h_3_mlp_act = candle_nn::Activation::NewGelu;
        let h_3_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.3.mlp.c_fc"))?;
        let h_3_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.3.mlp.c_proj"))?;
        let h_3_mlp_dropout = Dropout::new();
        let h_4_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.4.attn.c_attn"))?;
        let h_4_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.4.attn.c_proj"))?;
        let h_4_attn_resid_dropout = Dropout::new();
        let h_4_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_1"))?;
        let h_4_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_2"))?;
        let h_4_mlp_act = candle_nn::Activation::NewGelu;
        let h_4_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.4.mlp.c_fc"))?;
        let h_4_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.4.mlp.c_proj"))?;
        let h_4_mlp_dropout = Dropout::new();
        let h_5_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.5.attn.c_attn"))?;
        let h_5_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.5.attn.c_proj"))?;
        let h_5_attn_resid_dropout = Dropout::new();
        let h_5_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_1"))?;
        let h_5_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_2"))?;
        let h_5_mlp_act = candle_nn::Activation::NewGelu;
        let h_5_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.5.mlp.c_fc"))?;
        let h_5_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.5.mlp.c_proj"))?;
        let h_5_mlp_dropout = Dropout::new();
        let h_6_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.6.attn.c_attn"))?;
        let h_6_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.6.attn.c_proj"))?;
        let h_6_attn_resid_dropout = Dropout::new();
        let h_6_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_1"))?;
        let h_6_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_2"))?;
        let h_6_mlp_act = candle_nn::Activation::NewGelu;
        let h_6_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.6.mlp.c_fc"))?;
        let h_6_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.6.mlp.c_proj"))?;
        let h_6_mlp_dropout = Dropout::new();
        let h_7_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.7.attn.c_attn"))?;
        let h_7_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.7.attn.c_proj"))?;
        let h_7_attn_resid_dropout = Dropout::new();
        let h_7_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_1"))?;
        let h_7_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_2"))?;
        let h_7_mlp_act = candle_nn::Activation::NewGelu;
        let h_7_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.7.mlp.c_fc"))?;
        let h_7_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.7.mlp.c_proj"))?;
        let h_7_mlp_dropout = Dropout::new();
        let h_8_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.8.attn.c_attn"))?;
        let h_8_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.8.attn.c_proj"))?;
        let h_8_attn_resid_dropout = Dropout::new();
        let h_8_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_1"))?;
        let h_8_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_2"))?;
        let h_8_mlp_act = candle_nn::Activation::NewGelu;
        let h_8_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.8.mlp.c_fc"))?;
        let h_8_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.8.mlp.c_proj"))?;
        let h_8_mlp_dropout = Dropout::new();
        let h_9_attn_c_attn = candle_nn::linear(0, 0, vb.pp("h.9.attn.c_attn"))?;
        let h_9_attn_c_proj = candle_nn::linear(0, 0, vb.pp("h.9.attn.c_proj"))?;
        let h_9_attn_resid_dropout = Dropout::new();
        let h_9_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_1"))?;
        let h_9_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_2"))?;
        let h_9_mlp_act = candle_nn::Activation::NewGelu;
        let h_9_mlp_c_fc = candle_nn::linear(0, 0, vb.pp("h.9.mlp.c_fc"))?;
        let h_9_mlp_c_proj = candle_nn::linear(0, 0, vb.pp("h.9.mlp.c_proj"))?;
        let h_9_mlp_dropout = Dropout::new();
        let ln_f = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("ln_f"))?;
        let wpe = candle_nn::embedding(8196, 1024, vb.pp("wpe"))?;

        Ok(Self {
            drop,
            h_0_attn_c_attn,
            h_0_attn_c_proj,
            h_0_attn_resid_dropout,
            h_0_ln_1,
            h_0_ln_2,
            h_0_mlp_act,
            h_0_mlp_c_fc,
            h_0_mlp_c_proj,
            h_0_mlp_dropout,
            h_1_attn_c_attn,
            h_1_attn_c_proj,
            h_1_attn_resid_dropout,
            h_1_ln_1,
            h_1_ln_2,
            h_1_mlp_act,
            h_1_mlp_c_fc,
            h_1_mlp_c_proj,
            h_1_mlp_dropout,
            h_10_attn_c_attn,
            h_10_attn_c_proj,
            h_10_attn_resid_dropout,
            h_10_ln_1,
            h_10_ln_2,
            h_10_mlp_act,
            h_10_mlp_c_fc,
            h_10_mlp_c_proj,
            h_10_mlp_dropout,
            h_11_attn_c_attn,
            h_11_attn_c_proj,
            h_11_attn_resid_dropout,
            h_11_ln_1,
            h_11_ln_2,
            h_11_mlp_act,
            h_11_mlp_c_fc,
            h_11_mlp_c_proj,
            h_11_mlp_dropout,
            h_12_attn_c_attn,
            h_12_attn_c_proj,
            h_12_attn_resid_dropout,
            h_12_ln_1,
            h_12_ln_2,
            h_12_mlp_act,
            h_12_mlp_c_fc,
            h_12_mlp_c_proj,
            h_12_mlp_dropout,
            h_13_attn_c_attn,
            h_13_attn_c_proj,
            h_13_attn_resid_dropout,
            h_13_ln_1,
            h_13_ln_2,
            h_13_mlp_act,
            h_13_mlp_c_fc,
            h_13_mlp_c_proj,
            h_13_mlp_dropout,
            h_14_attn_c_attn,
            h_14_attn_c_proj,
            h_14_attn_resid_dropout,
            h_14_ln_1,
            h_14_ln_2,
            h_14_mlp_act,
            h_14_mlp_c_fc,
            h_14_mlp_c_proj,
            h_14_mlp_dropout,
            h_15_attn_c_attn,
            h_15_attn_c_proj,
            h_15_attn_resid_dropout,
            h_15_ln_1,
            h_15_ln_2,
            h_15_mlp_act,
            h_15_mlp_c_fc,
            h_15_mlp_c_proj,
            h_15_mlp_dropout,
            h_16_attn_c_attn,
            h_16_attn_c_proj,
            h_16_attn_resid_dropout,
            h_16_ln_1,
            h_16_ln_2,
            h_16_mlp_act,
            h_16_mlp_c_fc,
            h_16_mlp_c_proj,
            h_16_mlp_dropout,
            h_17_attn_c_attn,
            h_17_attn_c_proj,
            h_17_attn_resid_dropout,
            h_17_ln_1,
            h_17_ln_2,
            h_17_mlp_act,
            h_17_mlp_c_fc,
            h_17_mlp_c_proj,
            h_17_mlp_dropout,
            h_18_attn_c_attn,
            h_18_attn_c_proj,
            h_18_attn_resid_dropout,
            h_18_ln_1,
            h_18_ln_2,
            h_18_mlp_act,
            h_18_mlp_c_fc,
            h_18_mlp_c_proj,
            h_18_mlp_dropout,
            h_19_attn_c_attn,
            h_19_attn_c_proj,
            h_19_attn_resid_dropout,
            h_19_ln_1,
            h_19_ln_2,
            h_19_mlp_act,
            h_19_mlp_c_fc,
            h_19_mlp_c_proj,
            h_19_mlp_dropout,
            h_2_attn_c_attn,
            h_2_attn_c_proj,
            h_2_attn_resid_dropout,
            h_2_ln_1,
            h_2_ln_2,
            h_2_mlp_act,
            h_2_mlp_c_fc,
            h_2_mlp_c_proj,
            h_2_mlp_dropout,
            h_20_attn_c_attn,
            h_20_attn_c_proj,
            h_20_attn_resid_dropout,
            h_20_ln_1,
            h_20_ln_2,
            h_20_mlp_act,
            h_20_mlp_c_fc,
            h_20_mlp_c_proj,
            h_20_mlp_dropout,
            h_21_attn_c_attn,
            h_21_attn_c_proj,
            h_21_attn_resid_dropout,
            h_21_ln_1,
            h_21_ln_2,
            h_21_mlp_act,
            h_21_mlp_c_fc,
            h_21_mlp_c_proj,
            h_21_mlp_dropout,
            h_22_attn_c_attn,
            h_22_attn_c_proj,
            h_22_attn_resid_dropout,
            h_22_ln_1,
            h_22_ln_2,
            h_22_mlp_act,
            h_22_mlp_c_fc,
            h_22_mlp_c_proj,
            h_22_mlp_dropout,
            h_23_attn_c_attn,
            h_23_attn_c_proj,
            h_23_attn_resid_dropout,
            h_23_ln_1,
            h_23_ln_2,
            h_23_mlp_act,
            h_23_mlp_c_fc,
            h_23_mlp_c_proj,
            h_23_mlp_dropout,
            h_3_attn_c_attn,
            h_3_attn_c_proj,
            h_3_attn_resid_dropout,
            h_3_ln_1,
            h_3_ln_2,
            h_3_mlp_act,
            h_3_mlp_c_fc,
            h_3_mlp_c_proj,
            h_3_mlp_dropout,
            h_4_attn_c_attn,
            h_4_attn_c_proj,
            h_4_attn_resid_dropout,
            h_4_ln_1,
            h_4_ln_2,
            h_4_mlp_act,
            h_4_mlp_c_fc,
            h_4_mlp_c_proj,
            h_4_mlp_dropout,
            h_5_attn_c_attn,
            h_5_attn_c_proj,
            h_5_attn_resid_dropout,
            h_5_ln_1,
            h_5_ln_2,
            h_5_mlp_act,
            h_5_mlp_c_fc,
            h_5_mlp_c_proj,
            h_5_mlp_dropout,
            h_6_attn_c_attn,
            h_6_attn_c_proj,
            h_6_attn_resid_dropout,
            h_6_ln_1,
            h_6_ln_2,
            h_6_mlp_act,
            h_6_mlp_c_fc,
            h_6_mlp_c_proj,
            h_6_mlp_dropout,
            h_7_attn_c_attn,
            h_7_attn_c_proj,
            h_7_attn_resid_dropout,
            h_7_ln_1,
            h_7_ln_2,
            h_7_mlp_act,
            h_7_mlp_c_fc,
            h_7_mlp_c_proj,
            h_7_mlp_dropout,
            h_8_attn_c_attn,
            h_8_attn_c_proj,
            h_8_attn_resid_dropout,
            h_8_ln_1,
            h_8_ln_2,
            h_8_mlp_act,
            h_8_mlp_c_fc,
            h_8_mlp_c_proj,
            h_8_mlp_dropout,
            h_9_attn_c_attn,
            h_9_attn_c_proj,
            h_9_attn_resid_dropout,
            h_9_ln_1,
            h_9_ln_2,
            h_9_mlp_act,
            h_9_mlp_c_fc,
            h_9_mlp_c_proj,
            h_9_mlp_dropout,
            ln_f,
            wpe,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: drop
        x = self.drop.forward(&x)?;
        py_check!(self.checker, "drop", &x);

        // Layer: h.0.attn.c_attn
        x = self.h_0_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_attn", &x);

        // Layer: h.0.attn.c_proj
        x = self.h_0_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_proj", &x);

        // Layer: h.0.attn.resid_dropout
        x = self.h_0_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.attn.resid_dropout", &x);

        // Layer: h.0.ln_1
        x = self.h_0_ln_1.forward(&x)?;
        py_check!(self.checker, "h.0.ln_1", &x);

        // Layer: h.0.ln_2
        x = self.h_0_ln_2.forward(&x)?;
        py_check!(self.checker, "h.0.ln_2", &x);

        // Layer: h.0.mlp.act
        x = self.h_0_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.act", &x);

        // Layer: h.0.mlp.c_fc
        x = self.h_0_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_fc", &x);

        // Layer: h.0.mlp.c_proj
        x = self.h_0_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_proj", &x);

        // Layer: h.0.mlp.dropout
        x = self.h_0_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.dropout", &x);

        // Layer: h.1.attn.c_attn
        x = self.h_1_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_attn", &x);

        // Layer: h.1.attn.c_proj
        x = self.h_1_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_proj", &x);

        // Layer: h.1.attn.resid_dropout
        x = self.h_1_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.attn.resid_dropout", &x);

        // Layer: h.1.ln_1
        x = self.h_1_ln_1.forward(&x)?;
        py_check!(self.checker, "h.1.ln_1", &x);

        // Layer: h.1.ln_2
        x = self.h_1_ln_2.forward(&x)?;
        py_check!(self.checker, "h.1.ln_2", &x);

        // Layer: h.1.mlp.act
        x = self.h_1_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.act", &x);

        // Layer: h.1.mlp.c_fc
        x = self.h_1_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_fc", &x);

        // Layer: h.1.mlp.c_proj
        x = self.h_1_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_proj", &x);

        // Layer: h.1.mlp.dropout
        x = self.h_1_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.dropout", &x);

        // Layer: h.10.attn.c_attn
        x = self.h_10_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_attn", &x);

        // Layer: h.10.attn.c_proj
        x = self.h_10_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_proj", &x);

        // Layer: h.10.attn.resid_dropout
        x = self.h_10_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.attn.resid_dropout", &x);

        // Layer: h.10.ln_1
        x = self.h_10_ln_1.forward(&x)?;
        py_check!(self.checker, "h.10.ln_1", &x);

        // Layer: h.10.ln_2
        x = self.h_10_ln_2.forward(&x)?;
        py_check!(self.checker, "h.10.ln_2", &x);

        // Layer: h.10.mlp.act
        x = self.h_10_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.act", &x);

        // Layer: h.10.mlp.c_fc
        x = self.h_10_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_fc", &x);

        // Layer: h.10.mlp.c_proj
        x = self.h_10_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_proj", &x);

        // Layer: h.10.mlp.dropout
        x = self.h_10_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.dropout", &x);

        // Layer: h.11.attn.c_attn
        x = self.h_11_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_attn", &x);

        // Layer: h.11.attn.c_proj
        x = self.h_11_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_proj", &x);

        // Layer: h.11.attn.resid_dropout
        x = self.h_11_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.attn.resid_dropout", &x);

        // Layer: h.11.ln_1
        x = self.h_11_ln_1.forward(&x)?;
        py_check!(self.checker, "h.11.ln_1", &x);

        // Layer: h.11.ln_2
        x = self.h_11_ln_2.forward(&x)?;
        py_check!(self.checker, "h.11.ln_2", &x);

        // Layer: h.11.mlp.act
        x = self.h_11_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.act", &x);

        // Layer: h.11.mlp.c_fc
        x = self.h_11_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_fc", &x);

        // Layer: h.11.mlp.c_proj
        x = self.h_11_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_proj", &x);

        // Layer: h.11.mlp.dropout
        x = self.h_11_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.dropout", &x);

        // Layer: h.12.attn.c_attn
        x = self.h_12_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_attn", &x);

        // Layer: h.12.attn.c_proj
        x = self.h_12_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_proj", &x);

        // Layer: h.12.attn.resid_dropout
        x = self.h_12_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.attn.resid_dropout", &x);

        // Layer: h.12.ln_1
        x = self.h_12_ln_1.forward(&x)?;
        py_check!(self.checker, "h.12.ln_1", &x);

        // Layer: h.12.ln_2
        x = self.h_12_ln_2.forward(&x)?;
        py_check!(self.checker, "h.12.ln_2", &x);

        // Layer: h.12.mlp.act
        x = self.h_12_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.act", &x);

        // Layer: h.12.mlp.c_fc
        x = self.h_12_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_fc", &x);

        // Layer: h.12.mlp.c_proj
        x = self.h_12_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_proj", &x);

        // Layer: h.12.mlp.dropout
        x = self.h_12_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.dropout", &x);

        // Layer: h.13.attn.c_attn
        x = self.h_13_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_attn", &x);

        // Layer: h.13.attn.c_proj
        x = self.h_13_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_proj", &x);

        // Layer: h.13.attn.resid_dropout
        x = self.h_13_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.attn.resid_dropout", &x);

        // Layer: h.13.ln_1
        x = self.h_13_ln_1.forward(&x)?;
        py_check!(self.checker, "h.13.ln_1", &x);

        // Layer: h.13.ln_2
        x = self.h_13_ln_2.forward(&x)?;
        py_check!(self.checker, "h.13.ln_2", &x);

        // Layer: h.13.mlp.act
        x = self.h_13_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.act", &x);

        // Layer: h.13.mlp.c_fc
        x = self.h_13_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_fc", &x);

        // Layer: h.13.mlp.c_proj
        x = self.h_13_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_proj", &x);

        // Layer: h.13.mlp.dropout
        x = self.h_13_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.dropout", &x);

        // Layer: h.14.attn.c_attn
        x = self.h_14_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_attn", &x);

        // Layer: h.14.attn.c_proj
        x = self.h_14_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_proj", &x);

        // Layer: h.14.attn.resid_dropout
        x = self.h_14_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.attn.resid_dropout", &x);

        // Layer: h.14.ln_1
        x = self.h_14_ln_1.forward(&x)?;
        py_check!(self.checker, "h.14.ln_1", &x);

        // Layer: h.14.ln_2
        x = self.h_14_ln_2.forward(&x)?;
        py_check!(self.checker, "h.14.ln_2", &x);

        // Layer: h.14.mlp.act
        x = self.h_14_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.act", &x);

        // Layer: h.14.mlp.c_fc
        x = self.h_14_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_fc", &x);

        // Layer: h.14.mlp.c_proj
        x = self.h_14_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_proj", &x);

        // Layer: h.14.mlp.dropout
        x = self.h_14_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.dropout", &x);

        // Layer: h.15.attn.c_attn
        x = self.h_15_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_attn", &x);

        // Layer: h.15.attn.c_proj
        x = self.h_15_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_proj", &x);

        // Layer: h.15.attn.resid_dropout
        x = self.h_15_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.attn.resid_dropout", &x);

        // Layer: h.15.ln_1
        x = self.h_15_ln_1.forward(&x)?;
        py_check!(self.checker, "h.15.ln_1", &x);

        // Layer: h.15.ln_2
        x = self.h_15_ln_2.forward(&x)?;
        py_check!(self.checker, "h.15.ln_2", &x);

        // Layer: h.15.mlp.act
        x = self.h_15_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.act", &x);

        // Layer: h.15.mlp.c_fc
        x = self.h_15_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_fc", &x);

        // Layer: h.15.mlp.c_proj
        x = self.h_15_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_proj", &x);

        // Layer: h.15.mlp.dropout
        x = self.h_15_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.dropout", &x);

        // Layer: h.16.attn.c_attn
        x = self.h_16_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_attn", &x);

        // Layer: h.16.attn.c_proj
        x = self.h_16_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_proj", &x);

        // Layer: h.16.attn.resid_dropout
        x = self.h_16_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.attn.resid_dropout", &x);

        // Layer: h.16.ln_1
        x = self.h_16_ln_1.forward(&x)?;
        py_check!(self.checker, "h.16.ln_1", &x);

        // Layer: h.16.ln_2
        x = self.h_16_ln_2.forward(&x)?;
        py_check!(self.checker, "h.16.ln_2", &x);

        // Layer: h.16.mlp.act
        x = self.h_16_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.act", &x);

        // Layer: h.16.mlp.c_fc
        x = self.h_16_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_fc", &x);

        // Layer: h.16.mlp.c_proj
        x = self.h_16_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_proj", &x);

        // Layer: h.16.mlp.dropout
        x = self.h_16_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.dropout", &x);

        // Layer: h.17.attn.c_attn
        x = self.h_17_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_attn", &x);

        // Layer: h.17.attn.c_proj
        x = self.h_17_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_proj", &x);

        // Layer: h.17.attn.resid_dropout
        x = self.h_17_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.attn.resid_dropout", &x);

        // Layer: h.17.ln_1
        x = self.h_17_ln_1.forward(&x)?;
        py_check!(self.checker, "h.17.ln_1", &x);

        // Layer: h.17.ln_2
        x = self.h_17_ln_2.forward(&x)?;
        py_check!(self.checker, "h.17.ln_2", &x);

        // Layer: h.17.mlp.act
        x = self.h_17_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.act", &x);

        // Layer: h.17.mlp.c_fc
        x = self.h_17_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_fc", &x);

        // Layer: h.17.mlp.c_proj
        x = self.h_17_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_proj", &x);

        // Layer: h.17.mlp.dropout
        x = self.h_17_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.dropout", &x);

        // Layer: h.18.attn.c_attn
        x = self.h_18_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_attn", &x);

        // Layer: h.18.attn.c_proj
        x = self.h_18_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_proj", &x);

        // Layer: h.18.attn.resid_dropout
        x = self.h_18_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.attn.resid_dropout", &x);

        // Layer: h.18.ln_1
        x = self.h_18_ln_1.forward(&x)?;
        py_check!(self.checker, "h.18.ln_1", &x);

        // Layer: h.18.ln_2
        x = self.h_18_ln_2.forward(&x)?;
        py_check!(self.checker, "h.18.ln_2", &x);

        // Layer: h.18.mlp.act
        x = self.h_18_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.act", &x);

        // Layer: h.18.mlp.c_fc
        x = self.h_18_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_fc", &x);

        // Layer: h.18.mlp.c_proj
        x = self.h_18_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_proj", &x);

        // Layer: h.18.mlp.dropout
        x = self.h_18_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.dropout", &x);

        // Layer: h.19.attn.c_attn
        x = self.h_19_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_attn", &x);

        // Layer: h.19.attn.c_proj
        x = self.h_19_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_proj", &x);

        // Layer: h.19.attn.resid_dropout
        x = self.h_19_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.attn.resid_dropout", &x);

        // Layer: h.19.ln_1
        x = self.h_19_ln_1.forward(&x)?;
        py_check!(self.checker, "h.19.ln_1", &x);

        // Layer: h.19.ln_2
        x = self.h_19_ln_2.forward(&x)?;
        py_check!(self.checker, "h.19.ln_2", &x);

        // Layer: h.19.mlp.act
        x = self.h_19_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.act", &x);

        // Layer: h.19.mlp.c_fc
        x = self.h_19_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_fc", &x);

        // Layer: h.19.mlp.c_proj
        x = self.h_19_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_proj", &x);

        // Layer: h.19.mlp.dropout
        x = self.h_19_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.dropout", &x);

        // Layer: h.2.attn.c_attn
        x = self.h_2_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_attn", &x);

        // Layer: h.2.attn.c_proj
        x = self.h_2_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_proj", &x);

        // Layer: h.2.attn.resid_dropout
        x = self.h_2_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.attn.resid_dropout", &x);

        // Layer: h.2.ln_1
        x = self.h_2_ln_1.forward(&x)?;
        py_check!(self.checker, "h.2.ln_1", &x);

        // Layer: h.2.ln_2
        x = self.h_2_ln_2.forward(&x)?;
        py_check!(self.checker, "h.2.ln_2", &x);

        // Layer: h.2.mlp.act
        x = self.h_2_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.act", &x);

        // Layer: h.2.mlp.c_fc
        x = self.h_2_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_fc", &x);

        // Layer: h.2.mlp.c_proj
        x = self.h_2_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_proj", &x);

        // Layer: h.2.mlp.dropout
        x = self.h_2_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.dropout", &x);

        // Layer: h.20.attn.c_attn
        x = self.h_20_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_attn", &x);

        // Layer: h.20.attn.c_proj
        x = self.h_20_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_proj", &x);

        // Layer: h.20.attn.resid_dropout
        x = self.h_20_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.attn.resid_dropout", &x);

        // Layer: h.20.ln_1
        x = self.h_20_ln_1.forward(&x)?;
        py_check!(self.checker, "h.20.ln_1", &x);

        // Layer: h.20.ln_2
        x = self.h_20_ln_2.forward(&x)?;
        py_check!(self.checker, "h.20.ln_2", &x);

        // Layer: h.20.mlp.act
        x = self.h_20_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.act", &x);

        // Layer: h.20.mlp.c_fc
        x = self.h_20_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_fc", &x);

        // Layer: h.20.mlp.c_proj
        x = self.h_20_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_proj", &x);

        // Layer: h.20.mlp.dropout
        x = self.h_20_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.dropout", &x);

        // Layer: h.21.attn.c_attn
        x = self.h_21_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_attn", &x);

        // Layer: h.21.attn.c_proj
        x = self.h_21_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_proj", &x);

        // Layer: h.21.attn.resid_dropout
        x = self.h_21_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.attn.resid_dropout", &x);

        // Layer: h.21.ln_1
        x = self.h_21_ln_1.forward(&x)?;
        py_check!(self.checker, "h.21.ln_1", &x);

        // Layer: h.21.ln_2
        x = self.h_21_ln_2.forward(&x)?;
        py_check!(self.checker, "h.21.ln_2", &x);

        // Layer: h.21.mlp.act
        x = self.h_21_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.act", &x);

        // Layer: h.21.mlp.c_fc
        x = self.h_21_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_fc", &x);

        // Layer: h.21.mlp.c_proj
        x = self.h_21_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_proj", &x);

        // Layer: h.21.mlp.dropout
        x = self.h_21_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.dropout", &x);

        // Layer: h.22.attn.c_attn
        x = self.h_22_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_attn", &x);

        // Layer: h.22.attn.c_proj
        x = self.h_22_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_proj", &x);

        // Layer: h.22.attn.resid_dropout
        x = self.h_22_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.attn.resid_dropout", &x);

        // Layer: h.22.ln_1
        x = self.h_22_ln_1.forward(&x)?;
        py_check!(self.checker, "h.22.ln_1", &x);

        // Layer: h.22.ln_2
        x = self.h_22_ln_2.forward(&x)?;
        py_check!(self.checker, "h.22.ln_2", &x);

        // Layer: h.22.mlp.act
        x = self.h_22_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.act", &x);

        // Layer: h.22.mlp.c_fc
        x = self.h_22_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_fc", &x);

        // Layer: h.22.mlp.c_proj
        x = self.h_22_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_proj", &x);

        // Layer: h.22.mlp.dropout
        x = self.h_22_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.dropout", &x);

        // Layer: h.23.attn.c_attn
        x = self.h_23_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_attn", &x);

        // Layer: h.23.attn.c_proj
        x = self.h_23_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_proj", &x);

        // Layer: h.23.attn.resid_dropout
        x = self.h_23_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.attn.resid_dropout", &x);

        // Layer: h.23.ln_1
        x = self.h_23_ln_1.forward(&x)?;
        py_check!(self.checker, "h.23.ln_1", &x);

        // Layer: h.23.ln_2
        x = self.h_23_ln_2.forward(&x)?;
        py_check!(self.checker, "h.23.ln_2", &x);

        // Layer: h.23.mlp.act
        x = self.h_23_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.act", &x);

        // Layer: h.23.mlp.c_fc
        x = self.h_23_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_fc", &x);

        // Layer: h.23.mlp.c_proj
        x = self.h_23_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_proj", &x);

        // Layer: h.23.mlp.dropout
        x = self.h_23_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.dropout", &x);

        // Layer: h.3.attn.c_attn
        x = self.h_3_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_attn", &x);

        // Layer: h.3.attn.c_proj
        x = self.h_3_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_proj", &x);

        // Layer: h.3.attn.resid_dropout
        x = self.h_3_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.attn.resid_dropout", &x);

        // Layer: h.3.ln_1
        x = self.h_3_ln_1.forward(&x)?;
        py_check!(self.checker, "h.3.ln_1", &x);

        // Layer: h.3.ln_2
        x = self.h_3_ln_2.forward(&x)?;
        py_check!(self.checker, "h.3.ln_2", &x);

        // Layer: h.3.mlp.act
        x = self.h_3_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.act", &x);

        // Layer: h.3.mlp.c_fc
        x = self.h_3_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_fc", &x);

        // Layer: h.3.mlp.c_proj
        x = self.h_3_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_proj", &x);

        // Layer: h.3.mlp.dropout
        x = self.h_3_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.dropout", &x);

        // Layer: h.4.attn.c_attn
        x = self.h_4_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_attn", &x);

        // Layer: h.4.attn.c_proj
        x = self.h_4_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_proj", &x);

        // Layer: h.4.attn.resid_dropout
        x = self.h_4_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.attn.resid_dropout", &x);

        // Layer: h.4.ln_1
        x = self.h_4_ln_1.forward(&x)?;
        py_check!(self.checker, "h.4.ln_1", &x);

        // Layer: h.4.ln_2
        x = self.h_4_ln_2.forward(&x)?;
        py_check!(self.checker, "h.4.ln_2", &x);

        // Layer: h.4.mlp.act
        x = self.h_4_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.act", &x);

        // Layer: h.4.mlp.c_fc
        x = self.h_4_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_fc", &x);

        // Layer: h.4.mlp.c_proj
        x = self.h_4_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_proj", &x);

        // Layer: h.4.mlp.dropout
        x = self.h_4_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.dropout", &x);

        // Layer: h.5.attn.c_attn
        x = self.h_5_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_attn", &x);

        // Layer: h.5.attn.c_proj
        x = self.h_5_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_proj", &x);

        // Layer: h.5.attn.resid_dropout
        x = self.h_5_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.attn.resid_dropout", &x);

        // Layer: h.5.ln_1
        x = self.h_5_ln_1.forward(&x)?;
        py_check!(self.checker, "h.5.ln_1", &x);

        // Layer: h.5.ln_2
        x = self.h_5_ln_2.forward(&x)?;
        py_check!(self.checker, "h.5.ln_2", &x);

        // Layer: h.5.mlp.act
        x = self.h_5_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.act", &x);

        // Layer: h.5.mlp.c_fc
        x = self.h_5_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_fc", &x);

        // Layer: h.5.mlp.c_proj
        x = self.h_5_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_proj", &x);

        // Layer: h.5.mlp.dropout
        x = self.h_5_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.dropout", &x);

        // Layer: h.6.attn.c_attn
        x = self.h_6_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_attn", &x);

        // Layer: h.6.attn.c_proj
        x = self.h_6_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_proj", &x);

        // Layer: h.6.attn.resid_dropout
        x = self.h_6_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.attn.resid_dropout", &x);

        // Layer: h.6.ln_1
        x = self.h_6_ln_1.forward(&x)?;
        py_check!(self.checker, "h.6.ln_1", &x);

        // Layer: h.6.ln_2
        x = self.h_6_ln_2.forward(&x)?;
        py_check!(self.checker, "h.6.ln_2", &x);

        // Layer: h.6.mlp.act
        x = self.h_6_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.act", &x);

        // Layer: h.6.mlp.c_fc
        x = self.h_6_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_fc", &x);

        // Layer: h.6.mlp.c_proj
        x = self.h_6_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_proj", &x);

        // Layer: h.6.mlp.dropout
        x = self.h_6_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.dropout", &x);

        // Layer: h.7.attn.c_attn
        x = self.h_7_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_attn", &x);

        // Layer: h.7.attn.c_proj
        x = self.h_7_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_proj", &x);

        // Layer: h.7.attn.resid_dropout
        x = self.h_7_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.attn.resid_dropout", &x);

        // Layer: h.7.ln_1
        x = self.h_7_ln_1.forward(&x)?;
        py_check!(self.checker, "h.7.ln_1", &x);

        // Layer: h.7.ln_2
        x = self.h_7_ln_2.forward(&x)?;
        py_check!(self.checker, "h.7.ln_2", &x);

        // Layer: h.7.mlp.act
        x = self.h_7_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.act", &x);

        // Layer: h.7.mlp.c_fc
        x = self.h_7_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_fc", &x);

        // Layer: h.7.mlp.c_proj
        x = self.h_7_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_proj", &x);

        // Layer: h.7.mlp.dropout
        x = self.h_7_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.dropout", &x);

        // Layer: h.8.attn.c_attn
        x = self.h_8_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_attn", &x);

        // Layer: h.8.attn.c_proj
        x = self.h_8_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_proj", &x);

        // Layer: h.8.attn.resid_dropout
        x = self.h_8_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.attn.resid_dropout", &x);

        // Layer: h.8.ln_1
        x = self.h_8_ln_1.forward(&x)?;
        py_check!(self.checker, "h.8.ln_1", &x);

        // Layer: h.8.ln_2
        x = self.h_8_ln_2.forward(&x)?;
        py_check!(self.checker, "h.8.ln_2", &x);

        // Layer: h.8.mlp.act
        x = self.h_8_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.act", &x);

        // Layer: h.8.mlp.c_fc
        x = self.h_8_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_fc", &x);

        // Layer: h.8.mlp.c_proj
        x = self.h_8_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_proj", &x);

        // Layer: h.8.mlp.dropout
        x = self.h_8_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.dropout", &x);

        // Layer: h.9.attn.c_attn
        x = self.h_9_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_attn", &x);

        // Layer: h.9.attn.c_proj
        x = self.h_9_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_proj", &x);

        // Layer: h.9.attn.resid_dropout
        x = self.h_9_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.attn.resid_dropout", &x);

        // Layer: h.9.ln_1
        x = self.h_9_ln_1.forward(&x)?;
        py_check!(self.checker, "h.9.ln_1", &x);

        // Layer: h.9.ln_2
        x = self.h_9_ln_2.forward(&x)?;
        py_check!(self.checker, "h.9.ln_2", &x);

        // Layer: h.9.mlp.act
        x = self.h_9_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.act", &x);

        // Layer: h.9.mlp.c_fc
        x = self.h_9_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_fc", &x);

        // Layer: h.9.mlp.c_proj
        x = self.h_9_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_proj", &x);

        // Layer: h.9.mlp.dropout
        x = self.h_9_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.dropout", &x);

        // Layer: ln_f
        x = self.ln_f.forward(&x)?;
        py_check!(self.checker, "ln_f", &x);

        // Layer: wpe
        x = self.wpe.forward(&x)?;
        py_check!(self.checker, "wpe", &x);

        Ok(x)
    }
}
</file>

<file path="dx_simulation/src/generated_voice_encoder.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct MyModel {
    pub lstm: LSTM,
    pub proj: Linear,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let lstm = LSTM::load(vb.pp("lstm"), 40, 256, 3)?;
        let proj = { let w = vb.pp("proj").get((256, 256), "weight")?.t()?; let b = Some(vb.pp("proj").get(256, "bias")?); Linear::new(w, b) };

        Ok(Self {
            lstm,
            proj,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: lstm
        x = self.lstm.forward(&x)?.0;
        py_check!(self.checker, "lstm", &x);

        // Layer: proj
        x = self.proj.forward(&x)?;
        py_check!(self.checker, "proj", &x);

        Ok(x)
    }
}
</file>

<file path="dx_simulation/src/main.rs">
use anyhow::Result;
use candle_core::{DType, Device, IndexOp, Tensor};
use candle_nn::{Embedding, Linear, Module, VarBuilder};
use candle_transformers::generation::LogitsProcessor;
use hf_hub::{Repo, RepoType, api::sync::Api};
use std::path::PathBuf;
use tokenizers::Tokenizer;

mod punc_norm;
mod s3gen_flow;
mod voice_encoder;

use punc_norm::punc_norm;
use pycandle_core::gpt2::{Config as GPTConfig, GPTModel, KVCache};
use voice_encoder::{Config as VEConfig, VoiceEncoder};

// Set this to your local HF cache if needed
const HF_CACHE: &str = "D:/huggingface";
const REPO_ID: &str = "ResembleAI/chatterbox-turbo";

pub struct LearnedPositionEmbeddings {
    pub emb: Embedding,
}

impl LearnedPositionEmbeddings {
    pub fn load(vb: VarBuilder, vocab_size: usize, dim: usize) -> Result<Self> {
        let emb = candle_nn::embedding(vocab_size, dim, vb.pp("emb"))?;
        Ok(Self { emb })
    }

    pub fn forward(&self, t: usize, device: &Device) -> Result<Tensor> {
        let pos = Tensor::arange(0u32, t as u32, device)?.unsqueeze(0)?;
        Ok(self.emb.forward(&pos)?)
    }

    pub fn get_at(&self, idx: usize, device: &Device) -> Result<Tensor> {
        let pos = Tensor::new(&[idx as u32], device)?.unsqueeze(0)?;
        Ok(self.emb.forward(&pos)?)
    }
}

pub struct T3CondEnc {
    pub spkr_enc: Linear,
    pub emotion_adv_fc: Option<Linear>,
}

impl T3CondEnc {
    pub fn load(vb: VarBuilder) -> Result<Self> {
        let spkr_enc = candle_nn::linear(256, 1024, vb.pp("spkr_enc"))?;
        let emotion_adv_fc = vb
            .pp("emotion_adv_fc")
            .get((1024, 1), "weight")
            .ok()
            .map(|w| Linear::new(w, None));
        Ok(Self {
            spkr_enc,
            emotion_adv_fc,
        })
    }

    pub fn forward(&self, speaker_emb: &Tensor, device: &Device) -> Result<Tensor> {
        let b = speaker_emb.dim(0).map_err(anyhow::Error::msg)?;
        let emb = if speaker_emb.rank() == 3 {
            speaker_emb.mean(1).map_err(anyhow::Error::msg)?
        } else {
            speaker_emb.clone()
        };
        let cond_spkr = self
            .spkr_enc
            .forward(&emb.reshape((b, 256)).map_err(anyhow::Error::msg)?)
            .map_err(anyhow::Error::msg)?;
        let mut res = cond_spkr
            .reshape((b, 1, 1024))
            .map_err(anyhow::Error::msg)?;

        if let Some(ref fc) = self.emotion_adv_fc {
            // Default emotion_adv is 0.5
            let val = Tensor::new(&[0.5f32], device)
                .map_err(anyhow::Error::msg)?
                .reshape((b, 1, 1))
                .map_err(anyhow::Error::msg)?;
            let emotion_emb = fc.forward(&val).map_err(anyhow::Error::msg)?;
            res = (res + emotion_emb).map_err(anyhow::Error::msg)?;
        }
        Ok(res)
    }
}

pub struct T3Model {
    pub tfmr: GPTModel,
    pub speech_head: Linear,
    pub cond_enc: T3CondEnc,
}

impl T3Model {
    pub fn load(vb: VarBuilder) -> Result<Self> {
        let config = GPTConfig {
            vocab_size: 50276,
            context_length: 8196,
            emb_dim: 1024,
            n_heads: 16,
            n_layers: 24,
            ..Default::default()
        };

        let tfmr = GPTModel::new(config, vb.pp("tfmr"))?;
        let speech_head = candle_nn::linear(1024, 6563, vb.pp("speech_head"))?;
        let cond_enc = T3CondEnc::load(vb.pp("cond_enc"))?;

        Ok(Self {
            tfmr,
            speech_head,
            cond_enc,
        })
    }

    pub fn forward_manual(
        &self,
        x: &Tensor, // (B, T, D)
        mut kv_cache: Option<&mut Vec<Option<KVCache>>>,
        offset: usize,
    ) -> Result<Tensor> {
        let (_b, t, _d) = x.dims3()?;
        let device = x.device();

        // GPT-2 backbone positional encoding (wpe)
        let pos = Tensor::arange(offset as u32, (offset + t) as u32, device)?;
        let pos_emb = self.tfmr.wpe.forward(&pos)?;
        let h = x.broadcast_add(&pos_emb.unsqueeze(0)?)?;

        let mut h = h.clone();
        for (i, block) in self.tfmr.h.iter().enumerate() {
            let layer_cache = if let Some(ref mut cache) = kv_cache {
                if cache.len() <= i {
                    cache.resize_with(i + 1, || None);
                }
                cache.get_mut(i)
            } else {
                None
            };
            h = block.forward(&h, self.tfmr.mask.as_ref(), layer_cache)?;
        }

        Ok(self.tfmr.ln_f.forward(&h)?)
    }

    pub fn generate_tokens(
        &self,
        text_tokens: &Tensor, // [1, N]
        speaker_emb: &Tensor,
        device: &Device,
    ) -> Result<Vec<u32>> {
        // Wrap text with BOT (255) and EOT (0)
        let mut wrapped_text = vec![255u32];
        wrapped_text.extend(text_tokens.flatten_all()?.to_vec1::<u32>()?);
        wrapped_text.push(0u32);
        let text_tokens = Tensor::new(wrapped_text.as_slice(), device)?.unsqueeze(0)?;

        let cond_emb = self.cond_enc.forward(speaker_emb, device)?;
        let text_embed = self.tfmr.wte.forward(&text_tokens)?;

        let inputs_embeds = Tensor::cat(&[&cond_emb, &text_embed], 1)?;
        let mut generated_tokens = Vec::new();
        let mut kv_cache = Vec::new();

        // SOS token is 6561
        let mut current_token = Tensor::new(&[6561u32], device)?.unsqueeze(0)?;
        let mut logits_processor = LogitsProcessor::new(1337, Some(0.8), Some(0.95));

        println!("  (Sampling Loop Start)");

        for i in 0..1000 {
            let current_emb = if i == 0 {
                let bos_emb = self.tfmr.wte.forward(&current_token)?;
                Tensor::cat(&[&inputs_embeds, &bos_emb], 1)?
            } else {
                self.tfmr.wte.forward(&current_token)?
            };

            let offset = if i == 0 { 0 } else { inputs_embeds.dim(1)? + i };
            let h = self.forward_manual(&current_emb, Some(&mut kv_cache), offset)?;

            let last_h = h.i((.., h.dim(1)? - 1, ..))?;
            let logits = self.speech_head.forward(&last_h)?;

            let next_token = logits_processor.sample(&logits.i(0)?)?;
            if next_token == 6562 {
                // EOS
                break;
            }

            generated_tokens.push(next_token);
            current_token = Tensor::new(&[next_token], device)?.unsqueeze(0)?;

            if i % 100 == 0 && i > 0 {
                println!("    Sampled {} tokens...", i);
            }
        }

        Ok(generated_tokens)
    }
}

// ============================================================================
// S3Gen / HiFTGenerator Components
// ============================================================================

pub struct F0Predictor {
    pub condnet: Vec<Linear>,
    pub classifier: candle_nn::Linear,
}

fn cumsum_2d(x: &Tensor) -> Result<Tensor> {
    let (b, c, t) = x.dims3().map_err(anyhow::Error::msg)?;
    let mut data = x
        .to_device(&Device::Cpu)
        .map_err(anyhow::Error::msg)?
        .to_vec3::<f32>()
        .map_err(anyhow::Error::msg)?;
    for bi in 0..b {
        for ci in 0..c {
            for ti in 1..t {
                data[bi][ci][ti] += data[bi][ci][ti - 1];
            }
        }
    }
    let flattened: Vec<f32> = data
        .into_iter()
        .flat_map(|bc| bc.into_iter().flat_map(|t| t.into_iter()))
        .collect();
    Tensor::from_vec(flattened, (b, c, t), &Device::Cpu)?
        .to_device(x.device())
        .map_err(anyhow::Error::msg)
}

pub struct SineGen {
    pub sampling_rate: f64,
    pub harmonic_num: usize,
    pub sine_amp: f64,
    pub noise_std: f64,
    pub voiced_threshold: f64,
}

impl SineGen {
    pub fn new(sr: f64, harm: usize, amp: f64, noise: f64, thresh: f64) -> Self {
        Self {
            sampling_rate: sr,
            harmonic_num: harm,
            sine_amp: amp,
            noise_std: noise,
            voiced_threshold: thresh,
        }
    }

    pub fn forward(&self, f0: &Tensor) -> Result<Tensor> {
        let (_b, _c, _t) = f0.dims3().map_err(anyhow::Error::msg)?;
        let _device = f0.device();

        // F_mat = f0 * (i + 1) / sr
        let mut f_mats = Vec::new();
        for i in 0..=self.harmonic_num {
            let f_i = f0
                .affine((i + 1) as f64 / self.sampling_rate, 0.0)
                .map_err(anyhow::Error::msg)?;
            f_mats.push(f_i);
        }
        let f_mat = Tensor::cat(&f_mats, 1).map_err(anyhow::Error::msg)?; // [B, harm+1, T]

        // theta_mat = 2 * PI * cumsum(f_mat)
        let theta_mat = cumsum_2d(&f_mat)?
            .affine(2.0 * std::f32::consts::PI as f64, 0.0)
            .map_err(anyhow::Error::msg)?;

        let sine_waves = theta_mat
            .sin()
            .map_err(anyhow::Error::msg)?
            .affine(self.sine_amp, 0.0)
            .map_err(anyhow::Error::msg)?;

        // U/V
        let uv = f0
            .affine(1.0, -self.voiced_threshold as f64)
            .map_err(anyhow::Error::msg)?
            .gt(&f0.zeros_like().map_err(anyhow::Error::msg)?)
            .map_err(anyhow::Error::msg)?
            .to_dtype(DType::F32)
            .map_err(anyhow::Error::msg)?;

        // Noise
        let voiced_noise = uv.affine(self.noise_std, 0.0).map_err(anyhow::Error::msg)?;
        let unvoiced_noise = uv
            .affine(-1.0, 1.0)
            .map_err(anyhow::Error::msg)?
            .affine(self.sine_amp / 3.0, 0.0)
            .map_err(anyhow::Error::msg)?;
        let noise_amp = (voiced_noise + unvoiced_noise).map_err(anyhow::Error::msg)?;
        let randn = sine_waves
            .randn_like(0.0, 1.0)
            .map_err(anyhow::Error::msg)?;
        let noise = randn
            .broadcast_mul(&noise_amp)
            .map_err(anyhow::Error::msg)?;

        // first: set the unvoiced part to 0 by uv
        // then: additive noise
        let voiced_part = sine_waves.broadcast_mul(&uv).map_err(anyhow::Error::msg)?;
        let res = (voiced_part + noise).map_err(anyhow::Error::msg)?;
        Ok(res)
    }
}

pub struct SourceModule {
    pub sin_gen: SineGen,
    pub linear: candle_nn::Linear,
}

impl SourceModule {
    pub fn load(vb: VarBuilder, sr: f64, harm: usize) -> Result<Self> {
        let sin_gen = SineGen::new(sr, harm, 0.1, 0.003, 0.0);
        let linear_w = vb.get((1, harm + 1), "l_linear.weight")?;
        let linear_b = vb.get((1,), "l_linear.bias")?;
        let linear = candle_nn::Linear::new(linear_w, Some(linear_b));
        Ok(Self { sin_gen, linear })
    }

    pub fn forward(&self, f0: &Tensor) -> Result<Tensor> {
        // f0 is [B, 1, T] at 24kHz
        let sine_wavs = self.sin_gen.forward(f0)?; // [B, harm+1, T]
        let sine_wavs = sine_wavs.transpose(1, 2).map_err(anyhow::Error::msg)?; // [B, T, harm+1]
        let merged = self
            .linear
            .forward(&sine_wavs)
            .map_err(anyhow::Error::msg)?; // [B, T, 1]
        let res = merged
            .transpose(1, 2)
            .map_err(anyhow::Error::msg)?
            .tanh()
            .map_err(anyhow::Error::msg)?;
        Ok(res)
    }
}

impl F0Predictor {
    pub fn load(vb: VarBuilder) -> Result<Self> {
        let mut condnet = Vec::new();
        let channels = [80, 512, 512, 512, 512, 512];
        for i in 0..5 {
            let vb_i = vb.pp(&format!("condnet.{}", i * 2)); // ELU is at 1, 3, 5...
            let w = vb_i
                .pp("parametrizations.weight")
                .get((channels[i + 1], channels[i], 3), "original1")
                .map_err(anyhow::Error::msg)?;
            let b = vb_i
                .get((channels[i + 1],), "bias")
                .map_err(anyhow::Error::msg)?;
            condnet.push(Linear::new(w, Some(b)));
        }
        let classifier_w = vb
            .get((1, 512), "classifier.weight")
            .map_err(anyhow::Error::msg)?;
        let classifier_b = vb
            .get((1,), "classifier.bias")
            .map_err(anyhow::Error::msg)?;
        let classifier = candle_nn::Linear::new(classifier_w, Some(classifier_b));
        Ok(Self {
            condnet,
            classifier,
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let mut x = x.clone();
        for conv in &self.condnet {
            x = x
                .conv1d(&conv.weight(), 1, 1, 1, 1) // padding 1, stride 1
                .map_err(anyhow::Error::msg)?;
            if let Some(bias) = conv.bias() {
                x = x
                    .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                    .map_err(anyhow::Error::msg)?;
            }
            x = x.elu(1.0).map_err(anyhow::Error::msg)?;
        }
        // x: (B, 512, T) -> (B, T, 512)
        x = x.transpose(1, 2).map_err(anyhow::Error::msg)?;
        let x = self.classifier.forward(&x).map_err(anyhow::Error::msg)?;
        // abs(squeeze(-1))
        x.squeeze(2)
            .map_err(anyhow::Error::msg)?
            .abs()
            .map_err(anyhow::Error::msg)
    }
}

pub struct ResBlock {
    pub convs1: Vec<Linear>, // Use Linear for WeightNorm original1
    pub convs2: Vec<Linear>,
    pub activations1: Vec<pycandle_core::layers::Snake>,
    pub activations2: Vec<pycandle_core::layers::Snake>,
    pub kernel_size: usize,
}

impl ResBlock {
    pub fn load(
        vb: VarBuilder,
        channels: usize,
        kernel_size: usize,
        dilations: &[usize],
    ) -> Result<Self> {
        let mut convs1 = Vec::new();
        let mut convs2 = Vec::new();
        let mut activations1 = Vec::new();
        let mut activations2 = Vec::new();

        for (i, &_dilation) in dilations.iter().enumerate() {
            // WeightNorm in Python means weight is in parametrizations.weight.original1
            let vb1 = vb.pp(&format!("convs1.{}", i));
            let w1 = vb1
                .pp("parametrizations.weight")
                .get((channels, channels, kernel_size), "original1")
                .map_err(anyhow::Error::msg)?;
            let b1 = vb1.get((channels,), "bias").map_err(anyhow::Error::msg)?;
            convs1.push(Linear::new(w1, Some(b1)));

            let vb2 = vb.pp(&format!("convs2.{}", i));
            let w2 = vb2
                .pp("parametrizations.weight")
                .get((channels, channels, kernel_size), "original1")
                .map_err(anyhow::Error::msg)?;
            let b2 = vb2.get((channels,), "bias").map_err(anyhow::Error::msg)?;
            convs2.push(Linear::new(w2, Some(b2)));

            activations1.push(
                pycandle_core::layers::Snake::load(vb.pp(&format!("activations1.{}", i)), channels)
                    .map_err(anyhow::Error::msg)?,
            );
            activations2.push(
                pycandle_core::layers::Snake::load(vb.pp(&format!("activations2.{}", i)), channels)
                    .map_err(anyhow::Error::msg)?,
            );
        }

        Ok(Self {
            convs1,
            convs2,
            activations1,
            activations2,
            kernel_size,
        })
    }

    pub fn forward(&self, x: &Tensor, dilations: &[usize]) -> Result<Tensor> {
        let mut x = x.clone();
        for i in 0..self.convs1.len() {
            let dilation = dilations[i];
            let padding = (self.kernel_size * dilation - dilation) / 2;

            let mut xt = self.activations1[i]
                .forward(&x)
                .map_err(anyhow::Error::msg)?;
            xt = xt
                .conv1d(&self.convs1[i].weight(), padding, 1, dilation, 1)
                .map_err(anyhow::Error::msg)?;
            if let Some(bias) = self.convs1[i].bias() {
                xt = xt
                    .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                    .map_err(anyhow::Error::msg)?;
            }

            xt = self.activations2[i]
                .forward(&xt)
                .map_err(anyhow::Error::msg)?;
            let p2 = (self.kernel_size - 1) / 2;
            xt = xt
                .conv1d(&self.convs2[i].weight(), p2, 1, 1, 1)
                .map_err(anyhow::Error::msg)?;
            if let Some(bias) = self.convs2[i].bias() {
                xt = xt
                    .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                    .map_err(anyhow::Error::msg)?;
            }
            x = (x + xt).map_err(anyhow::Error::msg)?;
        }
        Ok(x)
    }
}

pub struct HiFTGenerator {
    pub f0_predictor: F0Predictor,
    pub m_source: SourceModule,
    pub conv_pre: Linear,
    pub ups: Vec<pycandle_core::layers::ConvTranspose1d>,
    pub source_downs: Vec<Linear>,
    pub source_resblocks: Vec<ResBlock>,
    pub resblocks: Vec<ResBlock>,
    pub conv_post: Linear,
}

impl HiFTGenerator {
    pub fn load(vb: VarBuilder) -> Result<Self> {
        let f0_predictor = F0Predictor::load(vb.pp("mel2wav.f0_predictor"))?;
        let m_source = SourceModule::load(vb.pp("mel2wav.m_source"), 24000.0, 8)?;

        let conv_pre_w = vb
            .pp("mel2wav.conv_pre.parametrizations.weight")
            .get((512, 80, 7), "original1")
            .map_err(anyhow::Error::msg)?;
        let conv_pre_b = vb
            .get((512,), "mel2wav.conv_pre.bias")
            .map_err(anyhow::Error::msg)?;
        let conv_pre = Linear::new(conv_pre_w, Some(conv_pre_b));

        let mut ups = Vec::new();
        let mut source_downs = Vec::new();
        let mut source_resblocks = Vec::new();

        let rates = [8, 5, 3];
        let kernels = [16, 11, 7];
        let channels = [512, 256, 128, 64];
        let sd_kernels = [30, 6, 1];
        let sd_res_kernels = [7, 7, 11];

        for i in 0..3 {
            ups.push(pycandle_core::layers::ConvTranspose1d::load(
                vb.pp(format!("mel2wav.ups.{}", i)),
                channels[i],
                channels[i + 1],
                kernels[i],
                rates[i],
                (kernels[i] - rates[i]) / 2,
            )?);

            let sd_w = vb
                .get(
                    (channels[i + 1], 18, sd_kernels[i]),
                    &format!("mel2wav.source_downs.{}.weight", i),
                )
                .map_err(anyhow::Error::msg)?;
            let sd_b = vb
                .get(
                    (channels[i + 1],),
                    &format!("mel2wav.source_downs.{}.bias", i),
                )
                .map_err(anyhow::Error::msg)?;
            source_downs.push(Linear::new(sd_w, Some(sd_b)));

            source_resblocks.push(ResBlock::load(
                vb.pp(&format!("mel2wav.source_resblocks.{}", i)),
                channels[i + 1],
                sd_res_kernels[i],
                &[1, 3, 5],
            )?);
        }

        let mut resblocks = Vec::new();
        for i in 0..3 {
            for j in 0..3 {
                resblocks.push(ResBlock::load(
                    vb.pp(&format!("mel2wav.resblocks.{}", i * 3 + j)),
                    channels[i + 1],
                    [3, 7, 11][j],
                    &[1, 3, 5],
                )?);
            }
        }

        let conv_post_w = vb
            .pp("mel2wav.conv_post.parametrizations.weight")
            .get((18, 64, 7), "original1")
            .map_err(anyhow::Error::msg)?;
        let conv_post_b = vb
            .get((18,), "mel2wav.conv_post.bias")
            .map_err(anyhow::Error::msg)?;
        let conv_post = Linear::new(conv_post_w, Some(conv_post_b));

        Ok(Self {
            f0_predictor,
            m_source,
            conv_pre,
            ups,
            source_downs,
            source_resblocks,
            resblocks,
            conv_post,
        })
    }

    pub fn forward(&self, mel: &Tensor) -> Result<Tensor> {
        let b = mel.dim(0)?;
        let t = mel.dim(2)?;

        // F0 branch
        let f0 = self.f0_predictor.forward(mel)?; // [B, T]
        let f0 = f0.unsqueeze(1)?; // [B, 1, T]

        // Upsample F0 to 24kHz (50Hz -> 24kHz: factor 480)
        let f0_up = f0
            .unsqueeze(2)?
            .upsample_nearest2d(1, t * 480)?
            .squeeze(2)?;

        let s = self.m_source.forward(&f0_up)?; // [B, 1, 120T]

        // s_stft: STFT of s with hop 4
        use pycandle_audio::{PadMode, StftConfig, stft};
        let stft_cfg = StftConfig {
            n_fft: 16,
            hop_length: Some(4),
            win_length: Some(16),
            center: true,
            pad_mode: PadMode::Reflect,
            ..Default::default()
        };
        // s is [B, 1, T_24k], stft expects [B, T_24k]
        let s_stft_complex = stft(&s.squeeze(1).map_err(anyhow::Error::msg)?, &stft_cfg, None)
            .map_err(anyhow::Error::msg)?; // [B, 9, T_voc, 2]
        let s_stft = s_stft_complex
            .reshape((b, 18, ()))
            .map_err(anyhow::Error::msg)?;

        let mut x = mel
            .conv1d(&self.conv_pre.weight(), 3, 1, 1, 1) // padding 3, stride 1
            .map_err(anyhow::Error::msg)?;
        if let Some(bias) = self.conv_pre.bias() {
            x = x
                .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                .map_err(anyhow::Error::msg)?;
        }

        let sd_strides = [15, 3, 1];
        let sd_paddings = [7, 1, 0];

        for i in 0..3 {
            x = candle_nn::ops::leaky_relu(&x, 0.1).map_err(anyhow::Error::msg)?;
            x = self.ups[i].forward(&x).map_err(anyhow::Error::msg)?;

            if i == 2 {
                // Reflection pad (1, 0)
                let zeros = Tensor::zeros((b, x.dim(1)?, 1), x.dtype(), x.device())?;
                x = Tensor::cat(&[&zeros, &x], 2)?;
            }

            // Fusion
            let mut si = s_stft
                .conv1d(
                    &self.source_downs[i].weight(),
                    sd_paddings[i],
                    sd_strides[i],
                    1,
                    1,
                )
                .map_err(anyhow::Error::msg)?;
            if let Some(bias) = self.source_downs[i].bias() {
                si = si
                    .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                    .map_err(anyhow::Error::msg)?;
            }
            si = self.source_resblocks[i].forward(&si, &[1, 3, 5])?;

            // si and x should now match exactly thanks to reflection_pad
            x = (x + si).map_err(anyhow::Error::msg)?;

            let mut res_sum: Option<Tensor> = None;
            for j in 0..3 {
                let r = self.resblocks[i * 3 + j].forward(&x, &[1, 3, 5])?;
                res_sum = match res_sum {
                    Some(s) => Some((s + r).map_err(anyhow::Error::msg)?),
                    None => Some(r),
                };
            }
            x = (res_sum.unwrap() / 3.0).map_err(anyhow::Error::msg)?;
        }

        x = x.relu().map_err(anyhow::Error::msg)?;
        x = x
            .conv1d(&self.conv_post.weight(), 3, 1, 1, 1) // padding 3, stride 1
            .map_err(anyhow::Error::msg)?;
        if let Some(bias) = self.conv_post.bias() {
            x = x
                .broadcast_add(&bias.reshape((1, (), 1)).map_err(anyhow::Error::msg)?)
                .map_err(anyhow::Error::msg)?;
        }

        // ISTFT: 18 channels -> 9 Mag, 9 Phase
        let mag = x
            .narrow(1, 0, 9)
            .map_err(anyhow::Error::msg)?
            .exp()
            .map_err(anyhow::Error::msg)?
            .clamp(0.0f32, 100.0f32)
            .map_err(anyhow::Error::msg)?;
        let phase = x
            .narrow(1, 9, 9)
            .map_err(anyhow::Error::msg)?;

        let real = mag
            .broadcast_mul(&phase.cos().map_err(anyhow::Error::msg)?)
            .map_err(anyhow::Error::msg)?;
        let imag = mag
            .broadcast_mul(&phase.sin().map_err(anyhow::Error::msg)?)
            .map_err(anyhow::Error::msg)?;

        // Zero out imaginary part for DC and Nyquist bins (0 and 8 for n_fft=16)
        // Hermitian symmetry: DC and Nyquist bins must be real (imag part must be exactly zero)
        let device = x.device();
        let t = imag.dim(2)?;
        let zero_row = Tensor::zeros((1, 1, t), DType::F32, device).map_err(anyhow::Error::msg)?;
        let mid = imag.narrow(1, 1, 7).map_err(anyhow::Error::msg)?;
        let imag = Tensor::cat(&[&zero_row, &mid, &zero_row], 1).map_err(anyhow::Error::msg)?;

        let spec = Tensor::cat(
            &[
                real.unsqueeze(3).map_err(anyhow::Error::msg)?,
                imag.unsqueeze(3).map_err(anyhow::Error::msg)?,
            ],
            3,
        )
        .map_err(anyhow::Error::msg)?;

        spec.squeeze(0).map_err(anyhow::Error::msg)
    }
}

pub struct Orchestrator {
    pub device: Device,
    pub tokenizer: Tokenizer,
    pub repo: Repo,
}

impl Orchestrator {
    pub fn load(device: &Device) -> Result<Self> {
        unsafe {
            std::env::set_var("HF_HOME", HF_CACHE);
        }
        let api = Api::new()?;
        let repo = Repo::new(REPO_ID.to_string(), RepoType::Model);
        let repo_handle = api.repo(repo.clone());

        println!(" Loading Tokenizer...");
        let vocab_path = repo_handle.get("vocab.json")?;
        let merges_path = repo_handle.get("merges.txt")?;

        use tokenizers::models::bpe::BPE;
        let bpe = BPE::from_file(vocab_path.to_str().unwrap(), merges_path.to_str().unwrap())
            .build()
            .map_err(anyhow::Error::msg)?;
        let tokenizer = Tokenizer::new(bpe);

        Ok(Self {
            device: device.clone(),
            tokenizer,
            repo,
        })
    }

    pub fn generate_sequential(
        &self,
        text: &str,
        _ref_audio_path: Option<PathBuf>,
    ) -> Result<Vec<f32>> {
        let text = punc_norm(text);
        println!(" Normalized text: \"{}\"", text);
        let tokens = self
            .tokenizer
            .encode(text, true)
            .map_err(anyhow::Error::msg)?;
        let text_tokens = Tensor::new(tokens.get_ids(), &self.device)?.unsqueeze(0)?;

        let api = Api::new()?;
        let repo_handle = api.repo(self.repo.clone());

        // Stage 1: Voice Encoding
        println!(" Stage 1: Voice Encoding...");
        let speaker_emb = {
            let ve_path = repo_handle.get("ve.safetensors")?;
            let vb_ve = unsafe {
                VarBuilder::from_mmaped_safetensors(&[ve_path], DType::F32, &self.device)?
            };
            let ve = VoiceEncoder::load(VEConfig {}, vb_ve, None).map_err(anyhow::Error::msg)?;
            let ref_path = if let Some(p) = _ref_audio_path {
                p
            } else {
                PathBuf::from("reference.wav")
            };
            println!(" Loading reference audio from {:?}...", ref_path);
            let mut reader = hound::WavReader::open(ref_path).map_err(anyhow::Error::msg)?;
            let spec = reader.spec();
            let samples: Vec<f32> = reader
                .samples::<i16>()
                .map(|s| s.unwrap() as f32 / 32768.0)
                .collect();
            let audio_tensor = Tensor::from_vec(samples, (1, reader.len() as usize), &self.device)
                .map_err(anyhow::Error::msg)?;

            // Compute Mel Spectrogram for VoiceEncoder (40 pins, 16k sr)
            use pycandle_audio::{
                MelNorm, MelScale, MelSpectrogramConfig, PadMode, StftConfig, mel_spectrogram,
            };
            let melspec_cfg = MelSpectrogramConfig {
                stft_config: StftConfig {
                    n_fft: 400,
                    hop_length: Some(160),
                    win_length: Some(400),
                    center: true,
                    pad_mode: PadMode::Reflect,
                    ..Default::default()
                },
                sample_rate: spec.sample_rate as usize,
                n_mels: 40,
                f_min: 0.0,
                f_max: Some(8000.0),
                mel_scale: MelScale::Htk,
                norm: MelNorm::None,
            };

            let mel =
                mel_spectrogram(&audio_tensor, &melspec_cfg, None).map_err(anyhow::Error::msg)?;
            // mel is (B, 40, T), VoiceEncoder expects (B, T, 40)
            let mel = mel.transpose(1, 2).map_err(anyhow::Error::msg)?;

            ve.forward(&mel).map_err(anyhow::Error::msg)?
        };
        // VoiceEncoder is dropped here

        // Stage 2: T3 Token Generation
        println!(" Stage 2: T3 Token Generation...");
        let speech_tokens = {
            let t3_path = repo_handle.get("t3_turbo_v1.safetensors")?;
            let vb_t3 = unsafe {
                VarBuilder::from_mmaped_safetensors(&[t3_path], DType::F32, &self.device)?
            };
            let t3 = T3Model::load(vb_t3).map_err(anyhow::Error::msg)?;
            t3.generate_tokens(&text_tokens, &speaker_emb, &self.device)
                .map_err(anyhow::Error::msg)?
        };
        println!(" Generated {} speech tokens.", speech_tokens.len());
        // T3Model is dropped here

        // Stage 3: S3Gen Waveform
        println!(" Stage 3: S3Gen Waveform Generation...");
        let audio_data = {
            let s3_path = repo_handle.get("s3gen_meanflow.safetensors")?;
            let vb_s3 = unsafe {
                VarBuilder::from_mmaped_safetensors(&[s3_path], DType::F32, &self.device)?
            };

            // Link Flow model to generate latents from T3 tokens
            use s3gen_flow::{Config as FlowConfig, S3GenFlow};
            let flow_cfg = FlowConfig {
                hidden_dim: 512,
                vocab_size: 6561,
            };
            let flow =
                S3GenFlow::load(flow_cfg, vb_s3.pp("flow"), None).map_err(anyhow::Error::msg)?;

            // tokens to tensor
            let speech_tokens_tensor = Tensor::new(speech_tokens, &self.device)?.unsqueeze(0)?;
            let latents = flow
                .mean_flow(&speech_tokens_tensor)
                .map_err(anyhow::Error::msg)?;
            println!("  (Latents Check: {:?})", latents.dims());

            let hift = HiFTGenerator::load(vb_s3).map_err(anyhow::Error::msg)?;
            let spec = hift.forward(&latents).map_err(anyhow::Error::msg)?;

            // ISTFT
            use pycandle_audio::{PadMode, StftConfig, istft};
            let istft_cfg = StftConfig {
                n_fft: 16,
                hop_length: Some(4),
                win_length: Some(16),
                center: true,
                pad_mode: PadMode::Reflect,
                ..Default::default()
            };
            let audio_tensor = istft(&spec, &istft_cfg, None).map_err(anyhow::Error::msg)?;
            audio_tensor.to_vec1::<f32>().map_err(anyhow::Error::msg)?
        };

        Ok(audio_data)
    }
}

fn main() -> Result<()> {
    let device = Device::Cpu;
    let orchestrator = Orchestrator::load(&device)?;

    let text = "I am a powerful agentic AI coding assistant designed by the Google Deepmind team.";
    let audio = orchestrator.generate_sequential(text, None)?;

    println!(" Saving output.wav ({} samples)...", audio.len());
    let spec = hound::WavSpec {
        channels: 1,
        sample_rate: 24000,
        bits_per_sample: 16,
        sample_format: hound::SampleFormat::Int,
    };
    let mut writer = hound::WavWriter::create("output.wav", spec)?;
    for &sample in audio.iter() {
        let s = (sample.max(-1.0).min(1.0) * 32767.0) as i16;
        writer.write_sample(s)?;
    }
    writer.finalize()?;
    println!(" Done! Audio saved to output.wav");

    Ok(())
}
</file>

<file path="dx_simulation/src/punc_norm.rs">
use regex::Regex;

pub fn punc_norm(text: &str) -> String {
    if text.is_empty() {
        return "You need to add some text for me to talk.".to_string();
    }

    let mut text = text.trim().to_string();

    // Capitalise first letter
    if let Some(first_char) = text.chars().next() {
        if first_char.is_lowercase() {
            let mut chars = text.chars();
            text = format!("{}{}", chars.next().unwrap().to_uppercase(), chars.as_str());
        }
    }

    // Remove multiple space chars
    let re_spaces = Regex::new(r"\s+").unwrap();
    text = re_spaces.replace_all(&text, " ").to_string();

    // Replace uncommon/llm punc
    let punc_to_replace = [
        ("", ", "),
        (":", ","),
        ("", "-"),
        ("", "-"),
        (" ,", ","),
        ("", "\""),
        ("", "\""),
        ("", "'"),
        ("", "'"),
    ];
    for (old, new) in punc_to_replace {
        text = text.replace(old, new);
    }

    // Add full stop if no ending punc
    let sentence_enders = ['.', '!', '?', '-', ','];
    if !text.is_empty() && !sentence_enders.contains(&text.chars().last().unwrap()) {
        text.push('.');
    }

    text
}
</file>

<file path="dx_simulation/src/s3gen_flow.rs">
use candle_core::{Result, Tensor};
use candle_nn::{Module, VarBuilder};
use pycandle_core::{PyChecker, py_check, layers::*};

pub struct Config {
    pub hidden_dim: usize, // 512
    pub vocab_size: usize, // 6561
}
pub struct S3GenFlow {
    pub decoder_estimator_down_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_down_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_down_blocks_0_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_down_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_down_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_down_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_down_blocks_0_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_down_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_down_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_down_blocks_0_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_down_blocks_0_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_down_blocks_0_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_down_blocks_0_2: CausalConv1d,
    pub decoder_estimator_final_block_block_0: CausalConv1d,
    pub decoder_estimator_final_block_block_1: Transpose,
    pub decoder_estimator_final_block_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_final_block_block_3: Transpose,
    pub decoder_estimator_final_block_block_4: Mish,
    pub decoder_estimator_final_proj: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_0_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_0_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_0_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_0_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_1_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_1_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_1_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_1_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_1_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_1_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_1_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_1_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_1_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_10_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_10_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_10_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_10_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_10_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_10_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_10_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_10_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_10_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_11_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_11_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_11_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_11_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_11_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_11_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_11_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_11_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_11_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_2_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_2_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_2_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_2_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_2_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_2_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_2_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_2_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_2_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_3_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_3_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_3_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_3_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_3_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_3_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_3_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_3_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_3_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_4_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_4_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_4_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_4_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_4_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_4_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_4_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_4_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_4_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_5_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_5_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_5_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_5_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_5_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_5_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_5_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_5_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_5_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_6_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_6_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_6_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_6_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_6_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_6_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_6_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_6_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_6_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_7_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_7_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_7_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_7_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_7_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_7_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_7_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_7_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_7_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_8_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_8_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_8_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_8_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_8_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_8_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_8_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_8_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_8_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_9_0_block1_block_1: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block1_block_3: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block1_block_4: Mish,
    pub decoder_estimator_mid_blocks_9_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_mid_blocks_9_0_block2_block_1: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_0_block2_block_3: Transpose,
    pub decoder_estimator_mid_blocks_9_0_block2_block_4: Mish,
    pub decoder_estimator_mid_blocks_9_0_mlp_0: Mish,
    pub decoder_estimator_mid_blocks_9_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_1: Dropout,
    pub decoder_estimator_mid_blocks_9_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_mid_blocks_9_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_mid_blocks_9_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_time_embeddings: SinusoidalPosEmb,
    pub decoder_estimator_time_mlp_act: SiLU,
    pub decoder_estimator_time_mlp_linear_1: candle_nn::Linear,
    pub decoder_estimator_time_mlp_linear_2: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_0_block1_block_0: CausalConv1d,
    pub decoder_estimator_up_blocks_0_0_block1_block_1: Transpose,
    pub decoder_estimator_up_blocks_0_0_block1_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_0_block1_block_3: Transpose,
    pub decoder_estimator_up_blocks_0_0_block1_block_4: Mish,
    pub decoder_estimator_up_blocks_0_0_block2_block_0: CausalConv1d,
    pub decoder_estimator_up_blocks_0_0_block2_block_1: Transpose,
    pub decoder_estimator_up_blocks_0_0_block2_block_2: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_0_block2_block_3: Transpose,
    pub decoder_estimator_up_blocks_0_0_block2_block_4: Mish,
    pub decoder_estimator_up_blocks_0_0_mlp_0: Mish,
    pub decoder_estimator_up_blocks_0_0_mlp_1: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_0_res_conv: candle_nn::Conv1d,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_0_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_0_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_0_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_1_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_1_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_1_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_2_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_2_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_2_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_k: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_out_0: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_out_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_q: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_attn1_to_v: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_0_proj: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_1: Dropout,
    pub decoder_estimator_up_blocks_0_1_3_ff_net_2: candle_nn::Linear,
    pub decoder_estimator_up_blocks_0_1_3_norm1: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_1_3_norm3: candle_nn::LayerNorm,
    pub decoder_estimator_up_blocks_0_2: CausalConv1d,
    pub encoder_after_norm: candle_nn::LayerNorm,
    pub encoder_embed_out_0: candle_nn::Linear,
    pub encoder_embed_out_1: candle_nn::LayerNorm,
    pub encoder_embed_out_2: Dropout,
    pub encoder_embed_pos_enc_dropout: Dropout,
    pub encoder_embed_pos_enc_dropout_1: Dropout,
    pub encoder_encoders_0_dropout: Dropout,
    pub encoder_encoders_0_dropout_1: Dropout,
    pub encoder_encoders_0_feed_forward_activation: SiLU,
    pub encoder_encoders_0_feed_forward_activation_1: SiLU,
    pub encoder_encoders_0_feed_forward_activation_2: SiLU,
    pub encoder_encoders_0_feed_forward_activation_3: SiLU,
    pub encoder_encoders_0_feed_forward_activation_4: SiLU,
    pub encoder_encoders_0_feed_forward_activation_5: SiLU,
    pub encoder_encoders_0_feed_forward_activation_6: SiLU,
    pub encoder_encoders_0_feed_forward_activation_7: SiLU,
    pub encoder_encoders_0_feed_forward_activation_8: SiLU,
    pub encoder_encoders_0_feed_forward_activation_9: SiLU,
    pub encoder_encoders_0_feed_forward_dropout: Dropout,
    pub encoder_encoders_0_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_0_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_0_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_0_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_0_self_attn_dropout: Dropout,
    pub encoder_encoders_0_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_0_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_0_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_0_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_0_self_attn_linear_v: candle_nn::Linear,
    pub encoder_encoders_1_dropout: Dropout,
    pub encoder_encoders_1_dropout_1: Dropout,
    pub encoder_encoders_1_feed_forward_dropout: Dropout,
    pub encoder_encoders_1_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_1_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_1_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_1_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_1_self_attn_dropout: Dropout,
    pub encoder_encoders_1_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_1_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_1_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_1_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_1_self_attn_linear_v: candle_nn::Linear,
    pub encoder_encoders_2_dropout: Dropout,
    pub encoder_encoders_2_dropout_1: Dropout,
    pub encoder_encoders_2_feed_forward_dropout: Dropout,
    pub encoder_encoders_2_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_2_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_2_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_2_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_2_self_attn_dropout: Dropout,
    pub encoder_encoders_2_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_2_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_2_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_2_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_2_self_attn_linear_v: candle_nn::Linear,
    pub encoder_encoders_3_dropout: Dropout,
    pub encoder_encoders_3_dropout_1: Dropout,
    pub encoder_encoders_3_feed_forward_dropout: Dropout,
    pub encoder_encoders_3_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_3_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_3_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_3_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_3_self_attn_dropout: Dropout,
    pub encoder_encoders_3_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_3_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_3_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_3_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_3_self_attn_linear_v: candle_nn::Linear,
    pub encoder_encoders_4_dropout: Dropout,
    pub encoder_encoders_4_dropout_1: Dropout,
    pub encoder_encoders_4_feed_forward_dropout: Dropout,
    pub encoder_encoders_4_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_4_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_4_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_4_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_4_self_attn_dropout: Dropout,
    pub encoder_encoders_4_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_4_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_4_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_4_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_4_self_attn_linear_v: candle_nn::Linear,
    pub encoder_encoders_5_dropout: Dropout,
    pub encoder_encoders_5_dropout_1: Dropout,
    pub encoder_encoders_5_feed_forward_dropout: Dropout,
    pub encoder_encoders_5_feed_forward_w_1: candle_nn::Linear,
    pub encoder_encoders_5_feed_forward_w_2: candle_nn::Linear,
    pub encoder_encoders_5_norm_ff: candle_nn::LayerNorm,
    pub encoder_encoders_5_norm_mha: candle_nn::LayerNorm,
    pub encoder_encoders_5_self_attn_dropout: Dropout,
    pub encoder_encoders_5_self_attn_linear_k: candle_nn::Linear,
    pub encoder_encoders_5_self_attn_linear_out: candle_nn::Linear,
    pub encoder_encoders_5_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_encoders_5_self_attn_linear_q: candle_nn::Linear,
    pub encoder_encoders_5_self_attn_linear_v: candle_nn::Linear,
    pub encoder_pre_lookahead_layer_conv1: candle_nn::Conv1d,
    pub encoder_pre_lookahead_layer_conv2: candle_nn::Conv1d,
    pub encoder_up_embed_out_0: candle_nn::Linear,
    pub encoder_up_embed_out_1: candle_nn::LayerNorm,
    pub encoder_up_embed_out_2: Dropout,
    pub encoder_up_embed_pos_enc_dropout: Dropout,
    pub encoder_up_embed_pos_enc_dropout_1: Dropout,
    pub encoder_up_encoders_0_dropout: Dropout,
    pub encoder_up_encoders_0_dropout_1: Dropout,
    pub encoder_up_encoders_0_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_0_feed_forward_w_1: candle_nn::Linear,
    pub encoder_up_encoders_0_feed_forward_w_2: candle_nn::Linear,
    pub encoder_up_encoders_0_norm_ff: candle_nn::LayerNorm,
    pub encoder_up_encoders_0_norm_mha: candle_nn::LayerNorm,
    pub encoder_up_encoders_0_self_attn_dropout: Dropout,
    pub encoder_up_encoders_0_self_attn_linear_k: candle_nn::Linear,
    pub encoder_up_encoders_0_self_attn_linear_out: candle_nn::Linear,
    pub encoder_up_encoders_0_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_up_encoders_0_self_attn_linear_q: candle_nn::Linear,
    pub encoder_up_encoders_0_self_attn_linear_v: candle_nn::Linear,
    pub encoder_up_encoders_1_dropout: Dropout,
    pub encoder_up_encoders_1_dropout_1: Dropout,
    pub encoder_up_encoders_1_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_1_feed_forward_w_1: candle_nn::Linear,
    pub encoder_up_encoders_1_feed_forward_w_2: candle_nn::Linear,
    pub encoder_up_encoders_1_norm_ff: candle_nn::LayerNorm,
    pub encoder_up_encoders_1_norm_mha: candle_nn::LayerNorm,
    pub encoder_up_encoders_1_self_attn_dropout: Dropout,
    pub encoder_up_encoders_1_self_attn_linear_k: candle_nn::Linear,
    pub encoder_up_encoders_1_self_attn_linear_out: candle_nn::Linear,
    pub encoder_up_encoders_1_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_up_encoders_1_self_attn_linear_q: candle_nn::Linear,
    pub encoder_up_encoders_1_self_attn_linear_v: candle_nn::Linear,
    pub encoder_up_encoders_2_dropout: Dropout,
    pub encoder_up_encoders_2_dropout_1: Dropout,
    pub encoder_up_encoders_2_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_2_feed_forward_w_1: candle_nn::Linear,
    pub encoder_up_encoders_2_feed_forward_w_2: candle_nn::Linear,
    pub encoder_up_encoders_2_norm_ff: candle_nn::LayerNorm,
    pub encoder_up_encoders_2_norm_mha: candle_nn::LayerNorm,
    pub encoder_up_encoders_2_self_attn_dropout: Dropout,
    pub encoder_up_encoders_2_self_attn_linear_k: candle_nn::Linear,
    pub encoder_up_encoders_2_self_attn_linear_out: candle_nn::Linear,
    pub encoder_up_encoders_2_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_up_encoders_2_self_attn_linear_q: candle_nn::Linear,
    pub encoder_up_encoders_2_self_attn_linear_v: candle_nn::Linear,
    pub encoder_up_encoders_3_dropout: Dropout,
    pub encoder_up_encoders_3_dropout_1: Dropout,
    pub encoder_up_encoders_3_feed_forward_dropout: Dropout,
    pub encoder_up_encoders_3_feed_forward_w_1: candle_nn::Linear,
    pub encoder_up_encoders_3_feed_forward_w_2: candle_nn::Linear,
    pub encoder_up_encoders_3_norm_ff: candle_nn::LayerNorm,
    pub encoder_up_encoders_3_norm_mha: candle_nn::LayerNorm,
    pub encoder_up_encoders_3_self_attn_dropout: Dropout,
    pub encoder_up_encoders_3_self_attn_linear_k: candle_nn::Linear,
    pub encoder_up_encoders_3_self_attn_linear_out: candle_nn::Linear,
    pub encoder_up_encoders_3_self_attn_linear_pos: candle_nn::Linear,
    pub encoder_up_encoders_3_self_attn_linear_q: candle_nn::Linear,
    pub encoder_up_encoders_3_self_attn_linear_v: candle_nn::Linear,
    pub encoder_up_layer_conv: candle_nn::Conv1d,
    pub encoder_proj: candle_nn::Linear,
    pub input_embedding: candle_nn::Embedding,
    pub spk_embed_affine_layer: candle_nn::Linear,
    pub checker: Option<PyChecker>,
}

impl S3GenFlow {
    #[allow(unused_variables)]
    pub fn load(config: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let decoder_estimator_down_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.0.block1.block.0"), 320, 256, 3, 1, true)?;
        let decoder_estimator_down_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_down_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_down_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_down_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_down_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_down_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_down_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_down_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.0.mlp.1"))?;
        let decoder_estimator_down_blocks_0_0_res_conv = candle_nn::conv1d(320, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.0.res_conv"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.0.norm1"))?;
        let decoder_estimator_down_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.0.norm3"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.1.norm1"))?;
        let decoder_estimator_down_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.1.norm3"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.2.norm1"))?;
        let decoder_estimator_down_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.2.norm3"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_down_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.down_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_down_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.down_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_down_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_down_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.down_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_down_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.3.norm1"))?;
        let decoder_estimator_down_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.down_blocks.0.1.3.norm3"))?;
        let decoder_estimator_down_blocks_0_2 = CausalConv1d::load(vb.pp("decoder.estimator.down_blocks.0.2"), 256, 256, 3, 1, true)?;
        let decoder_estimator_final_block_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.final_block.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_final_block_block_1 = Transpose::new(1, 2);
        let decoder_estimator_final_block_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.final_block.block.2"))?;
        let decoder_estimator_final_block_block_3 = Transpose::new(1, 2);
        let decoder_estimator_final_block_block_4 = Mish;
        let decoder_estimator_final_proj = candle_nn::conv1d(256, 80, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.final_proj"))?;
        let decoder_estimator_mid_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.0.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_0_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.0.res_conv"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.0.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_1_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.1.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_1_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_1_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_1_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.1.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_1_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_1_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_1_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_1_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_1_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_1_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.0.res_conv"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_1_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.1.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_1_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_1_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.1.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_1_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_1_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.1.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_10_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.10.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_10_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_10_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_10_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.10.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_10_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_10_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_10_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_10_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_10_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_10_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.0.res_conv"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_10_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.10.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_10_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_10_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.10.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_10_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_10_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.10.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_11_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.11.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_11_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_11_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_11_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.11.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_11_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_11_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_11_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_11_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_11_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_11_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.0.res_conv"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_11_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.11.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_11_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_11_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.11.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_11_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_11_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.11.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_2_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.2.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_2_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_2_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_2_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.2.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_2_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_2_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_2_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_2_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_2_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_2_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.0.res_conv"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_2_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.2.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_2_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_2_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.2.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_2_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_2_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.2.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_3_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.3.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_3_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_3_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_3_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.3.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_3_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_3_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_3_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_3_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_3_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_3_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.0.res_conv"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_3_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.3.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_3_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_3_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.3.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_3_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_3_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.3.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_4_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.4.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_4_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_4_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_4_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.4.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_4_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_4_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_4_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_4_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_4_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_4_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.0.res_conv"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_4_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.4.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_4_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_4_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.4.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_4_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_4_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.4.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_5_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.5.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_5_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_5_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_5_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.5.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_5_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_5_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_5_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_5_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_5_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_5_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.0.res_conv"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_5_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.5.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_5_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_5_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.5.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_5_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_5_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.5.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_6_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.6.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_6_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_6_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_6_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.6.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_6_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_6_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_6_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_6_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_6_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_6_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.0.res_conv"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_6_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.6.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_6_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_6_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.6.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_6_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_6_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.6.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_7_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.7.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_7_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_7_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_7_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.7.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_7_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_7_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_7_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_7_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_7_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_7_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.0.res_conv"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_7_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.7.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_7_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_7_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.7.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_7_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_7_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.7.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_8_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.8.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_8_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_8_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_8_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.8.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_8_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_8_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_8_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_8_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_8_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_8_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.0.res_conv"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_8_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.8.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_8_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_8_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.8.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_8_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_8_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.8.1.3.norm3"))?;
        let decoder_estimator_mid_blocks_9_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.9.0.block1.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_9_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.block1.block.2"))?;
        let decoder_estimator_mid_blocks_9_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block1_block_4 = Mish;
        let decoder_estimator_mid_blocks_9_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.mid_blocks.9.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_mid_blocks_9_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.block2.block.2"))?;
        let decoder_estimator_mid_blocks_9_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_mid_blocks_9_0_block2_block_4 = Mish;
        let decoder_estimator_mid_blocks_9_0_mlp_0 = Mish;
        let decoder_estimator_mid_blocks_9_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.0.mlp.1"))?;
        let decoder_estimator_mid_blocks_9_0_res_conv = candle_nn::conv1d(256, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.0.res_conv"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.0.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.0.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.0.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.0.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.1.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.1.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.1.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.1.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.2.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.2.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.2.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.2.norm3"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_k"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_q"))?;
        let decoder_estimator_mid_blocks_9_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.mid_blocks.9.1.3.attn1.to_v"))?;
        let decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj"))?;
        let decoder_estimator_mid_blocks_9_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_mid_blocks_9_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.mid_blocks.9.1.3.ff.net.2"))?;
        let decoder_estimator_mid_blocks_9_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.3.norm1"))?;
        let decoder_estimator_mid_blocks_9_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.mid_blocks.9.1.3.norm3"))?;
        let decoder_estimator_time_embeddings = SinusoidalPosEmb::new(320);
        let decoder_estimator_time_mlp_act = SiLU;
        let decoder_estimator_time_mlp_linear_1 = candle_nn::linear(320, 1024, vb.pp("decoder.estimator.time_mlp.linear_1"))?;
        let decoder_estimator_time_mlp_linear_2 = { let w = vb.pp("decoder.estimator.time_mlp.linear_2").get((1024, 1024), "weight")?.t()?; let b = Some(vb.pp("decoder.estimator.time_mlp.linear_2").get(1024, "bias")?); candle_nn::Linear::new(w, b) };
        let decoder_estimator_up_blocks_0_0_block1_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.0.block1.block.0"), config.hidden_dim, 256, 3, 1, true)?;
        let decoder_estimator_up_blocks_0_0_block1_block_1 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block1_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.block1.block.2"))?;
        let decoder_estimator_up_blocks_0_0_block1_block_3 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block1_block_4 = Mish;
        let decoder_estimator_up_blocks_0_0_block2_block_0 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.0.block2.block.0"), 256, 256, 3, 1, true)?;
        let decoder_estimator_up_blocks_0_0_block2_block_1 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block2_block_2 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.block2.block.2"))?;
        let decoder_estimator_up_blocks_0_0_block2_block_3 = Transpose::new(1, 2);
        let decoder_estimator_up_blocks_0_0_block2_block_4 = Mish;
        let decoder_estimator_up_blocks_0_0_mlp_0 = Mish;
        let decoder_estimator_up_blocks_0_0_mlp_1 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.0.mlp.1"))?;
        let decoder_estimator_up_blocks_0_0_res_conv = candle_nn::conv1d(config.hidden_dim, 256, 1, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.0.res_conv"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_0_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_0_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.0.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_0_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.0.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_0_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_0_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.0.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_0_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.0.norm1"))?;
        let decoder_estimator_up_blocks_0_1_0_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.0.norm3"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_1_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_1_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.1.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_1_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.1.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_1_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_1_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.1.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_1_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.1.norm1"))?;
        let decoder_estimator_up_blocks_0_1_1_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.1.norm3"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_2_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_2_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.2.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_2_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.2.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_2_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_2_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.2.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_2_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.2.norm1"))?;
        let decoder_estimator_up_blocks_0_1_2_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.2.norm3"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_k = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_k"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_out_0 = candle_nn::linear(config.hidden_dim, 256, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_out.0"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_out_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_3_attn1_to_q = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_q"))?;
        let decoder_estimator_up_blocks_0_1_3_attn1_to_v = candle_nn::linear_no_bias(256, config.hidden_dim, vb.pp("decoder.estimator.up_blocks.0.1.3.attn1.to_v"))?;
        let decoder_estimator_up_blocks_0_1_3_ff_net_0_proj = candle_nn::linear(256, 1024, vb.pp("decoder.estimator.up_blocks.0.1.3.ff.net.0.proj"))?;
        let decoder_estimator_up_blocks_0_1_3_ff_net_1 = Dropout::new();
        let decoder_estimator_up_blocks_0_1_3_ff_net_2 = candle_nn::linear(1024, 256, vb.pp("decoder.estimator.up_blocks.0.1.3.ff.net.2"))?;
        let decoder_estimator_up_blocks_0_1_3_norm1 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.3.norm1"))?;
        let decoder_estimator_up_blocks_0_1_3_norm3 = candle_nn::layer_norm(256, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("decoder.estimator.up_blocks.0.1.3.norm3"))?;
        let decoder_estimator_up_blocks_0_2 = CausalConv1d::load(vb.pp("decoder.estimator.up_blocks.0.2"), 256, 256, 3, 1, true)?;
        let encoder_after_norm = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.after_norm"))?;
        let encoder_embed_out_0 = { let w = vb.pp("encoder.embed.out.0").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.embed.out.0").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_embed_out_1 = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.embed.out.1"))?;
        let encoder_embed_out_2 = Dropout::new();
        let encoder_embed_pos_enc_dropout = Dropout::new();
        let encoder_embed_pos_enc_dropout_1 = Dropout::new();
        let encoder_encoders_0_dropout = Dropout::new();
        let encoder_encoders_0_dropout_1 = Dropout::new();
        let encoder_encoders_0_feed_forward_activation = SiLU;
        let encoder_encoders_0_feed_forward_activation_1 = SiLU;
        let encoder_encoders_0_feed_forward_activation_2 = SiLU;
        let encoder_encoders_0_feed_forward_activation_3 = SiLU;
        let encoder_encoders_0_feed_forward_activation_4 = SiLU;
        let encoder_encoders_0_feed_forward_activation_5 = SiLU;
        let encoder_encoders_0_feed_forward_activation_6 = SiLU;
        let encoder_encoders_0_feed_forward_activation_7 = SiLU;
        let encoder_encoders_0_feed_forward_activation_8 = SiLU;
        let encoder_encoders_0_feed_forward_activation_9 = SiLU;
        let encoder_encoders_0_feed_forward_dropout = Dropout::new();
        let encoder_encoders_0_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.0.feed_forward.w_1"))?;
        let encoder_encoders_0_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.0.feed_forward.w_2"))?;
        let encoder_encoders_0_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.0.norm_ff"))?;
        let encoder_encoders_0_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.0.norm_mha"))?;
        let encoder_encoders_0_self_attn_dropout = Dropout::new();
        let encoder_encoders_0_self_attn_linear_k = { let w = vb.pp("encoder.encoders.0.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_out = { let w = vb.pp("encoder.encoders.0.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.0.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_q = { let w = vb.pp("encoder.encoders.0.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_0_self_attn_linear_v = { let w = vb.pp("encoder.encoders.0.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.0.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_1_dropout = Dropout::new();
        let encoder_encoders_1_dropout_1 = Dropout::new();
        let encoder_encoders_1_feed_forward_dropout = Dropout::new();
        let encoder_encoders_1_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.1.feed_forward.w_1"))?;
        let encoder_encoders_1_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.1.feed_forward.w_2"))?;
        let encoder_encoders_1_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.1.norm_ff"))?;
        let encoder_encoders_1_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.1.norm_mha"))?;
        let encoder_encoders_1_self_attn_dropout = Dropout::new();
        let encoder_encoders_1_self_attn_linear_k = { let w = vb.pp("encoder.encoders.1.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_out = { let w = vb.pp("encoder.encoders.1.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.1.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_q = { let w = vb.pp("encoder.encoders.1.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_1_self_attn_linear_v = { let w = vb.pp("encoder.encoders.1.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.1.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_2_dropout = Dropout::new();
        let encoder_encoders_2_dropout_1 = Dropout::new();
        let encoder_encoders_2_feed_forward_dropout = Dropout::new();
        let encoder_encoders_2_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.2.feed_forward.w_1"))?;
        let encoder_encoders_2_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.2.feed_forward.w_2"))?;
        let encoder_encoders_2_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.2.norm_ff"))?;
        let encoder_encoders_2_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.2.norm_mha"))?;
        let encoder_encoders_2_self_attn_dropout = Dropout::new();
        let encoder_encoders_2_self_attn_linear_k = { let w = vb.pp("encoder.encoders.2.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_out = { let w = vb.pp("encoder.encoders.2.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.2.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_q = { let w = vb.pp("encoder.encoders.2.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_2_self_attn_linear_v = { let w = vb.pp("encoder.encoders.2.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.2.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_3_dropout = Dropout::new();
        let encoder_encoders_3_dropout_1 = Dropout::new();
        let encoder_encoders_3_feed_forward_dropout = Dropout::new();
        let encoder_encoders_3_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.3.feed_forward.w_1"))?;
        let encoder_encoders_3_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.3.feed_forward.w_2"))?;
        let encoder_encoders_3_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.3.norm_ff"))?;
        let encoder_encoders_3_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.3.norm_mha"))?;
        let encoder_encoders_3_self_attn_dropout = Dropout::new();
        let encoder_encoders_3_self_attn_linear_k = { let w = vb.pp("encoder.encoders.3.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_out = { let w = vb.pp("encoder.encoders.3.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.3.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_q = { let w = vb.pp("encoder.encoders.3.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_3_self_attn_linear_v = { let w = vb.pp("encoder.encoders.3.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.3.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_4_dropout = Dropout::new();
        let encoder_encoders_4_dropout_1 = Dropout::new();
        let encoder_encoders_4_feed_forward_dropout = Dropout::new();
        let encoder_encoders_4_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.4.feed_forward.w_1"))?;
        let encoder_encoders_4_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.4.feed_forward.w_2"))?;
        let encoder_encoders_4_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.4.norm_ff"))?;
        let encoder_encoders_4_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.4.norm_mha"))?;
        let encoder_encoders_4_self_attn_dropout = Dropout::new();
        let encoder_encoders_4_self_attn_linear_k = { let w = vb.pp("encoder.encoders.4.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_out = { let w = vb.pp("encoder.encoders.4.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.4.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_q = { let w = vb.pp("encoder.encoders.4.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_4_self_attn_linear_v = { let w = vb.pp("encoder.encoders.4.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.4.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_5_dropout = Dropout::new();
        let encoder_encoders_5_dropout_1 = Dropout::new();
        let encoder_encoders_5_feed_forward_dropout = Dropout::new();
        let encoder_encoders_5_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.encoders.5.feed_forward.w_1"))?;
        let encoder_encoders_5_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.encoders.5.feed_forward.w_2"))?;
        let encoder_encoders_5_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.5.norm_ff"))?;
        let encoder_encoders_5_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.encoders.5.norm_mha"))?;
        let encoder_encoders_5_self_attn_dropout = Dropout::new();
        let encoder_encoders_5_self_attn_linear_k = { let w = vb.pp("encoder.encoders.5.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_out = { let w = vb.pp("encoder.encoders.5.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_pos = { let w = vb.pp("encoder.encoders.5.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_q = { let w = vb.pp("encoder.encoders.5.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_encoders_5_self_attn_linear_v = { let w = vb.pp("encoder.encoders.5.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.encoders.5.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_pre_lookahead_layer_conv1 = candle_nn::conv1d(config.hidden_dim, config.hidden_dim, 4, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.pre_lookahead_layer.conv1"))?;
        let encoder_pre_lookahead_layer_conv2 = candle_nn::conv1d(config.hidden_dim, config.hidden_dim, 3, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.pre_lookahead_layer.conv2"))?;
        let encoder_up_embed_out_0 = { let w = vb.pp("encoder.up_embed.out.0").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_embed.out.0").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_embed_out_1 = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("encoder.up_embed.out.1"))?;
        let encoder_up_embed_out_2 = Dropout::new();
        let encoder_up_embed_pos_enc_dropout = Dropout::new();
        let encoder_up_embed_pos_enc_dropout_1 = Dropout::new();
        let encoder_up_encoders_0_dropout = Dropout::new();
        let encoder_up_encoders_0_dropout_1 = Dropout::new();
        let encoder_up_encoders_0_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_0_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.up_encoders.0.feed_forward.w_1"))?;
        let encoder_up_encoders_0_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.up_encoders.0.feed_forward.w_2"))?;
        let encoder_up_encoders_0_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.0.norm_ff"))?;
        let encoder_up_encoders_0_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.0.norm_mha"))?;
        let encoder_up_encoders_0_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_0_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_0_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.0.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.0.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_1_dropout = Dropout::new();
        let encoder_up_encoders_1_dropout_1 = Dropout::new();
        let encoder_up_encoders_1_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_1_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.up_encoders.1.feed_forward.w_1"))?;
        let encoder_up_encoders_1_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.up_encoders.1.feed_forward.w_2"))?;
        let encoder_up_encoders_1_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.1.norm_ff"))?;
        let encoder_up_encoders_1_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.1.norm_mha"))?;
        let encoder_up_encoders_1_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_1_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_1_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.1.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.1.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_2_dropout = Dropout::new();
        let encoder_up_encoders_2_dropout_1 = Dropout::new();
        let encoder_up_encoders_2_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_2_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.up_encoders.2.feed_forward.w_1"))?;
        let encoder_up_encoders_2_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.up_encoders.2.feed_forward.w_2"))?;
        let encoder_up_encoders_2_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.2.norm_ff"))?;
        let encoder_up_encoders_2_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.2.norm_mha"))?;
        let encoder_up_encoders_2_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_2_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_2_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.2.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.2.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_3_dropout = Dropout::new();
        let encoder_up_encoders_3_dropout_1 = Dropout::new();
        let encoder_up_encoders_3_feed_forward_dropout = Dropout::new();
        let encoder_up_encoders_3_feed_forward_w_1 = candle_nn::linear(config.hidden_dim, 2048, vb.pp("encoder.up_encoders.3.feed_forward.w_1"))?;
        let encoder_up_encoders_3_feed_forward_w_2 = candle_nn::linear(2048, config.hidden_dim, vb.pp("encoder.up_encoders.3.feed_forward.w_2"))?;
        let encoder_up_encoders_3_norm_ff = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.3.norm_ff"))?;
        let encoder_up_encoders_3_norm_mha = candle_nn::layer_norm(512, candle_nn::LayerNormConfig { eps: 1.0e-12, ..Default::default() }, vb.pp("encoder.up_encoders.3.norm_mha"))?;
        let encoder_up_encoders_3_self_attn_dropout = Dropout::new();
        let encoder_up_encoders_3_self_attn_linear_k = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_k").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_k").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_out = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_out").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_out").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_pos = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_pos").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = None; candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_q = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_q").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_q").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_encoders_3_self_attn_linear_v = { let w = vb.pp("encoder.up_encoders.3.self_attn.linear_v").get((config.hidden_dim, config.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("encoder.up_encoders.3.self_attn.linear_v").get(config.hidden_dim, "bias")?); candle_nn::Linear::new(w, b) };
        let encoder_up_layer_conv = candle_nn::conv1d(config.hidden_dim, config.hidden_dim, 5, candle_nn::Conv1dConfig { stride: 1, padding: 0, ..Default::default() }, vb.pp("encoder.up_layer.conv"))?;
        let encoder_proj = candle_nn::linear(config.hidden_dim, 80, vb.pp("encoder_proj"))?;
        let input_embedding = candle_nn::embedding(config.vocab_size, config.hidden_dim, vb.pp("input_embedding"))?;
        let spk_embed_affine_layer = candle_nn::linear(192, 80, vb.pp("spk_embed_affine_layer"))?;
        Ok(Self { decoder_estimator_down_blocks_0_0_block1_block_0, decoder_estimator_down_blocks_0_0_block1_block_1, decoder_estimator_down_blocks_0_0_block1_block_2, decoder_estimator_down_blocks_0_0_block1_block_3, decoder_estimator_down_blocks_0_0_block1_block_4, decoder_estimator_down_blocks_0_0_block2_block_0, decoder_estimator_down_blocks_0_0_block2_block_1, decoder_estimator_down_blocks_0_0_block2_block_2, decoder_estimator_down_blocks_0_0_block2_block_3, decoder_estimator_down_blocks_0_0_block2_block_4, decoder_estimator_down_blocks_0_0_mlp_0, decoder_estimator_down_blocks_0_0_mlp_1, decoder_estimator_down_blocks_0_0_res_conv, decoder_estimator_down_blocks_0_1_0_attn1_to_k, decoder_estimator_down_blocks_0_1_0_attn1_to_out_0, decoder_estimator_down_blocks_0_1_0_attn1_to_out_1, decoder_estimator_down_blocks_0_1_0_attn1_to_q, decoder_estimator_down_blocks_0_1_0_attn1_to_v, decoder_estimator_down_blocks_0_1_0_ff_net_0_proj, decoder_estimator_down_blocks_0_1_0_ff_net_1, decoder_estimator_down_blocks_0_1_0_ff_net_2, decoder_estimator_down_blocks_0_1_0_norm1, decoder_estimator_down_blocks_0_1_0_norm3, decoder_estimator_down_blocks_0_1_1_attn1_to_k, decoder_estimator_down_blocks_0_1_1_attn1_to_out_0, decoder_estimator_down_blocks_0_1_1_attn1_to_out_1, decoder_estimator_down_blocks_0_1_1_attn1_to_q, decoder_estimator_down_blocks_0_1_1_attn1_to_v, decoder_estimator_down_blocks_0_1_1_ff_net_0_proj, decoder_estimator_down_blocks_0_1_1_ff_net_1, decoder_estimator_down_blocks_0_1_1_ff_net_2, decoder_estimator_down_blocks_0_1_1_norm1, decoder_estimator_down_blocks_0_1_1_norm3, decoder_estimator_down_blocks_0_1_2_attn1_to_k, decoder_estimator_down_blocks_0_1_2_attn1_to_out_0, decoder_estimator_down_blocks_0_1_2_attn1_to_out_1, decoder_estimator_down_blocks_0_1_2_attn1_to_q, decoder_estimator_down_blocks_0_1_2_attn1_to_v, decoder_estimator_down_blocks_0_1_2_ff_net_0_proj, decoder_estimator_down_blocks_0_1_2_ff_net_1, decoder_estimator_down_blocks_0_1_2_ff_net_2, decoder_estimator_down_blocks_0_1_2_norm1, decoder_estimator_down_blocks_0_1_2_norm3, decoder_estimator_down_blocks_0_1_3_attn1_to_k, decoder_estimator_down_blocks_0_1_3_attn1_to_out_0, decoder_estimator_down_blocks_0_1_3_attn1_to_out_1, decoder_estimator_down_blocks_0_1_3_attn1_to_q, decoder_estimator_down_blocks_0_1_3_attn1_to_v, decoder_estimator_down_blocks_0_1_3_ff_net_0_proj, decoder_estimator_down_blocks_0_1_3_ff_net_1, decoder_estimator_down_blocks_0_1_3_ff_net_2, decoder_estimator_down_blocks_0_1_3_norm1, decoder_estimator_down_blocks_0_1_3_norm3, decoder_estimator_down_blocks_0_2, decoder_estimator_final_block_block_0, decoder_estimator_final_block_block_1, decoder_estimator_final_block_block_2, decoder_estimator_final_block_block_3, decoder_estimator_final_block_block_4, decoder_estimator_final_proj, decoder_estimator_mid_blocks_0_0_block1_block_0, decoder_estimator_mid_blocks_0_0_block1_block_1, decoder_estimator_mid_blocks_0_0_block1_block_2, decoder_estimator_mid_blocks_0_0_block1_block_3, decoder_estimator_mid_blocks_0_0_block1_block_4, decoder_estimator_mid_blocks_0_0_block2_block_0, decoder_estimator_mid_blocks_0_0_block2_block_1, decoder_estimator_mid_blocks_0_0_block2_block_2, decoder_estimator_mid_blocks_0_0_block2_block_3, decoder_estimator_mid_blocks_0_0_block2_block_4, decoder_estimator_mid_blocks_0_0_mlp_0, decoder_estimator_mid_blocks_0_0_mlp_1, decoder_estimator_mid_blocks_0_0_res_conv, decoder_estimator_mid_blocks_0_1_0_attn1_to_k, decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_0_1_0_attn1_to_q, decoder_estimator_mid_blocks_0_1_0_attn1_to_v, decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_0_1_0_ff_net_1, decoder_estimator_mid_blocks_0_1_0_ff_net_2, decoder_estimator_mid_blocks_0_1_0_norm1, decoder_estimator_mid_blocks_0_1_0_norm3, decoder_estimator_mid_blocks_0_1_1_attn1_to_k, decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_0_1_1_attn1_to_q, decoder_estimator_mid_blocks_0_1_1_attn1_to_v, decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_0_1_1_ff_net_1, decoder_estimator_mid_blocks_0_1_1_ff_net_2, decoder_estimator_mid_blocks_0_1_1_norm1, decoder_estimator_mid_blocks_0_1_1_norm3, decoder_estimator_mid_blocks_0_1_2_attn1_to_k, decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_0_1_2_attn1_to_q, decoder_estimator_mid_blocks_0_1_2_attn1_to_v, decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_0_1_2_ff_net_1, decoder_estimator_mid_blocks_0_1_2_ff_net_2, decoder_estimator_mid_blocks_0_1_2_norm1, decoder_estimator_mid_blocks_0_1_2_norm3, decoder_estimator_mid_blocks_0_1_3_attn1_to_k, decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_0_1_3_attn1_to_q, decoder_estimator_mid_blocks_0_1_3_attn1_to_v, decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_0_1_3_ff_net_1, decoder_estimator_mid_blocks_0_1_3_ff_net_2, decoder_estimator_mid_blocks_0_1_3_norm1, decoder_estimator_mid_blocks_0_1_3_norm3, decoder_estimator_mid_blocks_1_0_block1_block_0, decoder_estimator_mid_blocks_1_0_block1_block_1, decoder_estimator_mid_blocks_1_0_block1_block_2, decoder_estimator_mid_blocks_1_0_block1_block_3, decoder_estimator_mid_blocks_1_0_block1_block_4, decoder_estimator_mid_blocks_1_0_block2_block_0, decoder_estimator_mid_blocks_1_0_block2_block_1, decoder_estimator_mid_blocks_1_0_block2_block_2, decoder_estimator_mid_blocks_1_0_block2_block_3, decoder_estimator_mid_blocks_1_0_block2_block_4, decoder_estimator_mid_blocks_1_0_mlp_0, decoder_estimator_mid_blocks_1_0_mlp_1, decoder_estimator_mid_blocks_1_0_res_conv, decoder_estimator_mid_blocks_1_1_0_attn1_to_k, decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_1_1_0_attn1_to_q, decoder_estimator_mid_blocks_1_1_0_attn1_to_v, decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_1_1_0_ff_net_1, decoder_estimator_mid_blocks_1_1_0_ff_net_2, decoder_estimator_mid_blocks_1_1_0_norm1, decoder_estimator_mid_blocks_1_1_0_norm3, decoder_estimator_mid_blocks_1_1_1_attn1_to_k, decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_1_1_1_attn1_to_q, decoder_estimator_mid_blocks_1_1_1_attn1_to_v, decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_1_1_1_ff_net_1, decoder_estimator_mid_blocks_1_1_1_ff_net_2, decoder_estimator_mid_blocks_1_1_1_norm1, decoder_estimator_mid_blocks_1_1_1_norm3, decoder_estimator_mid_blocks_1_1_2_attn1_to_k, decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_1_1_2_attn1_to_q, decoder_estimator_mid_blocks_1_1_2_attn1_to_v, decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_1_1_2_ff_net_1, decoder_estimator_mid_blocks_1_1_2_ff_net_2, decoder_estimator_mid_blocks_1_1_2_norm1, decoder_estimator_mid_blocks_1_1_2_norm3, decoder_estimator_mid_blocks_1_1_3_attn1_to_k, decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_1_1_3_attn1_to_q, decoder_estimator_mid_blocks_1_1_3_attn1_to_v, decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_1_1_3_ff_net_1, decoder_estimator_mid_blocks_1_1_3_ff_net_2, decoder_estimator_mid_blocks_1_1_3_norm1, decoder_estimator_mid_blocks_1_1_3_norm3, decoder_estimator_mid_blocks_10_0_block1_block_0, decoder_estimator_mid_blocks_10_0_block1_block_1, decoder_estimator_mid_blocks_10_0_block1_block_2, decoder_estimator_mid_blocks_10_0_block1_block_3, decoder_estimator_mid_blocks_10_0_block1_block_4, decoder_estimator_mid_blocks_10_0_block2_block_0, decoder_estimator_mid_blocks_10_0_block2_block_1, decoder_estimator_mid_blocks_10_0_block2_block_2, decoder_estimator_mid_blocks_10_0_block2_block_3, decoder_estimator_mid_blocks_10_0_block2_block_4, decoder_estimator_mid_blocks_10_0_mlp_0, decoder_estimator_mid_blocks_10_0_mlp_1, decoder_estimator_mid_blocks_10_0_res_conv, decoder_estimator_mid_blocks_10_1_0_attn1_to_k, decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_10_1_0_attn1_to_q, decoder_estimator_mid_blocks_10_1_0_attn1_to_v, decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_10_1_0_ff_net_1, decoder_estimator_mid_blocks_10_1_0_ff_net_2, decoder_estimator_mid_blocks_10_1_0_norm1, decoder_estimator_mid_blocks_10_1_0_norm3, decoder_estimator_mid_blocks_10_1_1_attn1_to_k, decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_10_1_1_attn1_to_q, decoder_estimator_mid_blocks_10_1_1_attn1_to_v, decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_10_1_1_ff_net_1, decoder_estimator_mid_blocks_10_1_1_ff_net_2, decoder_estimator_mid_blocks_10_1_1_norm1, decoder_estimator_mid_blocks_10_1_1_norm3, decoder_estimator_mid_blocks_10_1_2_attn1_to_k, decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_10_1_2_attn1_to_q, decoder_estimator_mid_blocks_10_1_2_attn1_to_v, decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_10_1_2_ff_net_1, decoder_estimator_mid_blocks_10_1_2_ff_net_2, decoder_estimator_mid_blocks_10_1_2_norm1, decoder_estimator_mid_blocks_10_1_2_norm3, decoder_estimator_mid_blocks_10_1_3_attn1_to_k, decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_10_1_3_attn1_to_q, decoder_estimator_mid_blocks_10_1_3_attn1_to_v, decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_10_1_3_ff_net_1, decoder_estimator_mid_blocks_10_1_3_ff_net_2, decoder_estimator_mid_blocks_10_1_3_norm1, decoder_estimator_mid_blocks_10_1_3_norm3, decoder_estimator_mid_blocks_11_0_block1_block_0, decoder_estimator_mid_blocks_11_0_block1_block_1, decoder_estimator_mid_blocks_11_0_block1_block_2, decoder_estimator_mid_blocks_11_0_block1_block_3, decoder_estimator_mid_blocks_11_0_block1_block_4, decoder_estimator_mid_blocks_11_0_block2_block_0, decoder_estimator_mid_blocks_11_0_block2_block_1, decoder_estimator_mid_blocks_11_0_block2_block_2, decoder_estimator_mid_blocks_11_0_block2_block_3, decoder_estimator_mid_blocks_11_0_block2_block_4, decoder_estimator_mid_blocks_11_0_mlp_0, decoder_estimator_mid_blocks_11_0_mlp_1, decoder_estimator_mid_blocks_11_0_res_conv, decoder_estimator_mid_blocks_11_1_0_attn1_to_k, decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_11_1_0_attn1_to_q, decoder_estimator_mid_blocks_11_1_0_attn1_to_v, decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_11_1_0_ff_net_1, decoder_estimator_mid_blocks_11_1_0_ff_net_2, decoder_estimator_mid_blocks_11_1_0_norm1, decoder_estimator_mid_blocks_11_1_0_norm3, decoder_estimator_mid_blocks_11_1_1_attn1_to_k, decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_11_1_1_attn1_to_q, decoder_estimator_mid_blocks_11_1_1_attn1_to_v, decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_11_1_1_ff_net_1, decoder_estimator_mid_blocks_11_1_1_ff_net_2, decoder_estimator_mid_blocks_11_1_1_norm1, decoder_estimator_mid_blocks_11_1_1_norm3, decoder_estimator_mid_blocks_11_1_2_attn1_to_k, decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_11_1_2_attn1_to_q, decoder_estimator_mid_blocks_11_1_2_attn1_to_v, decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_11_1_2_ff_net_1, decoder_estimator_mid_blocks_11_1_2_ff_net_2, decoder_estimator_mid_blocks_11_1_2_norm1, decoder_estimator_mid_blocks_11_1_2_norm3, decoder_estimator_mid_blocks_11_1_3_attn1_to_k, decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_11_1_3_attn1_to_q, decoder_estimator_mid_blocks_11_1_3_attn1_to_v, decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_11_1_3_ff_net_1, decoder_estimator_mid_blocks_11_1_3_ff_net_2, decoder_estimator_mid_blocks_11_1_3_norm1, decoder_estimator_mid_blocks_11_1_3_norm3, decoder_estimator_mid_blocks_2_0_block1_block_0, decoder_estimator_mid_blocks_2_0_block1_block_1, decoder_estimator_mid_blocks_2_0_block1_block_2, decoder_estimator_mid_blocks_2_0_block1_block_3, decoder_estimator_mid_blocks_2_0_block1_block_4, decoder_estimator_mid_blocks_2_0_block2_block_0, decoder_estimator_mid_blocks_2_0_block2_block_1, decoder_estimator_mid_blocks_2_0_block2_block_2, decoder_estimator_mid_blocks_2_0_block2_block_3, decoder_estimator_mid_blocks_2_0_block2_block_4, decoder_estimator_mid_blocks_2_0_mlp_0, decoder_estimator_mid_blocks_2_0_mlp_1, decoder_estimator_mid_blocks_2_0_res_conv, decoder_estimator_mid_blocks_2_1_0_attn1_to_k, decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_2_1_0_attn1_to_q, decoder_estimator_mid_blocks_2_1_0_attn1_to_v, decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_2_1_0_ff_net_1, decoder_estimator_mid_blocks_2_1_0_ff_net_2, decoder_estimator_mid_blocks_2_1_0_norm1, decoder_estimator_mid_blocks_2_1_0_norm3, decoder_estimator_mid_blocks_2_1_1_attn1_to_k, decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_2_1_1_attn1_to_q, decoder_estimator_mid_blocks_2_1_1_attn1_to_v, decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_2_1_1_ff_net_1, decoder_estimator_mid_blocks_2_1_1_ff_net_2, decoder_estimator_mid_blocks_2_1_1_norm1, decoder_estimator_mid_blocks_2_1_1_norm3, decoder_estimator_mid_blocks_2_1_2_attn1_to_k, decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_2_1_2_attn1_to_q, decoder_estimator_mid_blocks_2_1_2_attn1_to_v, decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_2_1_2_ff_net_1, decoder_estimator_mid_blocks_2_1_2_ff_net_2, decoder_estimator_mid_blocks_2_1_2_norm1, decoder_estimator_mid_blocks_2_1_2_norm3, decoder_estimator_mid_blocks_2_1_3_attn1_to_k, decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_2_1_3_attn1_to_q, decoder_estimator_mid_blocks_2_1_3_attn1_to_v, decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_2_1_3_ff_net_1, decoder_estimator_mid_blocks_2_1_3_ff_net_2, decoder_estimator_mid_blocks_2_1_3_norm1, decoder_estimator_mid_blocks_2_1_3_norm3, decoder_estimator_mid_blocks_3_0_block1_block_0, decoder_estimator_mid_blocks_3_0_block1_block_1, decoder_estimator_mid_blocks_3_0_block1_block_2, decoder_estimator_mid_blocks_3_0_block1_block_3, decoder_estimator_mid_blocks_3_0_block1_block_4, decoder_estimator_mid_blocks_3_0_block2_block_0, decoder_estimator_mid_blocks_3_0_block2_block_1, decoder_estimator_mid_blocks_3_0_block2_block_2, decoder_estimator_mid_blocks_3_0_block2_block_3, decoder_estimator_mid_blocks_3_0_block2_block_4, decoder_estimator_mid_blocks_3_0_mlp_0, decoder_estimator_mid_blocks_3_0_mlp_1, decoder_estimator_mid_blocks_3_0_res_conv, decoder_estimator_mid_blocks_3_1_0_attn1_to_k, decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_3_1_0_attn1_to_q, decoder_estimator_mid_blocks_3_1_0_attn1_to_v, decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_3_1_0_ff_net_1, decoder_estimator_mid_blocks_3_1_0_ff_net_2, decoder_estimator_mid_blocks_3_1_0_norm1, decoder_estimator_mid_blocks_3_1_0_norm3, decoder_estimator_mid_blocks_3_1_1_attn1_to_k, decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_3_1_1_attn1_to_q, decoder_estimator_mid_blocks_3_1_1_attn1_to_v, decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_3_1_1_ff_net_1, decoder_estimator_mid_blocks_3_1_1_ff_net_2, decoder_estimator_mid_blocks_3_1_1_norm1, decoder_estimator_mid_blocks_3_1_1_norm3, decoder_estimator_mid_blocks_3_1_2_attn1_to_k, decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_3_1_2_attn1_to_q, decoder_estimator_mid_blocks_3_1_2_attn1_to_v, decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_3_1_2_ff_net_1, decoder_estimator_mid_blocks_3_1_2_ff_net_2, decoder_estimator_mid_blocks_3_1_2_norm1, decoder_estimator_mid_blocks_3_1_2_norm3, decoder_estimator_mid_blocks_3_1_3_attn1_to_k, decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_3_1_3_attn1_to_q, decoder_estimator_mid_blocks_3_1_3_attn1_to_v, decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_3_1_3_ff_net_1, decoder_estimator_mid_blocks_3_1_3_ff_net_2, decoder_estimator_mid_blocks_3_1_3_norm1, decoder_estimator_mid_blocks_3_1_3_norm3, decoder_estimator_mid_blocks_4_0_block1_block_0, decoder_estimator_mid_blocks_4_0_block1_block_1, decoder_estimator_mid_blocks_4_0_block1_block_2, decoder_estimator_mid_blocks_4_0_block1_block_3, decoder_estimator_mid_blocks_4_0_block1_block_4, decoder_estimator_mid_blocks_4_0_block2_block_0, decoder_estimator_mid_blocks_4_0_block2_block_1, decoder_estimator_mid_blocks_4_0_block2_block_2, decoder_estimator_mid_blocks_4_0_block2_block_3, decoder_estimator_mid_blocks_4_0_block2_block_4, decoder_estimator_mid_blocks_4_0_mlp_0, decoder_estimator_mid_blocks_4_0_mlp_1, decoder_estimator_mid_blocks_4_0_res_conv, decoder_estimator_mid_blocks_4_1_0_attn1_to_k, decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_4_1_0_attn1_to_q, decoder_estimator_mid_blocks_4_1_0_attn1_to_v, decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_4_1_0_ff_net_1, decoder_estimator_mid_blocks_4_1_0_ff_net_2, decoder_estimator_mid_blocks_4_1_0_norm1, decoder_estimator_mid_blocks_4_1_0_norm3, decoder_estimator_mid_blocks_4_1_1_attn1_to_k, decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_4_1_1_attn1_to_q, decoder_estimator_mid_blocks_4_1_1_attn1_to_v, decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_4_1_1_ff_net_1, decoder_estimator_mid_blocks_4_1_1_ff_net_2, decoder_estimator_mid_blocks_4_1_1_norm1, decoder_estimator_mid_blocks_4_1_1_norm3, decoder_estimator_mid_blocks_4_1_2_attn1_to_k, decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_4_1_2_attn1_to_q, decoder_estimator_mid_blocks_4_1_2_attn1_to_v, decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_4_1_2_ff_net_1, decoder_estimator_mid_blocks_4_1_2_ff_net_2, decoder_estimator_mid_blocks_4_1_2_norm1, decoder_estimator_mid_blocks_4_1_2_norm3, decoder_estimator_mid_blocks_4_1_3_attn1_to_k, decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_4_1_3_attn1_to_q, decoder_estimator_mid_blocks_4_1_3_attn1_to_v, decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_4_1_3_ff_net_1, decoder_estimator_mid_blocks_4_1_3_ff_net_2, decoder_estimator_mid_blocks_4_1_3_norm1, decoder_estimator_mid_blocks_4_1_3_norm3, decoder_estimator_mid_blocks_5_0_block1_block_0, decoder_estimator_mid_blocks_5_0_block1_block_1, decoder_estimator_mid_blocks_5_0_block1_block_2, decoder_estimator_mid_blocks_5_0_block1_block_3, decoder_estimator_mid_blocks_5_0_block1_block_4, decoder_estimator_mid_blocks_5_0_block2_block_0, decoder_estimator_mid_blocks_5_0_block2_block_1, decoder_estimator_mid_blocks_5_0_block2_block_2, decoder_estimator_mid_blocks_5_0_block2_block_3, decoder_estimator_mid_blocks_5_0_block2_block_4, decoder_estimator_mid_blocks_5_0_mlp_0, decoder_estimator_mid_blocks_5_0_mlp_1, decoder_estimator_mid_blocks_5_0_res_conv, decoder_estimator_mid_blocks_5_1_0_attn1_to_k, decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_5_1_0_attn1_to_q, decoder_estimator_mid_blocks_5_1_0_attn1_to_v, decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_5_1_0_ff_net_1, decoder_estimator_mid_blocks_5_1_0_ff_net_2, decoder_estimator_mid_blocks_5_1_0_norm1, decoder_estimator_mid_blocks_5_1_0_norm3, decoder_estimator_mid_blocks_5_1_1_attn1_to_k, decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_5_1_1_attn1_to_q, decoder_estimator_mid_blocks_5_1_1_attn1_to_v, decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_5_1_1_ff_net_1, decoder_estimator_mid_blocks_5_1_1_ff_net_2, decoder_estimator_mid_blocks_5_1_1_norm1, decoder_estimator_mid_blocks_5_1_1_norm3, decoder_estimator_mid_blocks_5_1_2_attn1_to_k, decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_5_1_2_attn1_to_q, decoder_estimator_mid_blocks_5_1_2_attn1_to_v, decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_5_1_2_ff_net_1, decoder_estimator_mid_blocks_5_1_2_ff_net_2, decoder_estimator_mid_blocks_5_1_2_norm1, decoder_estimator_mid_blocks_5_1_2_norm3, decoder_estimator_mid_blocks_5_1_3_attn1_to_k, decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_5_1_3_attn1_to_q, decoder_estimator_mid_blocks_5_1_3_attn1_to_v, decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_5_1_3_ff_net_1, decoder_estimator_mid_blocks_5_1_3_ff_net_2, decoder_estimator_mid_blocks_5_1_3_norm1, decoder_estimator_mid_blocks_5_1_3_norm3, decoder_estimator_mid_blocks_6_0_block1_block_0, decoder_estimator_mid_blocks_6_0_block1_block_1, decoder_estimator_mid_blocks_6_0_block1_block_2, decoder_estimator_mid_blocks_6_0_block1_block_3, decoder_estimator_mid_blocks_6_0_block1_block_4, decoder_estimator_mid_blocks_6_0_block2_block_0, decoder_estimator_mid_blocks_6_0_block2_block_1, decoder_estimator_mid_blocks_6_0_block2_block_2, decoder_estimator_mid_blocks_6_0_block2_block_3, decoder_estimator_mid_blocks_6_0_block2_block_4, decoder_estimator_mid_blocks_6_0_mlp_0, decoder_estimator_mid_blocks_6_0_mlp_1, decoder_estimator_mid_blocks_6_0_res_conv, decoder_estimator_mid_blocks_6_1_0_attn1_to_k, decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_6_1_0_attn1_to_q, decoder_estimator_mid_blocks_6_1_0_attn1_to_v, decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_6_1_0_ff_net_1, decoder_estimator_mid_blocks_6_1_0_ff_net_2, decoder_estimator_mid_blocks_6_1_0_norm1, decoder_estimator_mid_blocks_6_1_0_norm3, decoder_estimator_mid_blocks_6_1_1_attn1_to_k, decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_6_1_1_attn1_to_q, decoder_estimator_mid_blocks_6_1_1_attn1_to_v, decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_6_1_1_ff_net_1, decoder_estimator_mid_blocks_6_1_1_ff_net_2, decoder_estimator_mid_blocks_6_1_1_norm1, decoder_estimator_mid_blocks_6_1_1_norm3, decoder_estimator_mid_blocks_6_1_2_attn1_to_k, decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_6_1_2_attn1_to_q, decoder_estimator_mid_blocks_6_1_2_attn1_to_v, decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_6_1_2_ff_net_1, decoder_estimator_mid_blocks_6_1_2_ff_net_2, decoder_estimator_mid_blocks_6_1_2_norm1, decoder_estimator_mid_blocks_6_1_2_norm3, decoder_estimator_mid_blocks_6_1_3_attn1_to_k, decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_6_1_3_attn1_to_q, decoder_estimator_mid_blocks_6_1_3_attn1_to_v, decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_6_1_3_ff_net_1, decoder_estimator_mid_blocks_6_1_3_ff_net_2, decoder_estimator_mid_blocks_6_1_3_norm1, decoder_estimator_mid_blocks_6_1_3_norm3, decoder_estimator_mid_blocks_7_0_block1_block_0, decoder_estimator_mid_blocks_7_0_block1_block_1, decoder_estimator_mid_blocks_7_0_block1_block_2, decoder_estimator_mid_blocks_7_0_block1_block_3, decoder_estimator_mid_blocks_7_0_block1_block_4, decoder_estimator_mid_blocks_7_0_block2_block_0, decoder_estimator_mid_blocks_7_0_block2_block_1, decoder_estimator_mid_blocks_7_0_block2_block_2, decoder_estimator_mid_blocks_7_0_block2_block_3, decoder_estimator_mid_blocks_7_0_block2_block_4, decoder_estimator_mid_blocks_7_0_mlp_0, decoder_estimator_mid_blocks_7_0_mlp_1, decoder_estimator_mid_blocks_7_0_res_conv, decoder_estimator_mid_blocks_7_1_0_attn1_to_k, decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_7_1_0_attn1_to_q, decoder_estimator_mid_blocks_7_1_0_attn1_to_v, decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_7_1_0_ff_net_1, decoder_estimator_mid_blocks_7_1_0_ff_net_2, decoder_estimator_mid_blocks_7_1_0_norm1, decoder_estimator_mid_blocks_7_1_0_norm3, decoder_estimator_mid_blocks_7_1_1_attn1_to_k, decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_7_1_1_attn1_to_q, decoder_estimator_mid_blocks_7_1_1_attn1_to_v, decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_7_1_1_ff_net_1, decoder_estimator_mid_blocks_7_1_1_ff_net_2, decoder_estimator_mid_blocks_7_1_1_norm1, decoder_estimator_mid_blocks_7_1_1_norm3, decoder_estimator_mid_blocks_7_1_2_attn1_to_k, decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_7_1_2_attn1_to_q, decoder_estimator_mid_blocks_7_1_2_attn1_to_v, decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_7_1_2_ff_net_1, decoder_estimator_mid_blocks_7_1_2_ff_net_2, decoder_estimator_mid_blocks_7_1_2_norm1, decoder_estimator_mid_blocks_7_1_2_norm3, decoder_estimator_mid_blocks_7_1_3_attn1_to_k, decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_7_1_3_attn1_to_q, decoder_estimator_mid_blocks_7_1_3_attn1_to_v, decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_7_1_3_ff_net_1, decoder_estimator_mid_blocks_7_1_3_ff_net_2, decoder_estimator_mid_blocks_7_1_3_norm1, decoder_estimator_mid_blocks_7_1_3_norm3, decoder_estimator_mid_blocks_8_0_block1_block_0, decoder_estimator_mid_blocks_8_0_block1_block_1, decoder_estimator_mid_blocks_8_0_block1_block_2, decoder_estimator_mid_blocks_8_0_block1_block_3, decoder_estimator_mid_blocks_8_0_block1_block_4, decoder_estimator_mid_blocks_8_0_block2_block_0, decoder_estimator_mid_blocks_8_0_block2_block_1, decoder_estimator_mid_blocks_8_0_block2_block_2, decoder_estimator_mid_blocks_8_0_block2_block_3, decoder_estimator_mid_blocks_8_0_block2_block_4, decoder_estimator_mid_blocks_8_0_mlp_0, decoder_estimator_mid_blocks_8_0_mlp_1, decoder_estimator_mid_blocks_8_0_res_conv, decoder_estimator_mid_blocks_8_1_0_attn1_to_k, decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_8_1_0_attn1_to_q, decoder_estimator_mid_blocks_8_1_0_attn1_to_v, decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_8_1_0_ff_net_1, decoder_estimator_mid_blocks_8_1_0_ff_net_2, decoder_estimator_mid_blocks_8_1_0_norm1, decoder_estimator_mid_blocks_8_1_0_norm3, decoder_estimator_mid_blocks_8_1_1_attn1_to_k, decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_8_1_1_attn1_to_q, decoder_estimator_mid_blocks_8_1_1_attn1_to_v, decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_8_1_1_ff_net_1, decoder_estimator_mid_blocks_8_1_1_ff_net_2, decoder_estimator_mid_blocks_8_1_1_norm1, decoder_estimator_mid_blocks_8_1_1_norm3, decoder_estimator_mid_blocks_8_1_2_attn1_to_k, decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_8_1_2_attn1_to_q, decoder_estimator_mid_blocks_8_1_2_attn1_to_v, decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_8_1_2_ff_net_1, decoder_estimator_mid_blocks_8_1_2_ff_net_2, decoder_estimator_mid_blocks_8_1_2_norm1, decoder_estimator_mid_blocks_8_1_2_norm3, decoder_estimator_mid_blocks_8_1_3_attn1_to_k, decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_8_1_3_attn1_to_q, decoder_estimator_mid_blocks_8_1_3_attn1_to_v, decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_8_1_3_ff_net_1, decoder_estimator_mid_blocks_8_1_3_ff_net_2, decoder_estimator_mid_blocks_8_1_3_norm1, decoder_estimator_mid_blocks_8_1_3_norm3, decoder_estimator_mid_blocks_9_0_block1_block_0, decoder_estimator_mid_blocks_9_0_block1_block_1, decoder_estimator_mid_blocks_9_0_block1_block_2, decoder_estimator_mid_blocks_9_0_block1_block_3, decoder_estimator_mid_blocks_9_0_block1_block_4, decoder_estimator_mid_blocks_9_0_block2_block_0, decoder_estimator_mid_blocks_9_0_block2_block_1, decoder_estimator_mid_blocks_9_0_block2_block_2, decoder_estimator_mid_blocks_9_0_block2_block_3, decoder_estimator_mid_blocks_9_0_block2_block_4, decoder_estimator_mid_blocks_9_0_mlp_0, decoder_estimator_mid_blocks_9_0_mlp_1, decoder_estimator_mid_blocks_9_0_res_conv, decoder_estimator_mid_blocks_9_1_0_attn1_to_k, decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0, decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1, decoder_estimator_mid_blocks_9_1_0_attn1_to_q, decoder_estimator_mid_blocks_9_1_0_attn1_to_v, decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj, decoder_estimator_mid_blocks_9_1_0_ff_net_1, decoder_estimator_mid_blocks_9_1_0_ff_net_2, decoder_estimator_mid_blocks_9_1_0_norm1, decoder_estimator_mid_blocks_9_1_0_norm3, decoder_estimator_mid_blocks_9_1_1_attn1_to_k, decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0, decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1, decoder_estimator_mid_blocks_9_1_1_attn1_to_q, decoder_estimator_mid_blocks_9_1_1_attn1_to_v, decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj, decoder_estimator_mid_blocks_9_1_1_ff_net_1, decoder_estimator_mid_blocks_9_1_1_ff_net_2, decoder_estimator_mid_blocks_9_1_1_norm1, decoder_estimator_mid_blocks_9_1_1_norm3, decoder_estimator_mid_blocks_9_1_2_attn1_to_k, decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0, decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1, decoder_estimator_mid_blocks_9_1_2_attn1_to_q, decoder_estimator_mid_blocks_9_1_2_attn1_to_v, decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj, decoder_estimator_mid_blocks_9_1_2_ff_net_1, decoder_estimator_mid_blocks_9_1_2_ff_net_2, decoder_estimator_mid_blocks_9_1_2_norm1, decoder_estimator_mid_blocks_9_1_2_norm3, decoder_estimator_mid_blocks_9_1_3_attn1_to_k, decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0, decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1, decoder_estimator_mid_blocks_9_1_3_attn1_to_q, decoder_estimator_mid_blocks_9_1_3_attn1_to_v, decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj, decoder_estimator_mid_blocks_9_1_3_ff_net_1, decoder_estimator_mid_blocks_9_1_3_ff_net_2, decoder_estimator_mid_blocks_9_1_3_norm1, decoder_estimator_mid_blocks_9_1_3_norm3, decoder_estimator_time_embeddings, decoder_estimator_time_mlp_act, decoder_estimator_time_mlp_linear_1, decoder_estimator_time_mlp_linear_2, decoder_estimator_up_blocks_0_0_block1_block_0, decoder_estimator_up_blocks_0_0_block1_block_1, decoder_estimator_up_blocks_0_0_block1_block_2, decoder_estimator_up_blocks_0_0_block1_block_3, decoder_estimator_up_blocks_0_0_block1_block_4, decoder_estimator_up_blocks_0_0_block2_block_0, decoder_estimator_up_blocks_0_0_block2_block_1, decoder_estimator_up_blocks_0_0_block2_block_2, decoder_estimator_up_blocks_0_0_block2_block_3, decoder_estimator_up_blocks_0_0_block2_block_4, decoder_estimator_up_blocks_0_0_mlp_0, decoder_estimator_up_blocks_0_0_mlp_1, decoder_estimator_up_blocks_0_0_res_conv, decoder_estimator_up_blocks_0_1_0_attn1_to_k, decoder_estimator_up_blocks_0_1_0_attn1_to_out_0, decoder_estimator_up_blocks_0_1_0_attn1_to_out_1, decoder_estimator_up_blocks_0_1_0_attn1_to_q, decoder_estimator_up_blocks_0_1_0_attn1_to_v, decoder_estimator_up_blocks_0_1_0_ff_net_0_proj, decoder_estimator_up_blocks_0_1_0_ff_net_1, decoder_estimator_up_blocks_0_1_0_ff_net_2, decoder_estimator_up_blocks_0_1_0_norm1, decoder_estimator_up_blocks_0_1_0_norm3, decoder_estimator_up_blocks_0_1_1_attn1_to_k, decoder_estimator_up_blocks_0_1_1_attn1_to_out_0, decoder_estimator_up_blocks_0_1_1_attn1_to_out_1, decoder_estimator_up_blocks_0_1_1_attn1_to_q, decoder_estimator_up_blocks_0_1_1_attn1_to_v, decoder_estimator_up_blocks_0_1_1_ff_net_0_proj, decoder_estimator_up_blocks_0_1_1_ff_net_1, decoder_estimator_up_blocks_0_1_1_ff_net_2, decoder_estimator_up_blocks_0_1_1_norm1, decoder_estimator_up_blocks_0_1_1_norm3, decoder_estimator_up_blocks_0_1_2_attn1_to_k, decoder_estimator_up_blocks_0_1_2_attn1_to_out_0, decoder_estimator_up_blocks_0_1_2_attn1_to_out_1, decoder_estimator_up_blocks_0_1_2_attn1_to_q, decoder_estimator_up_blocks_0_1_2_attn1_to_v, decoder_estimator_up_blocks_0_1_2_ff_net_0_proj, decoder_estimator_up_blocks_0_1_2_ff_net_1, decoder_estimator_up_blocks_0_1_2_ff_net_2, decoder_estimator_up_blocks_0_1_2_norm1, decoder_estimator_up_blocks_0_1_2_norm3, decoder_estimator_up_blocks_0_1_3_attn1_to_k, decoder_estimator_up_blocks_0_1_3_attn1_to_out_0, decoder_estimator_up_blocks_0_1_3_attn1_to_out_1, decoder_estimator_up_blocks_0_1_3_attn1_to_q, decoder_estimator_up_blocks_0_1_3_attn1_to_v, decoder_estimator_up_blocks_0_1_3_ff_net_0_proj, decoder_estimator_up_blocks_0_1_3_ff_net_1, decoder_estimator_up_blocks_0_1_3_ff_net_2, decoder_estimator_up_blocks_0_1_3_norm1, decoder_estimator_up_blocks_0_1_3_norm3, decoder_estimator_up_blocks_0_2, encoder_after_norm, encoder_embed_out_0, encoder_embed_out_1, encoder_embed_out_2, encoder_embed_pos_enc_dropout, encoder_embed_pos_enc_dropout_1, encoder_encoders_0_dropout, encoder_encoders_0_dropout_1, encoder_encoders_0_feed_forward_activation, encoder_encoders_0_feed_forward_activation_1, encoder_encoders_0_feed_forward_activation_2, encoder_encoders_0_feed_forward_activation_3, encoder_encoders_0_feed_forward_activation_4, encoder_encoders_0_feed_forward_activation_5, encoder_encoders_0_feed_forward_activation_6, encoder_encoders_0_feed_forward_activation_7, encoder_encoders_0_feed_forward_activation_8, encoder_encoders_0_feed_forward_activation_9, encoder_encoders_0_feed_forward_dropout, encoder_encoders_0_feed_forward_w_1, encoder_encoders_0_feed_forward_w_2, encoder_encoders_0_norm_ff, encoder_encoders_0_norm_mha, encoder_encoders_0_self_attn_dropout, encoder_encoders_0_self_attn_linear_k, encoder_encoders_0_self_attn_linear_out, encoder_encoders_0_self_attn_linear_pos, encoder_encoders_0_self_attn_linear_q, encoder_encoders_0_self_attn_linear_v, encoder_encoders_1_dropout, encoder_encoders_1_dropout_1, encoder_encoders_1_feed_forward_dropout, encoder_encoders_1_feed_forward_w_1, encoder_encoders_1_feed_forward_w_2, encoder_encoders_1_norm_ff, encoder_encoders_1_norm_mha, encoder_encoders_1_self_attn_dropout, encoder_encoders_1_self_attn_linear_k, encoder_encoders_1_self_attn_linear_out, encoder_encoders_1_self_attn_linear_pos, encoder_encoders_1_self_attn_linear_q, encoder_encoders_1_self_attn_linear_v, encoder_encoders_2_dropout, encoder_encoders_2_dropout_1, encoder_encoders_2_feed_forward_dropout, encoder_encoders_2_feed_forward_w_1, encoder_encoders_2_feed_forward_w_2, encoder_encoders_2_norm_ff, encoder_encoders_2_norm_mha, encoder_encoders_2_self_attn_dropout, encoder_encoders_2_self_attn_linear_k, encoder_encoders_2_self_attn_linear_out, encoder_encoders_2_self_attn_linear_pos, encoder_encoders_2_self_attn_linear_q, encoder_encoders_2_self_attn_linear_v, encoder_encoders_3_dropout, encoder_encoders_3_dropout_1, encoder_encoders_3_feed_forward_dropout, encoder_encoders_3_feed_forward_w_1, encoder_encoders_3_feed_forward_w_2, encoder_encoders_3_norm_ff, encoder_encoders_3_norm_mha, encoder_encoders_3_self_attn_dropout, encoder_encoders_3_self_attn_linear_k, encoder_encoders_3_self_attn_linear_out, encoder_encoders_3_self_attn_linear_pos, encoder_encoders_3_self_attn_linear_q, encoder_encoders_3_self_attn_linear_v, encoder_encoders_4_dropout, encoder_encoders_4_dropout_1, encoder_encoders_4_feed_forward_dropout, encoder_encoders_4_feed_forward_w_1, encoder_encoders_4_feed_forward_w_2, encoder_encoders_4_norm_ff, encoder_encoders_4_norm_mha, encoder_encoders_4_self_attn_dropout, encoder_encoders_4_self_attn_linear_k, encoder_encoders_4_self_attn_linear_out, encoder_encoders_4_self_attn_linear_pos, encoder_encoders_4_self_attn_linear_q, encoder_encoders_4_self_attn_linear_v, encoder_encoders_5_dropout, encoder_encoders_5_dropout_1, encoder_encoders_5_feed_forward_dropout, encoder_encoders_5_feed_forward_w_1, encoder_encoders_5_feed_forward_w_2, encoder_encoders_5_norm_ff, encoder_encoders_5_norm_mha, encoder_encoders_5_self_attn_dropout, encoder_encoders_5_self_attn_linear_k, encoder_encoders_5_self_attn_linear_out, encoder_encoders_5_self_attn_linear_pos, encoder_encoders_5_self_attn_linear_q, encoder_encoders_5_self_attn_linear_v, encoder_pre_lookahead_layer_conv1, encoder_pre_lookahead_layer_conv2, encoder_up_embed_out_0, encoder_up_embed_out_1, encoder_up_embed_out_2, encoder_up_embed_pos_enc_dropout, encoder_up_embed_pos_enc_dropout_1, encoder_up_encoders_0_dropout, encoder_up_encoders_0_dropout_1, encoder_up_encoders_0_feed_forward_dropout, encoder_up_encoders_0_feed_forward_w_1, encoder_up_encoders_0_feed_forward_w_2, encoder_up_encoders_0_norm_ff, encoder_up_encoders_0_norm_mha, encoder_up_encoders_0_self_attn_dropout, encoder_up_encoders_0_self_attn_linear_k, encoder_up_encoders_0_self_attn_linear_out, encoder_up_encoders_0_self_attn_linear_pos, encoder_up_encoders_0_self_attn_linear_q, encoder_up_encoders_0_self_attn_linear_v, encoder_up_encoders_1_dropout, encoder_up_encoders_1_dropout_1, encoder_up_encoders_1_feed_forward_dropout, encoder_up_encoders_1_feed_forward_w_1, encoder_up_encoders_1_feed_forward_w_2, encoder_up_encoders_1_norm_ff, encoder_up_encoders_1_norm_mha, encoder_up_encoders_1_self_attn_dropout, encoder_up_encoders_1_self_attn_linear_k, encoder_up_encoders_1_self_attn_linear_out, encoder_up_encoders_1_self_attn_linear_pos, encoder_up_encoders_1_self_attn_linear_q, encoder_up_encoders_1_self_attn_linear_v, encoder_up_encoders_2_dropout, encoder_up_encoders_2_dropout_1, encoder_up_encoders_2_feed_forward_dropout, encoder_up_encoders_2_feed_forward_w_1, encoder_up_encoders_2_feed_forward_w_2, encoder_up_encoders_2_norm_ff, encoder_up_encoders_2_norm_mha, encoder_up_encoders_2_self_attn_dropout, encoder_up_encoders_2_self_attn_linear_k, encoder_up_encoders_2_self_attn_linear_out, encoder_up_encoders_2_self_attn_linear_pos, encoder_up_encoders_2_self_attn_linear_q, encoder_up_encoders_2_self_attn_linear_v, encoder_up_encoders_3_dropout, encoder_up_encoders_3_dropout_1, encoder_up_encoders_3_feed_forward_dropout, encoder_up_encoders_3_feed_forward_w_1, encoder_up_encoders_3_feed_forward_w_2, encoder_up_encoders_3_norm_ff, encoder_up_encoders_3_norm_mha, encoder_up_encoders_3_self_attn_dropout, encoder_up_encoders_3_self_attn_linear_k, encoder_up_encoders_3_self_attn_linear_out, encoder_up_encoders_3_self_attn_linear_pos, encoder_up_encoders_3_self_attn_linear_q, encoder_up_encoders_3_self_attn_linear_v, encoder_up_layer_conv, encoder_proj, input_embedding, spk_embed_affine_layer, checker })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.0
        x = self.decoder_estimator_down_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.1
        x = self.decoder_estimator_down_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.2
        x = self.decoder_estimator_down_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.3
        x = self.decoder_estimator_down_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block1.block.4
        x = self.decoder_estimator_down_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.0
        x = self.decoder_estimator_down_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.1
        x = self.decoder_estimator_down_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.2
        x = self.decoder_estimator_down_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.3
        x = self.decoder_estimator_down_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.down_blocks.0.0.block2.block.4
        x = self.decoder_estimator_down_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.down_blocks.0.0.mlp.0
        x = self.decoder_estimator_down_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.down_blocks.0.0.mlp.1
        x = self.decoder_estimator_down_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.down_blocks.0.0.res_conv
        x = self.decoder_estimator_down_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.norm1
        x = self.decoder_estimator_down_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.0.norm3
        x = self.decoder_estimator_down_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.norm1
        x = self.decoder_estimator_down_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.1.norm3
        x = self.decoder_estimator_down_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.norm1
        x = self.decoder_estimator_down_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.2.norm3
        x = self.decoder_estimator_down_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_down_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_down_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.norm1
        x = self.decoder_estimator_down_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.down_blocks.0.1.3.norm3
        x = self.decoder_estimator_down_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.down_blocks.0.2
        x = self.decoder_estimator_down_blocks_0_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.down_blocks.0.2", &x);

        // Layer: decoder.estimator.final_block.block.0
        x = self.decoder_estimator_final_block_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.0", &x);

        // Layer: decoder.estimator.final_block.block.1
        x = self.decoder_estimator_final_block_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.1", &x);

        // Layer: decoder.estimator.final_block.block.2
        x = self.decoder_estimator_final_block_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.2", &x);

        // Layer: decoder.estimator.final_block.block.3
        x = self.decoder_estimator_final_block_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.3", &x);

        // Layer: decoder.estimator.final_block.block.4
        x = self.decoder_estimator_final_block_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_block.block.4", &x);

        // Layer: decoder.estimator.final_proj
        x = self.decoder_estimator_final_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.final_proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.mlp.0
        x = self.decoder_estimator_mid_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.mlp.1
        x = self.decoder_estimator_mid_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.0.res_conv
        x = self.decoder_estimator_mid_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.norm1
        x = self.decoder_estimator_mid_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.0.norm3
        x = self.decoder_estimator_mid_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.norm1
        x = self.decoder_estimator_mid_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.1.norm3
        x = self.decoder_estimator_mid_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.norm1
        x = self.decoder_estimator_mid_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.2.norm3
        x = self.decoder_estimator_mid_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.norm1
        x = self.decoder_estimator_mid_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.0.1.3.norm3
        x = self.decoder_estimator_mid_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_1_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_1_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.mlp.0
        x = self.decoder_estimator_mid_blocks_1_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.mlp.1
        x = self.decoder_estimator_mid_blocks_1_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.0.res_conv
        x = self.decoder_estimator_mid_blocks_1_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.norm1
        x = self.decoder_estimator_mid_blocks_1_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.0.norm3
        x = self.decoder_estimator_mid_blocks_1_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.norm1
        x = self.decoder_estimator_mid_blocks_1_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.1.norm3
        x = self.decoder_estimator_mid_blocks_1_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.norm1
        x = self.decoder_estimator_mid_blocks_1_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.2.norm3
        x = self.decoder_estimator_mid_blocks_1_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_1_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_1_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.norm1
        x = self.decoder_estimator_mid_blocks_1_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.1.1.3.norm3
        x = self.decoder_estimator_mid_blocks_1_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.1.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_10_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_10_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.mlp.0
        x = self.decoder_estimator_mid_blocks_10_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.mlp.1
        x = self.decoder_estimator_mid_blocks_10_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.0.res_conv
        x = self.decoder_estimator_mid_blocks_10_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.norm1
        x = self.decoder_estimator_mid_blocks_10_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.0.norm3
        x = self.decoder_estimator_mid_blocks_10_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.norm1
        x = self.decoder_estimator_mid_blocks_10_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.1.norm3
        x = self.decoder_estimator_mid_blocks_10_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.norm1
        x = self.decoder_estimator_mid_blocks_10_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.2.norm3
        x = self.decoder_estimator_mid_blocks_10_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_10_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_10_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.norm1
        x = self.decoder_estimator_mid_blocks_10_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.10.1.3.norm3
        x = self.decoder_estimator_mid_blocks_10_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.10.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_11_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_11_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.mlp.0
        x = self.decoder_estimator_mid_blocks_11_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.mlp.1
        x = self.decoder_estimator_mid_blocks_11_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.0.res_conv
        x = self.decoder_estimator_mid_blocks_11_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.norm1
        x = self.decoder_estimator_mid_blocks_11_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.0.norm3
        x = self.decoder_estimator_mid_blocks_11_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.norm1
        x = self.decoder_estimator_mid_blocks_11_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.1.norm3
        x = self.decoder_estimator_mid_blocks_11_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.norm1
        x = self.decoder_estimator_mid_blocks_11_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.2.norm3
        x = self.decoder_estimator_mid_blocks_11_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_11_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_11_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.norm1
        x = self.decoder_estimator_mid_blocks_11_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.11.1.3.norm3
        x = self.decoder_estimator_mid_blocks_11_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.11.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_2_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_2_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.mlp.0
        x = self.decoder_estimator_mid_blocks_2_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.mlp.1
        x = self.decoder_estimator_mid_blocks_2_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.0.res_conv
        x = self.decoder_estimator_mid_blocks_2_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.norm1
        x = self.decoder_estimator_mid_blocks_2_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.0.norm3
        x = self.decoder_estimator_mid_blocks_2_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.norm1
        x = self.decoder_estimator_mid_blocks_2_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.1.norm3
        x = self.decoder_estimator_mid_blocks_2_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.norm1
        x = self.decoder_estimator_mid_blocks_2_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.2.norm3
        x = self.decoder_estimator_mid_blocks_2_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_2_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_2_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.norm1
        x = self.decoder_estimator_mid_blocks_2_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.2.1.3.norm3
        x = self.decoder_estimator_mid_blocks_2_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.2.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_3_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_3_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.mlp.0
        x = self.decoder_estimator_mid_blocks_3_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.mlp.1
        x = self.decoder_estimator_mid_blocks_3_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.0.res_conv
        x = self.decoder_estimator_mid_blocks_3_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.norm1
        x = self.decoder_estimator_mid_blocks_3_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.0.norm3
        x = self.decoder_estimator_mid_blocks_3_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.norm1
        x = self.decoder_estimator_mid_blocks_3_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.1.norm3
        x = self.decoder_estimator_mid_blocks_3_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.norm1
        x = self.decoder_estimator_mid_blocks_3_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.2.norm3
        x = self.decoder_estimator_mid_blocks_3_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_3_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_3_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.norm1
        x = self.decoder_estimator_mid_blocks_3_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.3.1.3.norm3
        x = self.decoder_estimator_mid_blocks_3_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.3.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_4_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_4_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.mlp.0
        x = self.decoder_estimator_mid_blocks_4_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.mlp.1
        x = self.decoder_estimator_mid_blocks_4_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.0.res_conv
        x = self.decoder_estimator_mid_blocks_4_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.norm1
        x = self.decoder_estimator_mid_blocks_4_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.0.norm3
        x = self.decoder_estimator_mid_blocks_4_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.norm1
        x = self.decoder_estimator_mid_blocks_4_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.1.norm3
        x = self.decoder_estimator_mid_blocks_4_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.norm1
        x = self.decoder_estimator_mid_blocks_4_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.2.norm3
        x = self.decoder_estimator_mid_blocks_4_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_4_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_4_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.norm1
        x = self.decoder_estimator_mid_blocks_4_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.4.1.3.norm3
        x = self.decoder_estimator_mid_blocks_4_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.4.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_5_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_5_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.mlp.0
        x = self.decoder_estimator_mid_blocks_5_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.mlp.1
        x = self.decoder_estimator_mid_blocks_5_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.0.res_conv
        x = self.decoder_estimator_mid_blocks_5_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.norm1
        x = self.decoder_estimator_mid_blocks_5_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.0.norm3
        x = self.decoder_estimator_mid_blocks_5_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.norm1
        x = self.decoder_estimator_mid_blocks_5_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.1.norm3
        x = self.decoder_estimator_mid_blocks_5_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.norm1
        x = self.decoder_estimator_mid_blocks_5_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.2.norm3
        x = self.decoder_estimator_mid_blocks_5_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_5_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_5_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.norm1
        x = self.decoder_estimator_mid_blocks_5_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.5.1.3.norm3
        x = self.decoder_estimator_mid_blocks_5_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.5.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_6_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_6_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.mlp.0
        x = self.decoder_estimator_mid_blocks_6_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.mlp.1
        x = self.decoder_estimator_mid_blocks_6_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.0.res_conv
        x = self.decoder_estimator_mid_blocks_6_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.norm1
        x = self.decoder_estimator_mid_blocks_6_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.0.norm3
        x = self.decoder_estimator_mid_blocks_6_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.norm1
        x = self.decoder_estimator_mid_blocks_6_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.1.norm3
        x = self.decoder_estimator_mid_blocks_6_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.norm1
        x = self.decoder_estimator_mid_blocks_6_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.2.norm3
        x = self.decoder_estimator_mid_blocks_6_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_6_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_6_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.norm1
        x = self.decoder_estimator_mid_blocks_6_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.6.1.3.norm3
        x = self.decoder_estimator_mid_blocks_6_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.6.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_7_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_7_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.mlp.0
        x = self.decoder_estimator_mid_blocks_7_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.mlp.1
        x = self.decoder_estimator_mid_blocks_7_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.0.res_conv
        x = self.decoder_estimator_mid_blocks_7_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.norm1
        x = self.decoder_estimator_mid_blocks_7_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.0.norm3
        x = self.decoder_estimator_mid_blocks_7_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.norm1
        x = self.decoder_estimator_mid_blocks_7_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.1.norm3
        x = self.decoder_estimator_mid_blocks_7_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.norm1
        x = self.decoder_estimator_mid_blocks_7_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.2.norm3
        x = self.decoder_estimator_mid_blocks_7_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_7_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_7_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.norm1
        x = self.decoder_estimator_mid_blocks_7_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.7.1.3.norm3
        x = self.decoder_estimator_mid_blocks_7_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.7.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_8_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_8_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.mlp.0
        x = self.decoder_estimator_mid_blocks_8_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.mlp.1
        x = self.decoder_estimator_mid_blocks_8_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.0.res_conv
        x = self.decoder_estimator_mid_blocks_8_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.norm1
        x = self.decoder_estimator_mid_blocks_8_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.0.norm3
        x = self.decoder_estimator_mid_blocks_8_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.norm1
        x = self.decoder_estimator_mid_blocks_8_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.1.norm3
        x = self.decoder_estimator_mid_blocks_8_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.norm1
        x = self.decoder_estimator_mid_blocks_8_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.2.norm3
        x = self.decoder_estimator_mid_blocks_8_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_8_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_8_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.norm1
        x = self.decoder_estimator_mid_blocks_8_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.8.1.3.norm3
        x = self.decoder_estimator_mid_blocks_8_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.8.1.3.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.0
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.1
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.2
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.3
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block1.block.4
        x = self.decoder_estimator_mid_blocks_9_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block1.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.0
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.1
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.2
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.3
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.3", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.block2.block.4
        x = self.decoder_estimator_mid_blocks_9_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.block2.block.4", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.mlp.0
        x = self.decoder_estimator_mid_blocks_9_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.mlp.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.mlp.1
        x = self.decoder_estimator_mid_blocks_9_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.mlp.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.0.res_conv
        x = self.decoder_estimator_mid_blocks_9_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.0.res_conv", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.norm1
        x = self.decoder_estimator_mid_blocks_9_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.0.norm3
        x = self.decoder_estimator_mid_blocks_9_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.0.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.norm1
        x = self.decoder_estimator_mid_blocks_9_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.1.norm3
        x = self.decoder_estimator_mid_blocks_9_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.1.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.norm1
        x = self.decoder_estimator_mid_blocks_9_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.2.norm3
        x = self.decoder_estimator_mid_blocks_9_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.2.norm3", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_k
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_out.1
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_q
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.attn1.to_v
        x = self.decoder_estimator_mid_blocks_9_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.1
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.ff.net.2
        x = self.decoder_estimator_mid_blocks_9_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.norm1
        x = self.decoder_estimator_mid_blocks_9_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.norm1", &x);

        // Layer: decoder.estimator.mid_blocks.9.1.3.norm3
        x = self.decoder_estimator_mid_blocks_9_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.mid_blocks.9.1.3.norm3", &x);

        // Layer: decoder.estimator.time_embeddings
        x = self.decoder_estimator_time_embeddings.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_embeddings", &x);

        // Layer: decoder.estimator.time_mlp.act
        x = self.decoder_estimator_time_mlp_act.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.act", &x);

        // Layer: decoder.estimator.time_mlp.linear_1
        x = self.decoder_estimator_time_mlp_linear_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.linear_1", &x);

        // Layer: decoder.estimator.time_mlp.linear_2
        x = self.decoder_estimator_time_mlp_linear_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.time_mlp.linear_2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.0
        x = self.decoder_estimator_up_blocks_0_0_block1_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.1
        x = self.decoder_estimator_up_blocks_0_0_block1_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.2
        x = self.decoder_estimator_up_blocks_0_0_block1_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.3
        x = self.decoder_estimator_up_blocks_0_0_block1_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.3", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block1.block.4
        x = self.decoder_estimator_up_blocks_0_0_block1_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block1.block.4", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.0
        x = self.decoder_estimator_up_blocks_0_0_block2_block_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.1
        x = self.decoder_estimator_up_blocks_0_0_block2_block_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.2
        x = self.decoder_estimator_up_blocks_0_0_block2_block_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.2", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.3
        x = self.decoder_estimator_up_blocks_0_0_block2_block_3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.3", &x);

        // Layer: decoder.estimator.up_blocks.0.0.block2.block.4
        x = self.decoder_estimator_up_blocks_0_0_block2_block_4.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.block2.block.4", &x);

        // Layer: decoder.estimator.up_blocks.0.0.mlp.0
        x = self.decoder_estimator_up_blocks_0_0_mlp_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.mlp.0", &x);

        // Layer: decoder.estimator.up_blocks.0.0.mlp.1
        x = self.decoder_estimator_up_blocks_0_0_mlp_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.mlp.1", &x);

        // Layer: decoder.estimator.up_blocks.0.0.res_conv
        x = self.decoder_estimator_up_blocks_0_0_res_conv.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.0.res_conv", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_0_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_0_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.norm1
        x = self.decoder_estimator_up_blocks_0_1_0_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.0.norm3
        x = self.decoder_estimator_up_blocks_0_1_0_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.0.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_1_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_1_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.norm1
        x = self.decoder_estimator_up_blocks_0_1_1_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.1.norm3
        x = self.decoder_estimator_up_blocks_0_1_1_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.1.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_2_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_2_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.norm1
        x = self.decoder_estimator_up_blocks_0_1_2_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.2.norm3
        x = self.decoder_estimator_up_blocks_0_1_2_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.2.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_k
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_k.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_k", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_out.0
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_out_0.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_out.0", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_out.1
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_out_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_out.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_q
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_q.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_q", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.attn1.to_v
        x = self.decoder_estimator_up_blocks_0_1_3_attn1_to_v.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.attn1.to_v", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.0.proj
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_0_proj.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.0.proj", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.1
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.ff.net.2
        x = self.decoder_estimator_up_blocks_0_1_3_ff_net_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.ff.net.2", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.norm1
        x = self.decoder_estimator_up_blocks_0_1_3_norm1.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.norm1", &x);

        // Layer: decoder.estimator.up_blocks.0.1.3.norm3
        x = self.decoder_estimator_up_blocks_0_1_3_norm3.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.1.3.norm3", &x);

        // Layer: decoder.estimator.up_blocks.0.2
        x = self.decoder_estimator_up_blocks_0_2.forward(&x)?;
        py_check!(self.checker, "decoder.estimator.up_blocks.0.2", &x);

        // Layer: encoder.after_norm
        x = self.encoder_after_norm.forward(&x)?;
        py_check!(self.checker, "encoder.after_norm", &x);

        // Layer: encoder.embed.out.0
        x = self.encoder_embed_out_0.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.0", &x);

        // Layer: encoder.embed.out.1
        x = self.encoder_embed_out_1.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.1", &x);

        // Layer: encoder.embed.out.2
        x = self.encoder_embed_out_2.forward(&x)?;
        py_check!(self.checker, "encoder.embed.out.2", &x);

        // Layer: encoder.embed.pos_enc.dropout
        x = self.encoder_embed_pos_enc_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.embed.pos_enc.dropout", &x);

        // Layer: encoder.embed.pos_enc.dropout.1
        x = self.encoder_embed_pos_enc_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.embed.pos_enc.dropout.1", &x);

        // Layer: encoder.encoders.0.dropout
        x = self.encoder_encoders_0_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.dropout", &x);

        // Layer: encoder.encoders.0.dropout.1
        x = self.encoder_encoders_0_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.dropout.1", &x);

        // Layer: encoder.encoders.0.feed_forward.activation
        x = self.encoder_encoders_0_feed_forward_activation.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.1
        x = self.encoder_encoders_0_feed_forward_activation_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.1", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.2
        x = self.encoder_encoders_0_feed_forward_activation_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.2", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.3
        x = self.encoder_encoders_0_feed_forward_activation_3.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.3", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.4
        x = self.encoder_encoders_0_feed_forward_activation_4.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.4", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.5
        x = self.encoder_encoders_0_feed_forward_activation_5.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.5", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.6
        x = self.encoder_encoders_0_feed_forward_activation_6.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.6", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.7
        x = self.encoder_encoders_0_feed_forward_activation_7.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.7", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.8
        x = self.encoder_encoders_0_feed_forward_activation_8.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.8", &x);

        // Layer: encoder.encoders.0.feed_forward.activation.9
        x = self.encoder_encoders_0_feed_forward_activation_9.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.activation.9", &x);

        // Layer: encoder.encoders.0.feed_forward.dropout
        x = self.encoder_encoders_0_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.dropout", &x);

        // Layer: encoder.encoders.0.feed_forward.w_1
        x = self.encoder_encoders_0_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.w_1", &x);

        // Layer: encoder.encoders.0.feed_forward.w_2
        x = self.encoder_encoders_0_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.feed_forward.w_2", &x);

        // Layer: encoder.encoders.0.norm_ff
        x = self.encoder_encoders_0_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.norm_ff", &x);

        // Layer: encoder.encoders.0.norm_mha
        x = self.encoder_encoders_0_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.norm_mha", &x);

        // Layer: encoder.encoders.0.self_attn.dropout
        x = self.encoder_encoders_0_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.dropout", &x);

        // Layer: encoder.encoders.0.self_attn.linear_k
        x = self.encoder_encoders_0_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_k", &x);

        // Layer: encoder.encoders.0.self_attn.linear_out
        x = self.encoder_encoders_0_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_out", &x);

        // Layer: encoder.encoders.0.self_attn.linear_pos
        x = self.encoder_encoders_0_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.0.self_attn.linear_q
        x = self.encoder_encoders_0_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_q", &x);

        // Layer: encoder.encoders.0.self_attn.linear_v
        x = self.encoder_encoders_0_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.0.self_attn.linear_v", &x);

        // Layer: encoder.encoders.1.dropout
        x = self.encoder_encoders_1_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.dropout", &x);

        // Layer: encoder.encoders.1.dropout.1
        x = self.encoder_encoders_1_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.dropout.1", &x);

        // Layer: encoder.encoders.1.feed_forward.dropout
        x = self.encoder_encoders_1_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.dropout", &x);

        // Layer: encoder.encoders.1.feed_forward.w_1
        x = self.encoder_encoders_1_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.w_1", &x);

        // Layer: encoder.encoders.1.feed_forward.w_2
        x = self.encoder_encoders_1_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.feed_forward.w_2", &x);

        // Layer: encoder.encoders.1.norm_ff
        x = self.encoder_encoders_1_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.norm_ff", &x);

        // Layer: encoder.encoders.1.norm_mha
        x = self.encoder_encoders_1_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.norm_mha", &x);

        // Layer: encoder.encoders.1.self_attn.dropout
        x = self.encoder_encoders_1_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.dropout", &x);

        // Layer: encoder.encoders.1.self_attn.linear_k
        x = self.encoder_encoders_1_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_k", &x);

        // Layer: encoder.encoders.1.self_attn.linear_out
        x = self.encoder_encoders_1_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_out", &x);

        // Layer: encoder.encoders.1.self_attn.linear_pos
        x = self.encoder_encoders_1_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.1.self_attn.linear_q
        x = self.encoder_encoders_1_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_q", &x);

        // Layer: encoder.encoders.1.self_attn.linear_v
        x = self.encoder_encoders_1_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.1.self_attn.linear_v", &x);

        // Layer: encoder.encoders.2.dropout
        x = self.encoder_encoders_2_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.dropout", &x);

        // Layer: encoder.encoders.2.dropout.1
        x = self.encoder_encoders_2_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.dropout.1", &x);

        // Layer: encoder.encoders.2.feed_forward.dropout
        x = self.encoder_encoders_2_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.dropout", &x);

        // Layer: encoder.encoders.2.feed_forward.w_1
        x = self.encoder_encoders_2_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.w_1", &x);

        // Layer: encoder.encoders.2.feed_forward.w_2
        x = self.encoder_encoders_2_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.feed_forward.w_2", &x);

        // Layer: encoder.encoders.2.norm_ff
        x = self.encoder_encoders_2_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.norm_ff", &x);

        // Layer: encoder.encoders.2.norm_mha
        x = self.encoder_encoders_2_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.norm_mha", &x);

        // Layer: encoder.encoders.2.self_attn.dropout
        x = self.encoder_encoders_2_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.dropout", &x);

        // Layer: encoder.encoders.2.self_attn.linear_k
        x = self.encoder_encoders_2_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_k", &x);

        // Layer: encoder.encoders.2.self_attn.linear_out
        x = self.encoder_encoders_2_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_out", &x);

        // Layer: encoder.encoders.2.self_attn.linear_pos
        x = self.encoder_encoders_2_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.2.self_attn.linear_q
        x = self.encoder_encoders_2_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_q", &x);

        // Layer: encoder.encoders.2.self_attn.linear_v
        x = self.encoder_encoders_2_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.2.self_attn.linear_v", &x);

        // Layer: encoder.encoders.3.dropout
        x = self.encoder_encoders_3_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.dropout", &x);

        // Layer: encoder.encoders.3.dropout.1
        x = self.encoder_encoders_3_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.dropout.1", &x);

        // Layer: encoder.encoders.3.feed_forward.dropout
        x = self.encoder_encoders_3_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.dropout", &x);

        // Layer: encoder.encoders.3.feed_forward.w_1
        x = self.encoder_encoders_3_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.w_1", &x);

        // Layer: encoder.encoders.3.feed_forward.w_2
        x = self.encoder_encoders_3_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.feed_forward.w_2", &x);

        // Layer: encoder.encoders.3.norm_ff
        x = self.encoder_encoders_3_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.norm_ff", &x);

        // Layer: encoder.encoders.3.norm_mha
        x = self.encoder_encoders_3_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.norm_mha", &x);

        // Layer: encoder.encoders.3.self_attn.dropout
        x = self.encoder_encoders_3_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.dropout", &x);

        // Layer: encoder.encoders.3.self_attn.linear_k
        x = self.encoder_encoders_3_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_k", &x);

        // Layer: encoder.encoders.3.self_attn.linear_out
        x = self.encoder_encoders_3_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_out", &x);

        // Layer: encoder.encoders.3.self_attn.linear_pos
        x = self.encoder_encoders_3_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.3.self_attn.linear_q
        x = self.encoder_encoders_3_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_q", &x);

        // Layer: encoder.encoders.3.self_attn.linear_v
        x = self.encoder_encoders_3_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.3.self_attn.linear_v", &x);

        // Layer: encoder.encoders.4.dropout
        x = self.encoder_encoders_4_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.dropout", &x);

        // Layer: encoder.encoders.4.dropout.1
        x = self.encoder_encoders_4_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.dropout.1", &x);

        // Layer: encoder.encoders.4.feed_forward.dropout
        x = self.encoder_encoders_4_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.dropout", &x);

        // Layer: encoder.encoders.4.feed_forward.w_1
        x = self.encoder_encoders_4_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.w_1", &x);

        // Layer: encoder.encoders.4.feed_forward.w_2
        x = self.encoder_encoders_4_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.feed_forward.w_2", &x);

        // Layer: encoder.encoders.4.norm_ff
        x = self.encoder_encoders_4_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.norm_ff", &x);

        // Layer: encoder.encoders.4.norm_mha
        x = self.encoder_encoders_4_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.norm_mha", &x);

        // Layer: encoder.encoders.4.self_attn.dropout
        x = self.encoder_encoders_4_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.dropout", &x);

        // Layer: encoder.encoders.4.self_attn.linear_k
        x = self.encoder_encoders_4_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_k", &x);

        // Layer: encoder.encoders.4.self_attn.linear_out
        x = self.encoder_encoders_4_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_out", &x);

        // Layer: encoder.encoders.4.self_attn.linear_pos
        x = self.encoder_encoders_4_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.4.self_attn.linear_q
        x = self.encoder_encoders_4_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_q", &x);

        // Layer: encoder.encoders.4.self_attn.linear_v
        x = self.encoder_encoders_4_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.4.self_attn.linear_v", &x);

        // Layer: encoder.encoders.5.dropout
        x = self.encoder_encoders_5_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.dropout", &x);

        // Layer: encoder.encoders.5.dropout.1
        x = self.encoder_encoders_5_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.dropout.1", &x);

        // Layer: encoder.encoders.5.feed_forward.dropout
        x = self.encoder_encoders_5_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.dropout", &x);

        // Layer: encoder.encoders.5.feed_forward.w_1
        x = self.encoder_encoders_5_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.w_1", &x);

        // Layer: encoder.encoders.5.feed_forward.w_2
        x = self.encoder_encoders_5_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.feed_forward.w_2", &x);

        // Layer: encoder.encoders.5.norm_ff
        x = self.encoder_encoders_5_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.norm_ff", &x);

        // Layer: encoder.encoders.5.norm_mha
        x = self.encoder_encoders_5_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.norm_mha", &x);

        // Layer: encoder.encoders.5.self_attn.dropout
        x = self.encoder_encoders_5_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.dropout", &x);

        // Layer: encoder.encoders.5.self_attn.linear_k
        x = self.encoder_encoders_5_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_k", &x);

        // Layer: encoder.encoders.5.self_attn.linear_out
        x = self.encoder_encoders_5_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_out", &x);

        // Layer: encoder.encoders.5.self_attn.linear_pos
        x = self.encoder_encoders_5_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_pos", &x);

        // Layer: encoder.encoders.5.self_attn.linear_q
        x = self.encoder_encoders_5_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_q", &x);

        // Layer: encoder.encoders.5.self_attn.linear_v
        x = self.encoder_encoders_5_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.encoders.5.self_attn.linear_v", &x);

        // Layer: encoder.pre_lookahead_layer.conv1
        x = self.encoder_pre_lookahead_layer_conv1.forward(&x)?;
        py_check!(self.checker, "encoder.pre_lookahead_layer.conv1", &x);

        // Layer: encoder.pre_lookahead_layer.conv2
        x = self.encoder_pre_lookahead_layer_conv2.forward(&x)?;
        py_check!(self.checker, "encoder.pre_lookahead_layer.conv2", &x);

        // Layer: encoder.up_embed.out.0
        x = self.encoder_up_embed_out_0.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.0", &x);

        // Layer: encoder.up_embed.out.1
        x = self.encoder_up_embed_out_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.1", &x);

        // Layer: encoder.up_embed.out.2
        x = self.encoder_up_embed_out_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.out.2", &x);

        // Layer: encoder.up_embed.pos_enc.dropout
        x = self.encoder_up_embed_pos_enc_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.pos_enc.dropout", &x);

        // Layer: encoder.up_embed.pos_enc.dropout.1
        x = self.encoder_up_embed_pos_enc_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_embed.pos_enc.dropout.1", &x);

        // Layer: encoder.up_encoders.0.dropout
        x = self.encoder_up_encoders_0_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.dropout", &x);

        // Layer: encoder.up_encoders.0.dropout.1
        x = self.encoder_up_encoders_0_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.dropout.1", &x);

        // Layer: encoder.up_encoders.0.feed_forward.dropout
        x = self.encoder_up_encoders_0_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.0.feed_forward.w_1
        x = self.encoder_up_encoders_0_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.0.feed_forward.w_2
        x = self.encoder_up_encoders_0_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.0.norm_ff
        x = self.encoder_up_encoders_0_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.norm_ff", &x);

        // Layer: encoder.up_encoders.0.norm_mha
        x = self.encoder_up_encoders_0_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.norm_mha", &x);

        // Layer: encoder.up_encoders.0.self_attn.dropout
        x = self.encoder_up_encoders_0_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_k
        x = self.encoder_up_encoders_0_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_out
        x = self.encoder_up_encoders_0_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_pos
        x = self.encoder_up_encoders_0_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_q
        x = self.encoder_up_encoders_0_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.0.self_attn.linear_v
        x = self.encoder_up_encoders_0_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.0.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.1.dropout
        x = self.encoder_up_encoders_1_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.dropout", &x);

        // Layer: encoder.up_encoders.1.dropout.1
        x = self.encoder_up_encoders_1_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.dropout.1", &x);

        // Layer: encoder.up_encoders.1.feed_forward.dropout
        x = self.encoder_up_encoders_1_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.1.feed_forward.w_1
        x = self.encoder_up_encoders_1_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.1.feed_forward.w_2
        x = self.encoder_up_encoders_1_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.1.norm_ff
        x = self.encoder_up_encoders_1_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.norm_ff", &x);

        // Layer: encoder.up_encoders.1.norm_mha
        x = self.encoder_up_encoders_1_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.norm_mha", &x);

        // Layer: encoder.up_encoders.1.self_attn.dropout
        x = self.encoder_up_encoders_1_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_k
        x = self.encoder_up_encoders_1_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_out
        x = self.encoder_up_encoders_1_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_pos
        x = self.encoder_up_encoders_1_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_q
        x = self.encoder_up_encoders_1_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.1.self_attn.linear_v
        x = self.encoder_up_encoders_1_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.1.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.2.dropout
        x = self.encoder_up_encoders_2_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.dropout", &x);

        // Layer: encoder.up_encoders.2.dropout.1
        x = self.encoder_up_encoders_2_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.dropout.1", &x);

        // Layer: encoder.up_encoders.2.feed_forward.dropout
        x = self.encoder_up_encoders_2_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.2.feed_forward.w_1
        x = self.encoder_up_encoders_2_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.2.feed_forward.w_2
        x = self.encoder_up_encoders_2_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.2.norm_ff
        x = self.encoder_up_encoders_2_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.norm_ff", &x);

        // Layer: encoder.up_encoders.2.norm_mha
        x = self.encoder_up_encoders_2_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.norm_mha", &x);

        // Layer: encoder.up_encoders.2.self_attn.dropout
        x = self.encoder_up_encoders_2_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_k
        x = self.encoder_up_encoders_2_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_out
        x = self.encoder_up_encoders_2_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_pos
        x = self.encoder_up_encoders_2_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_q
        x = self.encoder_up_encoders_2_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.2.self_attn.linear_v
        x = self.encoder_up_encoders_2_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.2.self_attn.linear_v", &x);

        // Layer: encoder.up_encoders.3.dropout
        x = self.encoder_up_encoders_3_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.dropout", &x);

        // Layer: encoder.up_encoders.3.dropout.1
        x = self.encoder_up_encoders_3_dropout_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.dropout.1", &x);

        // Layer: encoder.up_encoders.3.feed_forward.dropout
        x = self.encoder_up_encoders_3_feed_forward_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.dropout", &x);

        // Layer: encoder.up_encoders.3.feed_forward.w_1
        x = self.encoder_up_encoders_3_feed_forward_w_1.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.w_1", &x);

        // Layer: encoder.up_encoders.3.feed_forward.w_2
        x = self.encoder_up_encoders_3_feed_forward_w_2.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.feed_forward.w_2", &x);

        // Layer: encoder.up_encoders.3.norm_ff
        x = self.encoder_up_encoders_3_norm_ff.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.norm_ff", &x);

        // Layer: encoder.up_encoders.3.norm_mha
        x = self.encoder_up_encoders_3_norm_mha.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.norm_mha", &x);

        // Layer: encoder.up_encoders.3.self_attn.dropout
        x = self.encoder_up_encoders_3_self_attn_dropout.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.dropout", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_k
        x = self.encoder_up_encoders_3_self_attn_linear_k.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_k", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_out
        x = self.encoder_up_encoders_3_self_attn_linear_out.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_out", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_pos
        x = self.encoder_up_encoders_3_self_attn_linear_pos.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_pos", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_q
        x = self.encoder_up_encoders_3_self_attn_linear_q.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_q", &x);

        // Layer: encoder.up_encoders.3.self_attn.linear_v
        x = self.encoder_up_encoders_3_self_attn_linear_v.forward(&x)?;
        py_check!(self.checker, "encoder.up_encoders.3.self_attn.linear_v", &x);

        // Layer: encoder.up_layer.conv
        x = self.encoder_up_layer_conv.forward(&x)?;
        py_check!(self.checker, "encoder.up_layer.conv", &x);

        // Layer: encoder_proj
        x = self.encoder_proj.forward(&x)?;
        py_check!(self.checker, "encoder_proj", &x);

        // Layer: input_embedding
        x = self.input_embedding.forward(&x)?;
        py_check!(self.checker, "input_embedding", &x);

        // Layer: spk_embed_affine_layer
        x = self.spk_embed_affine_layer.forward(&x)?;
        py_check!(self.checker, "spk_embed_affine_layer", &x);

        Ok(x)
    }
    fn manual_pad(x: &Tensor, dim: usize, left: usize, right: usize) -> Result<Tensor> {
        let mut chunks = Vec::new();
        if left > 0 {
            let mut shape = x.dims().to_vec();
            shape[dim] = left;
            chunks.push(Tensor::zeros(shape, x.dtype(), x.device())?);
        }
        chunks.push(x.clone());
        if right > 0 {
            let mut shape = x.dims().to_vec();
            shape[dim] = right;
            chunks.push(Tensor::zeros(shape, x.dtype(), x.device())?);
        }
        Tensor::cat(&chunks, dim)
    }

    pub fn mean_flow(&self, tokens: &Tensor) -> Result<Tensor> {
        let _b = tokens.dim(0)?;
        let _t = tokens.dim(1)?;
        let mut x = self.input_embedding.forward(tokens)?; // [B, T, 512]

        // --- 1. encoder.embed ---
        x = self.encoder_embed_out_0.forward(&x)?;
        x = self.encoder_embed_out_1.forward(&x)?;
        x = self.encoder_embed_out_2.forward(&x)?;

        // --- 2. Pre-Lookahead ---
        {
            let residual = x.clone();
            let mut h = x.transpose(1, 2)?;
            h = Self::manual_pad(&h, 2, 0, 3)?; // Pad end
            h = self.encoder_pre_lookahead_layer_conv1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = Self::manual_pad(&h, 2, 2, 0)?; // Pad start
            h = self.encoder_pre_lookahead_layer_conv2.forward(&h)?;
            x = (h.transpose(1, 2)? + residual)?;
        }

        // --- 3. Conformer Blocks (0-5) ---
        // Block 0
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_0_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_0_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_0_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_0_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_0_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_0_norm_ff.forward(&x)?;
            h = self.encoder_encoders_0_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_0_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 1
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_1_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_1_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_1_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_1_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_1_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_1_norm_ff.forward(&x)?;
            h = self.encoder_encoders_1_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_1_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 2
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_2_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_2_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_2_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_2_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_2_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_2_norm_ff.forward(&x)?;
            h = self.encoder_encoders_2_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_2_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 3
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_3_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_3_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_3_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_3_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_3_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_3_norm_ff.forward(&x)?;
            h = self.encoder_encoders_3_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_3_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 4
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_4_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_4_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_4_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_4_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_4_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_4_norm_ff.forward(&x)?;
            h = self.encoder_encoders_4_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_4_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 5
        {
            let residual = x.clone();
            let mut h = self.encoder_encoders_5_norm_mha.forward(&x)?;
            let q = self.encoder_encoders_5_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_encoders_5_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_encoders_5_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_encoders_5_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_encoders_5_norm_ff.forward(&x)?;
            h = self.encoder_encoders_5_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_encoders_5_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }

        // --- 4. Upsample 1D ---
        {
            let current_t = x.dim(1)?;
            x = x.transpose(1, 2)?;
            x = x.unsqueeze(2)?.upsample_nearest2d(1, current_t * 2)?.squeeze(2)?;
            x = Self::manual_pad(&x, 2, 4, 0)?; // Pad beginning with 4
            x = self.encoder_up_layer_conv.forward(&x)?; // [B, 512, 2T]
            x = x.transpose(1, 2)?;
        }

        // --- 5. up_embed ---
        x = self.encoder_up_embed_out_0.forward(&x)?;
        x = self.encoder_up_embed_out_1.forward(&x)?;
        x = self.encoder_up_embed_out_2.forward(&x)?;

        // --- 6. up_encoders (0-3) ---
        // Block 0
        {
            let residual = x.clone();
            let mut h = self.encoder_up_encoders_0_norm_mha.forward(&x)?;
            let q = self.encoder_up_encoders_0_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_up_encoders_0_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_up_encoders_0_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_up_encoders_0_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_up_encoders_0_norm_ff.forward(&x)?;
            h = self.encoder_up_encoders_0_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_up_encoders_0_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 1
        {
            let residual = x.clone();
            let mut h = self.encoder_up_encoders_1_norm_mha.forward(&x)?;
            let q = self.encoder_up_encoders_1_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_up_encoders_1_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_up_encoders_1_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_up_encoders_1_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_up_encoders_1_norm_ff.forward(&x)?;
            h = self.encoder_up_encoders_1_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_up_encoders_1_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 2
        {
            let residual = x.clone();
            let mut h = self.encoder_up_encoders_2_norm_mha.forward(&x)?;
            let q = self.encoder_up_encoders_2_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_up_encoders_2_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_up_encoders_2_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_up_encoders_2_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_up_encoders_2_norm_ff.forward(&x)?;
            h = self.encoder_up_encoders_2_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_up_encoders_2_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }
        // Block 3
        {
            let residual = x.clone();
            let mut h = self.encoder_up_encoders_3_norm_mha.forward(&x)?;
            let q = self.encoder_up_encoders_3_self_attn_linear_q.forward(&h)?;
            let k = self.encoder_up_encoders_3_self_attn_linear_k.forward(&h)?;
            let v = self.encoder_up_encoders_3_self_attn_linear_v.forward(&h)?;
            h = self.apply_std_mha(&q, &k, &v, 8)?;
            x = (self.encoder_up_encoders_3_self_attn_linear_out.forward(&h)? + residual)?;

            let residual = x.clone();
            let mut h = self.encoder_up_encoders_3_norm_ff.forward(&x)?;
            h = self.encoder_up_encoders_3_feed_forward_w_1.forward(&h)?;
            h = (h.clone() * candle_nn::ops::sigmoid(&h)?)?;
            h = self.encoder_up_encoders_3_feed_forward_w_2.forward(&h)?;
            x = (h + residual)?;
        }

        // --- 7. Final ---
        x = self.encoder_after_norm.forward(&x)?;
        x = self.encoder_proj.forward(&x)?;

        Ok(x.transpose(1, 2)?) // Return [B, 80, 2T]
    }

    fn apply_std_mha(&self, q: &Tensor, k: &Tensor, v: &Tensor, n_heads: usize) -> Result<Tensor> {
        let (b, t, d) = q.dims3()?;
        let dk = d / n_heads;
        let q = q.reshape((b, t, n_heads, dk))?.transpose(1, 2)?;
        let k = k.reshape((b, t, n_heads, dk))?.transpose(1, 2)?;
        let v = v.reshape((b, t, n_heads, dk))?.transpose(1, 2)?;

        let scores = (q.matmul(&k.transpose(2, 3)?)? / (dk as f64).sqrt())?;
        let attn = candle_nn::ops::softmax(&scores, 3)?;
        let x = attn.matmul(&v)?;
        x.transpose(1, 2)?.reshape((b, t, d))
    }
}
</file>

<file path="dx_simulation/src/t3_transformer.rs">
use candle_core::{Result, Tensor, IndexOp, Shape};
use candle_nn::{Module, VarBuilder};
use pycandle_core::{PyChecker, py_check, VerificationMode, layers::*};

pub struct Config {
    pub context_length: usize, // 8196
    pub hidden_dim: usize, // 1024
    pub n_head: usize, // 16
    pub n_layers: usize, // 24
    pub vocab_size: usize, // 50276
}
pub struct T3Transformer {
    pub drop: Dropout,
    pub h_0_attn_c_attn: candle_nn::Linear,
    pub h_0_attn_c_proj: candle_nn::Linear,
    pub h_0_attn_resid_dropout: Dropout,
    pub h_0_ln_1: candle_nn::LayerNorm,
    pub h_0_ln_2: candle_nn::LayerNorm,
    pub h_0_mlp_act: candle_nn::Activation,
    pub h_0_mlp_c_fc: candle_nn::Linear,
    pub h_0_mlp_c_proj: candle_nn::Linear,
    pub h_0_mlp_dropout: Dropout,
    pub h_1_attn_c_attn: candle_nn::Linear,
    pub h_1_attn_c_proj: candle_nn::Linear,
    pub h_1_attn_resid_dropout: Dropout,
    pub h_1_ln_1: candle_nn::LayerNorm,
    pub h_1_ln_2: candle_nn::LayerNorm,
    pub h_1_mlp_act: candle_nn::Activation,
    pub h_1_mlp_c_fc: candle_nn::Linear,
    pub h_1_mlp_c_proj: candle_nn::Linear,
    pub h_1_mlp_dropout: Dropout,
    pub h_10_attn_c_attn: candle_nn::Linear,
    pub h_10_attn_c_proj: candle_nn::Linear,
    pub h_10_attn_resid_dropout: Dropout,
    pub h_10_ln_1: candle_nn::LayerNorm,
    pub h_10_ln_2: candle_nn::LayerNorm,
    pub h_10_mlp_act: candle_nn::Activation,
    pub h_10_mlp_c_fc: candle_nn::Linear,
    pub h_10_mlp_c_proj: candle_nn::Linear,
    pub h_10_mlp_dropout: Dropout,
    pub h_11_attn_c_attn: candle_nn::Linear,
    pub h_11_attn_c_proj: candle_nn::Linear,
    pub h_11_attn_resid_dropout: Dropout,
    pub h_11_ln_1: candle_nn::LayerNorm,
    pub h_11_ln_2: candle_nn::LayerNorm,
    pub h_11_mlp_act: candle_nn::Activation,
    pub h_11_mlp_c_fc: candle_nn::Linear,
    pub h_11_mlp_c_proj: candle_nn::Linear,
    pub h_11_mlp_dropout: Dropout,
    pub h_12_attn_c_attn: candle_nn::Linear,
    pub h_12_attn_c_proj: candle_nn::Linear,
    pub h_12_attn_resid_dropout: Dropout,
    pub h_12_ln_1: candle_nn::LayerNorm,
    pub h_12_ln_2: candle_nn::LayerNorm,
    pub h_12_mlp_act: candle_nn::Activation,
    pub h_12_mlp_c_fc: candle_nn::Linear,
    pub h_12_mlp_c_proj: candle_nn::Linear,
    pub h_12_mlp_dropout: Dropout,
    pub h_13_attn_c_attn: candle_nn::Linear,
    pub h_13_attn_c_proj: candle_nn::Linear,
    pub h_13_attn_resid_dropout: Dropout,
    pub h_13_ln_1: candle_nn::LayerNorm,
    pub h_13_ln_2: candle_nn::LayerNorm,
    pub h_13_mlp_act: candle_nn::Activation,
    pub h_13_mlp_c_fc: candle_nn::Linear,
    pub h_13_mlp_c_proj: candle_nn::Linear,
    pub h_13_mlp_dropout: Dropout,
    pub h_14_attn_c_attn: candle_nn::Linear,
    pub h_14_attn_c_proj: candle_nn::Linear,
    pub h_14_attn_resid_dropout: Dropout,
    pub h_14_ln_1: candle_nn::LayerNorm,
    pub h_14_ln_2: candle_nn::LayerNorm,
    pub h_14_mlp_act: candle_nn::Activation,
    pub h_14_mlp_c_fc: candle_nn::Linear,
    pub h_14_mlp_c_proj: candle_nn::Linear,
    pub h_14_mlp_dropout: Dropout,
    pub h_15_attn_c_attn: candle_nn::Linear,
    pub h_15_attn_c_proj: candle_nn::Linear,
    pub h_15_attn_resid_dropout: Dropout,
    pub h_15_ln_1: candle_nn::LayerNorm,
    pub h_15_ln_2: candle_nn::LayerNorm,
    pub h_15_mlp_act: candle_nn::Activation,
    pub h_15_mlp_c_fc: candle_nn::Linear,
    pub h_15_mlp_c_proj: candle_nn::Linear,
    pub h_15_mlp_dropout: Dropout,
    pub h_16_attn_c_attn: candle_nn::Linear,
    pub h_16_attn_c_proj: candle_nn::Linear,
    pub h_16_attn_resid_dropout: Dropout,
    pub h_16_ln_1: candle_nn::LayerNorm,
    pub h_16_ln_2: candle_nn::LayerNorm,
    pub h_16_mlp_act: candle_nn::Activation,
    pub h_16_mlp_c_fc: candle_nn::Linear,
    pub h_16_mlp_c_proj: candle_nn::Linear,
    pub h_16_mlp_dropout: Dropout,
    pub h_17_attn_c_attn: candle_nn::Linear,
    pub h_17_attn_c_proj: candle_nn::Linear,
    pub h_17_attn_resid_dropout: Dropout,
    pub h_17_ln_1: candle_nn::LayerNorm,
    pub h_17_ln_2: candle_nn::LayerNorm,
    pub h_17_mlp_act: candle_nn::Activation,
    pub h_17_mlp_c_fc: candle_nn::Linear,
    pub h_17_mlp_c_proj: candle_nn::Linear,
    pub h_17_mlp_dropout: Dropout,
    pub h_18_attn_c_attn: candle_nn::Linear,
    pub h_18_attn_c_proj: candle_nn::Linear,
    pub h_18_attn_resid_dropout: Dropout,
    pub h_18_ln_1: candle_nn::LayerNorm,
    pub h_18_ln_2: candle_nn::LayerNorm,
    pub h_18_mlp_act: candle_nn::Activation,
    pub h_18_mlp_c_fc: candle_nn::Linear,
    pub h_18_mlp_c_proj: candle_nn::Linear,
    pub h_18_mlp_dropout: Dropout,
    pub h_19_attn_c_attn: candle_nn::Linear,
    pub h_19_attn_c_proj: candle_nn::Linear,
    pub h_19_attn_resid_dropout: Dropout,
    pub h_19_ln_1: candle_nn::LayerNorm,
    pub h_19_ln_2: candle_nn::LayerNorm,
    pub h_19_mlp_act: candle_nn::Activation,
    pub h_19_mlp_c_fc: candle_nn::Linear,
    pub h_19_mlp_c_proj: candle_nn::Linear,
    pub h_19_mlp_dropout: Dropout,
    pub h_2_attn_c_attn: candle_nn::Linear,
    pub h_2_attn_c_proj: candle_nn::Linear,
    pub h_2_attn_resid_dropout: Dropout,
    pub h_2_ln_1: candle_nn::LayerNorm,
    pub h_2_ln_2: candle_nn::LayerNorm,
    pub h_2_mlp_act: candle_nn::Activation,
    pub h_2_mlp_c_fc: candle_nn::Linear,
    pub h_2_mlp_c_proj: candle_nn::Linear,
    pub h_2_mlp_dropout: Dropout,
    pub h_20_attn_c_attn: candle_nn::Linear,
    pub h_20_attn_c_proj: candle_nn::Linear,
    pub h_20_attn_resid_dropout: Dropout,
    pub h_20_ln_1: candle_nn::LayerNorm,
    pub h_20_ln_2: candle_nn::LayerNorm,
    pub h_20_mlp_act: candle_nn::Activation,
    pub h_20_mlp_c_fc: candle_nn::Linear,
    pub h_20_mlp_c_proj: candle_nn::Linear,
    pub h_20_mlp_dropout: Dropout,
    pub h_21_attn_c_attn: candle_nn::Linear,
    pub h_21_attn_c_proj: candle_nn::Linear,
    pub h_21_attn_resid_dropout: Dropout,
    pub h_21_ln_1: candle_nn::LayerNorm,
    pub h_21_ln_2: candle_nn::LayerNorm,
    pub h_21_mlp_act: candle_nn::Activation,
    pub h_21_mlp_c_fc: candle_nn::Linear,
    pub h_21_mlp_c_proj: candle_nn::Linear,
    pub h_21_mlp_dropout: Dropout,
    pub h_22_attn_c_attn: candle_nn::Linear,
    pub h_22_attn_c_proj: candle_nn::Linear,
    pub h_22_attn_resid_dropout: Dropout,
    pub h_22_ln_1: candle_nn::LayerNorm,
    pub h_22_ln_2: candle_nn::LayerNorm,
    pub h_22_mlp_act: candle_nn::Activation,
    pub h_22_mlp_c_fc: candle_nn::Linear,
    pub h_22_mlp_c_proj: candle_nn::Linear,
    pub h_22_mlp_dropout: Dropout,
    pub h_23_attn_c_attn: candle_nn::Linear,
    pub h_23_attn_c_proj: candle_nn::Linear,
    pub h_23_attn_resid_dropout: Dropout,
    pub h_23_ln_1: candle_nn::LayerNorm,
    pub h_23_ln_2: candle_nn::LayerNorm,
    pub h_23_mlp_act: candle_nn::Activation,
    pub h_23_mlp_c_fc: candle_nn::Linear,
    pub h_23_mlp_c_proj: candle_nn::Linear,
    pub h_23_mlp_dropout: Dropout,
    pub h_3_attn_c_attn: candle_nn::Linear,
    pub h_3_attn_c_proj: candle_nn::Linear,
    pub h_3_attn_resid_dropout: Dropout,
    pub h_3_ln_1: candle_nn::LayerNorm,
    pub h_3_ln_2: candle_nn::LayerNorm,
    pub h_3_mlp_act: candle_nn::Activation,
    pub h_3_mlp_c_fc: candle_nn::Linear,
    pub h_3_mlp_c_proj: candle_nn::Linear,
    pub h_3_mlp_dropout: Dropout,
    pub h_4_attn_c_attn: candle_nn::Linear,
    pub h_4_attn_c_proj: candle_nn::Linear,
    pub h_4_attn_resid_dropout: Dropout,
    pub h_4_ln_1: candle_nn::LayerNorm,
    pub h_4_ln_2: candle_nn::LayerNorm,
    pub h_4_mlp_act: candle_nn::Activation,
    pub h_4_mlp_c_fc: candle_nn::Linear,
    pub h_4_mlp_c_proj: candle_nn::Linear,
    pub h_4_mlp_dropout: Dropout,
    pub h_5_attn_c_attn: candle_nn::Linear,
    pub h_5_attn_c_proj: candle_nn::Linear,
    pub h_5_attn_resid_dropout: Dropout,
    pub h_5_ln_1: candle_nn::LayerNorm,
    pub h_5_ln_2: candle_nn::LayerNorm,
    pub h_5_mlp_act: candle_nn::Activation,
    pub h_5_mlp_c_fc: candle_nn::Linear,
    pub h_5_mlp_c_proj: candle_nn::Linear,
    pub h_5_mlp_dropout: Dropout,
    pub h_6_attn_c_attn: candle_nn::Linear,
    pub h_6_attn_c_proj: candle_nn::Linear,
    pub h_6_attn_resid_dropout: Dropout,
    pub h_6_ln_1: candle_nn::LayerNorm,
    pub h_6_ln_2: candle_nn::LayerNorm,
    pub h_6_mlp_act: candle_nn::Activation,
    pub h_6_mlp_c_fc: candle_nn::Linear,
    pub h_6_mlp_c_proj: candle_nn::Linear,
    pub h_6_mlp_dropout: Dropout,
    pub h_7_attn_c_attn: candle_nn::Linear,
    pub h_7_attn_c_proj: candle_nn::Linear,
    pub h_7_attn_resid_dropout: Dropout,
    pub h_7_ln_1: candle_nn::LayerNorm,
    pub h_7_ln_2: candle_nn::LayerNorm,
    pub h_7_mlp_act: candle_nn::Activation,
    pub h_7_mlp_c_fc: candle_nn::Linear,
    pub h_7_mlp_c_proj: candle_nn::Linear,
    pub h_7_mlp_dropout: Dropout,
    pub h_8_attn_c_attn: candle_nn::Linear,
    pub h_8_attn_c_proj: candle_nn::Linear,
    pub h_8_attn_resid_dropout: Dropout,
    pub h_8_ln_1: candle_nn::LayerNorm,
    pub h_8_ln_2: candle_nn::LayerNorm,
    pub h_8_mlp_act: candle_nn::Activation,
    pub h_8_mlp_c_fc: candle_nn::Linear,
    pub h_8_mlp_c_proj: candle_nn::Linear,
    pub h_8_mlp_dropout: Dropout,
    pub h_9_attn_c_attn: candle_nn::Linear,
    pub h_9_attn_c_proj: candle_nn::Linear,
    pub h_9_attn_resid_dropout: Dropout,
    pub h_9_ln_1: candle_nn::LayerNorm,
    pub h_9_ln_2: candle_nn::LayerNorm,
    pub h_9_mlp_act: candle_nn::Activation,
    pub h_9_mlp_c_fc: candle_nn::Linear,
    pub h_9_mlp_c_proj: candle_nn::Linear,
    pub h_9_mlp_dropout: Dropout,
    pub ln_f: candle_nn::LayerNorm,
    pub wpe: candle_nn::Embedding,
    pub checker: Option<PyChecker>,
}

impl T3Transformer {
    #[allow(unused_variables)]
    pub fn load(config: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let gpt2_cfg = pycandle_core::gpt2::Config {
            vocab_size: config.vocab_size,
            context_length: config.context_length,
            emb_dim: config.hidden_dim,
            n_heads: config.n_head,
            n_layers: config.n_layers,
            ..Default::default()
        };
        let drop = Dropout::new();
        let h_0_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.0.attn.c_attn"))?;
        let h_0_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.0.attn.c_proj"))?;
        let h_0_attn_resid_dropout = Dropout::new();
        let h_0_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_1"))?;
        let h_0_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.0.ln_2"))?;
        let h_0_mlp_act = candle_nn::Activation::NewGelu;
        let h_0_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.0.mlp.c_fc"))?;
        let h_0_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.0.mlp.c_proj"))?;
        let h_0_mlp_dropout = Dropout::new();
        let h_1_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.1.attn.c_attn"))?;
        let h_1_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.1.attn.c_proj"))?;
        let h_1_attn_resid_dropout = Dropout::new();
        let h_1_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_1"))?;
        let h_1_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.1.ln_2"))?;
        let h_1_mlp_act = candle_nn::Activation::NewGelu;
        let h_1_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.1.mlp.c_fc"))?;
        let h_1_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.1.mlp.c_proj"))?;
        let h_1_mlp_dropout = Dropout::new();
        let h_10_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.10.attn.c_attn"))?;
        let h_10_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.10.attn.c_proj"))?;
        let h_10_attn_resid_dropout = Dropout::new();
        let h_10_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_1"))?;
        let h_10_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.10.ln_2"))?;
        let h_10_mlp_act = candle_nn::Activation::NewGelu;
        let h_10_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.10.mlp.c_fc"))?;
        let h_10_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.10.mlp.c_proj"))?;
        let h_10_mlp_dropout = Dropout::new();
        let h_11_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.11.attn.c_attn"))?;
        let h_11_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.11.attn.c_proj"))?;
        let h_11_attn_resid_dropout = Dropout::new();
        let h_11_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_1"))?;
        let h_11_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.11.ln_2"))?;
        let h_11_mlp_act = candle_nn::Activation::NewGelu;
        let h_11_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.11.mlp.c_fc"))?;
        let h_11_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.11.mlp.c_proj"))?;
        let h_11_mlp_dropout = Dropout::new();
        let h_12_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.12.attn.c_attn"))?;
        let h_12_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.12.attn.c_proj"))?;
        let h_12_attn_resid_dropout = Dropout::new();
        let h_12_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_1"))?;
        let h_12_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.12.ln_2"))?;
        let h_12_mlp_act = candle_nn::Activation::NewGelu;
        let h_12_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.12.mlp.c_fc"))?;
        let h_12_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.12.mlp.c_proj"))?;
        let h_12_mlp_dropout = Dropout::new();
        let h_13_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.13.attn.c_attn"))?;
        let h_13_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.13.attn.c_proj"))?;
        let h_13_attn_resid_dropout = Dropout::new();
        let h_13_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_1"))?;
        let h_13_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.13.ln_2"))?;
        let h_13_mlp_act = candle_nn::Activation::NewGelu;
        let h_13_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.13.mlp.c_fc"))?;
        let h_13_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.13.mlp.c_proj"))?;
        let h_13_mlp_dropout = Dropout::new();
        let h_14_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.14.attn.c_attn"))?;
        let h_14_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.14.attn.c_proj"))?;
        let h_14_attn_resid_dropout = Dropout::new();
        let h_14_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_1"))?;
        let h_14_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.14.ln_2"))?;
        let h_14_mlp_act = candle_nn::Activation::NewGelu;
        let h_14_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.14.mlp.c_fc"))?;
        let h_14_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.14.mlp.c_proj"))?;
        let h_14_mlp_dropout = Dropout::new();
        let h_15_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.15.attn.c_attn"))?;
        let h_15_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.15.attn.c_proj"))?;
        let h_15_attn_resid_dropout = Dropout::new();
        let h_15_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_1"))?;
        let h_15_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.15.ln_2"))?;
        let h_15_mlp_act = candle_nn::Activation::NewGelu;
        let h_15_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.15.mlp.c_fc"))?;
        let h_15_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.15.mlp.c_proj"))?;
        let h_15_mlp_dropout = Dropout::new();
        let h_16_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.16.attn.c_attn"))?;
        let h_16_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.16.attn.c_proj"))?;
        let h_16_attn_resid_dropout = Dropout::new();
        let h_16_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_1"))?;
        let h_16_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.16.ln_2"))?;
        let h_16_mlp_act = candle_nn::Activation::NewGelu;
        let h_16_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.16.mlp.c_fc"))?;
        let h_16_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.16.mlp.c_proj"))?;
        let h_16_mlp_dropout = Dropout::new();
        let h_17_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.17.attn.c_attn"))?;
        let h_17_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.17.attn.c_proj"))?;
        let h_17_attn_resid_dropout = Dropout::new();
        let h_17_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_1"))?;
        let h_17_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.17.ln_2"))?;
        let h_17_mlp_act = candle_nn::Activation::NewGelu;
        let h_17_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.17.mlp.c_fc"))?;
        let h_17_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.17.mlp.c_proj"))?;
        let h_17_mlp_dropout = Dropout::new();
        let h_18_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.18.attn.c_attn"))?;
        let h_18_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.18.attn.c_proj"))?;
        let h_18_attn_resid_dropout = Dropout::new();
        let h_18_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_1"))?;
        let h_18_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.18.ln_2"))?;
        let h_18_mlp_act = candle_nn::Activation::NewGelu;
        let h_18_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.18.mlp.c_fc"))?;
        let h_18_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.18.mlp.c_proj"))?;
        let h_18_mlp_dropout = Dropout::new();
        let h_19_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.19.attn.c_attn"))?;
        let h_19_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.19.attn.c_proj"))?;
        let h_19_attn_resid_dropout = Dropout::new();
        let h_19_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_1"))?;
        let h_19_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.19.ln_2"))?;
        let h_19_mlp_act = candle_nn::Activation::NewGelu;
        let h_19_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.19.mlp.c_fc"))?;
        let h_19_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.19.mlp.c_proj"))?;
        let h_19_mlp_dropout = Dropout::new();
        let h_2_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.2.attn.c_attn"))?;
        let h_2_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.2.attn.c_proj"))?;
        let h_2_attn_resid_dropout = Dropout::new();
        let h_2_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_1"))?;
        let h_2_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.2.ln_2"))?;
        let h_2_mlp_act = candle_nn::Activation::NewGelu;
        let h_2_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.2.mlp.c_fc"))?;
        let h_2_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.2.mlp.c_proj"))?;
        let h_2_mlp_dropout = Dropout::new();
        let h_20_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.20.attn.c_attn"))?;
        let h_20_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.20.attn.c_proj"))?;
        let h_20_attn_resid_dropout = Dropout::new();
        let h_20_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_1"))?;
        let h_20_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.20.ln_2"))?;
        let h_20_mlp_act = candle_nn::Activation::NewGelu;
        let h_20_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.20.mlp.c_fc"))?;
        let h_20_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.20.mlp.c_proj"))?;
        let h_20_mlp_dropout = Dropout::new();
        let h_21_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.21.attn.c_attn"))?;
        let h_21_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.21.attn.c_proj"))?;
        let h_21_attn_resid_dropout = Dropout::new();
        let h_21_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_1"))?;
        let h_21_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.21.ln_2"))?;
        let h_21_mlp_act = candle_nn::Activation::NewGelu;
        let h_21_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.21.mlp.c_fc"))?;
        let h_21_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.21.mlp.c_proj"))?;
        let h_21_mlp_dropout = Dropout::new();
        let h_22_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.22.attn.c_attn"))?;
        let h_22_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.22.attn.c_proj"))?;
        let h_22_attn_resid_dropout = Dropout::new();
        let h_22_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_1"))?;
        let h_22_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.22.ln_2"))?;
        let h_22_mlp_act = candle_nn::Activation::NewGelu;
        let h_22_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.22.mlp.c_fc"))?;
        let h_22_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.22.mlp.c_proj"))?;
        let h_22_mlp_dropout = Dropout::new();
        let h_23_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.23.attn.c_attn"))?;
        let h_23_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.23.attn.c_proj"))?;
        let h_23_attn_resid_dropout = Dropout::new();
        let h_23_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_1"))?;
        let h_23_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.23.ln_2"))?;
        let h_23_mlp_act = candle_nn::Activation::NewGelu;
        let h_23_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.23.mlp.c_fc"))?;
        let h_23_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.23.mlp.c_proj"))?;
        let h_23_mlp_dropout = Dropout::new();
        let h_3_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.3.attn.c_attn"))?;
        let h_3_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.3.attn.c_proj"))?;
        let h_3_attn_resid_dropout = Dropout::new();
        let h_3_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_1"))?;
        let h_3_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.3.ln_2"))?;
        let h_3_mlp_act = candle_nn::Activation::NewGelu;
        let h_3_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.3.mlp.c_fc"))?;
        let h_3_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.3.mlp.c_proj"))?;
        let h_3_mlp_dropout = Dropout::new();
        let h_4_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.4.attn.c_attn"))?;
        let h_4_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.4.attn.c_proj"))?;
        let h_4_attn_resid_dropout = Dropout::new();
        let h_4_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_1"))?;
        let h_4_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.4.ln_2"))?;
        let h_4_mlp_act = candle_nn::Activation::NewGelu;
        let h_4_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.4.mlp.c_fc"))?;
        let h_4_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.4.mlp.c_proj"))?;
        let h_4_mlp_dropout = Dropout::new();
        let h_5_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.5.attn.c_attn"))?;
        let h_5_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.5.attn.c_proj"))?;
        let h_5_attn_resid_dropout = Dropout::new();
        let h_5_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_1"))?;
        let h_5_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.5.ln_2"))?;
        let h_5_mlp_act = candle_nn::Activation::NewGelu;
        let h_5_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.5.mlp.c_fc"))?;
        let h_5_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.5.mlp.c_proj"))?;
        let h_5_mlp_dropout = Dropout::new();
        let h_6_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.6.attn.c_attn"))?;
        let h_6_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.6.attn.c_proj"))?;
        let h_6_attn_resid_dropout = Dropout::new();
        let h_6_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_1"))?;
        let h_6_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.6.ln_2"))?;
        let h_6_mlp_act = candle_nn::Activation::NewGelu;
        let h_6_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.6.mlp.c_fc"))?;
        let h_6_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.6.mlp.c_proj"))?;
        let h_6_mlp_dropout = Dropout::new();
        let h_7_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.7.attn.c_attn"))?;
        let h_7_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.7.attn.c_proj"))?;
        let h_7_attn_resid_dropout = Dropout::new();
        let h_7_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_1"))?;
        let h_7_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.7.ln_2"))?;
        let h_7_mlp_act = candle_nn::Activation::NewGelu;
        let h_7_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.7.mlp.c_fc"))?;
        let h_7_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.7.mlp.c_proj"))?;
        let h_7_mlp_dropout = Dropout::new();
        let h_8_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.8.attn.c_attn"))?;
        let h_8_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.8.attn.c_proj"))?;
        let h_8_attn_resid_dropout = Dropout::new();
        let h_8_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_1"))?;
        let h_8_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.8.ln_2"))?;
        let h_8_mlp_act = candle_nn::Activation::NewGelu;
        let h_8_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.8.mlp.c_fc"))?;
        let h_8_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.8.mlp.c_proj"))?;
        let h_8_mlp_dropout = Dropout::new();
        let h_9_attn_c_attn = candle_nn::linear(config.hidden_dim, 3072, vb.pp("h.9.attn.c_attn"))?;
        let h_9_attn_c_proj = candle_nn::linear(config.hidden_dim, config.hidden_dim, vb.pp("h.9.attn.c_proj"))?;
        let h_9_attn_resid_dropout = Dropout::new();
        let h_9_ln_1 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_1"))?;
        let h_9_ln_2 = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("h.9.ln_2"))?;
        let h_9_mlp_act = candle_nn::Activation::NewGelu;
        let h_9_mlp_c_fc = candle_nn::linear(config.hidden_dim, 4096, vb.pp("h.9.mlp.c_fc"))?;
        let h_9_mlp_c_proj = candle_nn::linear(4096, config.hidden_dim, vb.pp("h.9.mlp.c_proj"))?;
        let h_9_mlp_dropout = Dropout::new();
        let ln_f = candle_nn::layer_norm(1024, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("ln_f"))?;
        let wpe = candle_nn::embedding(config.context_length, config.hidden_dim, vb.pp("wpe"))?;
        Ok(Self { drop, h_0_attn_c_attn, h_0_attn_c_proj, h_0_attn_resid_dropout, h_0_ln_1, h_0_ln_2, h_0_mlp_act, h_0_mlp_c_fc, h_0_mlp_c_proj, h_0_mlp_dropout, h_1_attn_c_attn, h_1_attn_c_proj, h_1_attn_resid_dropout, h_1_ln_1, h_1_ln_2, h_1_mlp_act, h_1_mlp_c_fc, h_1_mlp_c_proj, h_1_mlp_dropout, h_10_attn_c_attn, h_10_attn_c_proj, h_10_attn_resid_dropout, h_10_ln_1, h_10_ln_2, h_10_mlp_act, h_10_mlp_c_fc, h_10_mlp_c_proj, h_10_mlp_dropout, h_11_attn_c_attn, h_11_attn_c_proj, h_11_attn_resid_dropout, h_11_ln_1, h_11_ln_2, h_11_mlp_act, h_11_mlp_c_fc, h_11_mlp_c_proj, h_11_mlp_dropout, h_12_attn_c_attn, h_12_attn_c_proj, h_12_attn_resid_dropout, h_12_ln_1, h_12_ln_2, h_12_mlp_act, h_12_mlp_c_fc, h_12_mlp_c_proj, h_12_mlp_dropout, h_13_attn_c_attn, h_13_attn_c_proj, h_13_attn_resid_dropout, h_13_ln_1, h_13_ln_2, h_13_mlp_act, h_13_mlp_c_fc, h_13_mlp_c_proj, h_13_mlp_dropout, h_14_attn_c_attn, h_14_attn_c_proj, h_14_attn_resid_dropout, h_14_ln_1, h_14_ln_2, h_14_mlp_act, h_14_mlp_c_fc, h_14_mlp_c_proj, h_14_mlp_dropout, h_15_attn_c_attn, h_15_attn_c_proj, h_15_attn_resid_dropout, h_15_ln_1, h_15_ln_2, h_15_mlp_act, h_15_mlp_c_fc, h_15_mlp_c_proj, h_15_mlp_dropout, h_16_attn_c_attn, h_16_attn_c_proj, h_16_attn_resid_dropout, h_16_ln_1, h_16_ln_2, h_16_mlp_act, h_16_mlp_c_fc, h_16_mlp_c_proj, h_16_mlp_dropout, h_17_attn_c_attn, h_17_attn_c_proj, h_17_attn_resid_dropout, h_17_ln_1, h_17_ln_2, h_17_mlp_act, h_17_mlp_c_fc, h_17_mlp_c_proj, h_17_mlp_dropout, h_18_attn_c_attn, h_18_attn_c_proj, h_18_attn_resid_dropout, h_18_ln_1, h_18_ln_2, h_18_mlp_act, h_18_mlp_c_fc, h_18_mlp_c_proj, h_18_mlp_dropout, h_19_attn_c_attn, h_19_attn_c_proj, h_19_attn_resid_dropout, h_19_ln_1, h_19_ln_2, h_19_mlp_act, h_19_mlp_c_fc, h_19_mlp_c_proj, h_19_mlp_dropout, h_2_attn_c_attn, h_2_attn_c_proj, h_2_attn_resid_dropout, h_2_ln_1, h_2_ln_2, h_2_mlp_act, h_2_mlp_c_fc, h_2_mlp_c_proj, h_2_mlp_dropout, h_20_attn_c_attn, h_20_attn_c_proj, h_20_attn_resid_dropout, h_20_ln_1, h_20_ln_2, h_20_mlp_act, h_20_mlp_c_fc, h_20_mlp_c_proj, h_20_mlp_dropout, h_21_attn_c_attn, h_21_attn_c_proj, h_21_attn_resid_dropout, h_21_ln_1, h_21_ln_2, h_21_mlp_act, h_21_mlp_c_fc, h_21_mlp_c_proj, h_21_mlp_dropout, h_22_attn_c_attn, h_22_attn_c_proj, h_22_attn_resid_dropout, h_22_ln_1, h_22_ln_2, h_22_mlp_act, h_22_mlp_c_fc, h_22_mlp_c_proj, h_22_mlp_dropout, h_23_attn_c_attn, h_23_attn_c_proj, h_23_attn_resid_dropout, h_23_ln_1, h_23_ln_2, h_23_mlp_act, h_23_mlp_c_fc, h_23_mlp_c_proj, h_23_mlp_dropout, h_3_attn_c_attn, h_3_attn_c_proj, h_3_attn_resid_dropout, h_3_ln_1, h_3_ln_2, h_3_mlp_act, h_3_mlp_c_fc, h_3_mlp_c_proj, h_3_mlp_dropout, h_4_attn_c_attn, h_4_attn_c_proj, h_4_attn_resid_dropout, h_4_ln_1, h_4_ln_2, h_4_mlp_act, h_4_mlp_c_fc, h_4_mlp_c_proj, h_4_mlp_dropout, h_5_attn_c_attn, h_5_attn_c_proj, h_5_attn_resid_dropout, h_5_ln_1, h_5_ln_2, h_5_mlp_act, h_5_mlp_c_fc, h_5_mlp_c_proj, h_5_mlp_dropout, h_6_attn_c_attn, h_6_attn_c_proj, h_6_attn_resid_dropout, h_6_ln_1, h_6_ln_2, h_6_mlp_act, h_6_mlp_c_fc, h_6_mlp_c_proj, h_6_mlp_dropout, h_7_attn_c_attn, h_7_attn_c_proj, h_7_attn_resid_dropout, h_7_ln_1, h_7_ln_2, h_7_mlp_act, h_7_mlp_c_fc, h_7_mlp_c_proj, h_7_mlp_dropout, h_8_attn_c_attn, h_8_attn_c_proj, h_8_attn_resid_dropout, h_8_ln_1, h_8_ln_2, h_8_mlp_act, h_8_mlp_c_fc, h_8_mlp_c_proj, h_8_mlp_dropout, h_9_attn_c_attn, h_9_attn_c_proj, h_9_attn_resid_dropout, h_9_ln_1, h_9_ln_2, h_9_mlp_act, h_9_mlp_c_fc, h_9_mlp_c_proj, h_9_mlp_dropout, ln_f, wpe, checker })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: drop
        x = self.drop.forward(&x)?;
        py_check!(self.checker, "drop", &x);

        // Layer: h.0.attn.c_attn
        x = self.h_0_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_attn", &x);

        // Layer: h.0.attn.c_proj
        x = self.h_0_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.attn.c_proj", &x);

        // Layer: h.0.attn.resid_dropout
        x = self.h_0_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.attn.resid_dropout", &x);

        // Layer: h.0.ln_1
        x = self.h_0_ln_1.forward(&x)?;
        py_check!(self.checker, "h.0.ln_1", &x);

        // Layer: h.0.ln_2
        x = self.h_0_ln_2.forward(&x)?;
        py_check!(self.checker, "h.0.ln_2", &x);

        // Layer: h.0.mlp.act
        x = self.h_0_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.act", &x);

        // Layer: h.0.mlp.c_fc
        x = self.h_0_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_fc", &x);

        // Layer: h.0.mlp.c_proj
        x = self.h_0_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.c_proj", &x);

        // Layer: h.0.mlp.dropout
        x = self.h_0_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.0.mlp.dropout", &x);

        // Layer: h.1.attn.c_attn
        x = self.h_1_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_attn", &x);

        // Layer: h.1.attn.c_proj
        x = self.h_1_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.attn.c_proj", &x);

        // Layer: h.1.attn.resid_dropout
        x = self.h_1_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.attn.resid_dropout", &x);

        // Layer: h.1.ln_1
        x = self.h_1_ln_1.forward(&x)?;
        py_check!(self.checker, "h.1.ln_1", &x);

        // Layer: h.1.ln_2
        x = self.h_1_ln_2.forward(&x)?;
        py_check!(self.checker, "h.1.ln_2", &x);

        // Layer: h.1.mlp.act
        x = self.h_1_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.act", &x);

        // Layer: h.1.mlp.c_fc
        x = self.h_1_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_fc", &x);

        // Layer: h.1.mlp.c_proj
        x = self.h_1_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.c_proj", &x);

        // Layer: h.1.mlp.dropout
        x = self.h_1_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.1.mlp.dropout", &x);

        // Layer: h.10.attn.c_attn
        x = self.h_10_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_attn", &x);

        // Layer: h.10.attn.c_proj
        x = self.h_10_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.attn.c_proj", &x);

        // Layer: h.10.attn.resid_dropout
        x = self.h_10_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.attn.resid_dropout", &x);

        // Layer: h.10.ln_1
        x = self.h_10_ln_1.forward(&x)?;
        py_check!(self.checker, "h.10.ln_1", &x);

        // Layer: h.10.ln_2
        x = self.h_10_ln_2.forward(&x)?;
        py_check!(self.checker, "h.10.ln_2", &x);

        // Layer: h.10.mlp.act
        x = self.h_10_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.act", &x);

        // Layer: h.10.mlp.c_fc
        x = self.h_10_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_fc", &x);

        // Layer: h.10.mlp.c_proj
        x = self.h_10_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.c_proj", &x);

        // Layer: h.10.mlp.dropout
        x = self.h_10_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.10.mlp.dropout", &x);

        // Layer: h.11.attn.c_attn
        x = self.h_11_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_attn", &x);

        // Layer: h.11.attn.c_proj
        x = self.h_11_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.attn.c_proj", &x);

        // Layer: h.11.attn.resid_dropout
        x = self.h_11_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.attn.resid_dropout", &x);

        // Layer: h.11.ln_1
        x = self.h_11_ln_1.forward(&x)?;
        py_check!(self.checker, "h.11.ln_1", &x);

        // Layer: h.11.ln_2
        x = self.h_11_ln_2.forward(&x)?;
        py_check!(self.checker, "h.11.ln_2", &x);

        // Layer: h.11.mlp.act
        x = self.h_11_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.act", &x);

        // Layer: h.11.mlp.c_fc
        x = self.h_11_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_fc", &x);

        // Layer: h.11.mlp.c_proj
        x = self.h_11_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.c_proj", &x);

        // Layer: h.11.mlp.dropout
        x = self.h_11_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.11.mlp.dropout", &x);

        // Layer: h.12.attn.c_attn
        x = self.h_12_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_attn", &x);

        // Layer: h.12.attn.c_proj
        x = self.h_12_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.attn.c_proj", &x);

        // Layer: h.12.attn.resid_dropout
        x = self.h_12_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.attn.resid_dropout", &x);

        // Layer: h.12.ln_1
        x = self.h_12_ln_1.forward(&x)?;
        py_check!(self.checker, "h.12.ln_1", &x);

        // Layer: h.12.ln_2
        x = self.h_12_ln_2.forward(&x)?;
        py_check!(self.checker, "h.12.ln_2", &x);

        // Layer: h.12.mlp.act
        x = self.h_12_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.act", &x);

        // Layer: h.12.mlp.c_fc
        x = self.h_12_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_fc", &x);

        // Layer: h.12.mlp.c_proj
        x = self.h_12_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.c_proj", &x);

        // Layer: h.12.mlp.dropout
        x = self.h_12_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.12.mlp.dropout", &x);

        // Layer: h.13.attn.c_attn
        x = self.h_13_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_attn", &x);

        // Layer: h.13.attn.c_proj
        x = self.h_13_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.attn.c_proj", &x);

        // Layer: h.13.attn.resid_dropout
        x = self.h_13_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.attn.resid_dropout", &x);

        // Layer: h.13.ln_1
        x = self.h_13_ln_1.forward(&x)?;
        py_check!(self.checker, "h.13.ln_1", &x);

        // Layer: h.13.ln_2
        x = self.h_13_ln_2.forward(&x)?;
        py_check!(self.checker, "h.13.ln_2", &x);

        // Layer: h.13.mlp.act
        x = self.h_13_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.act", &x);

        // Layer: h.13.mlp.c_fc
        x = self.h_13_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_fc", &x);

        // Layer: h.13.mlp.c_proj
        x = self.h_13_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.c_proj", &x);

        // Layer: h.13.mlp.dropout
        x = self.h_13_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.13.mlp.dropout", &x);

        // Layer: h.14.attn.c_attn
        x = self.h_14_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_attn", &x);

        // Layer: h.14.attn.c_proj
        x = self.h_14_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.attn.c_proj", &x);

        // Layer: h.14.attn.resid_dropout
        x = self.h_14_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.attn.resid_dropout", &x);

        // Layer: h.14.ln_1
        x = self.h_14_ln_1.forward(&x)?;
        py_check!(self.checker, "h.14.ln_1", &x);

        // Layer: h.14.ln_2
        x = self.h_14_ln_2.forward(&x)?;
        py_check!(self.checker, "h.14.ln_2", &x);

        // Layer: h.14.mlp.act
        x = self.h_14_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.act", &x);

        // Layer: h.14.mlp.c_fc
        x = self.h_14_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_fc", &x);

        // Layer: h.14.mlp.c_proj
        x = self.h_14_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.c_proj", &x);

        // Layer: h.14.mlp.dropout
        x = self.h_14_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.14.mlp.dropout", &x);

        // Layer: h.15.attn.c_attn
        x = self.h_15_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_attn", &x);

        // Layer: h.15.attn.c_proj
        x = self.h_15_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.attn.c_proj", &x);

        // Layer: h.15.attn.resid_dropout
        x = self.h_15_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.attn.resid_dropout", &x);

        // Layer: h.15.ln_1
        x = self.h_15_ln_1.forward(&x)?;
        py_check!(self.checker, "h.15.ln_1", &x);

        // Layer: h.15.ln_2
        x = self.h_15_ln_2.forward(&x)?;
        py_check!(self.checker, "h.15.ln_2", &x);

        // Layer: h.15.mlp.act
        x = self.h_15_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.act", &x);

        // Layer: h.15.mlp.c_fc
        x = self.h_15_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_fc", &x);

        // Layer: h.15.mlp.c_proj
        x = self.h_15_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.c_proj", &x);

        // Layer: h.15.mlp.dropout
        x = self.h_15_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.15.mlp.dropout", &x);

        // Layer: h.16.attn.c_attn
        x = self.h_16_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_attn", &x);

        // Layer: h.16.attn.c_proj
        x = self.h_16_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.attn.c_proj", &x);

        // Layer: h.16.attn.resid_dropout
        x = self.h_16_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.attn.resid_dropout", &x);

        // Layer: h.16.ln_1
        x = self.h_16_ln_1.forward(&x)?;
        py_check!(self.checker, "h.16.ln_1", &x);

        // Layer: h.16.ln_2
        x = self.h_16_ln_2.forward(&x)?;
        py_check!(self.checker, "h.16.ln_2", &x);

        // Layer: h.16.mlp.act
        x = self.h_16_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.act", &x);

        // Layer: h.16.mlp.c_fc
        x = self.h_16_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_fc", &x);

        // Layer: h.16.mlp.c_proj
        x = self.h_16_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.c_proj", &x);

        // Layer: h.16.mlp.dropout
        x = self.h_16_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.16.mlp.dropout", &x);

        // Layer: h.17.attn.c_attn
        x = self.h_17_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_attn", &x);

        // Layer: h.17.attn.c_proj
        x = self.h_17_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.attn.c_proj", &x);

        // Layer: h.17.attn.resid_dropout
        x = self.h_17_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.attn.resid_dropout", &x);

        // Layer: h.17.ln_1
        x = self.h_17_ln_1.forward(&x)?;
        py_check!(self.checker, "h.17.ln_1", &x);

        // Layer: h.17.ln_2
        x = self.h_17_ln_2.forward(&x)?;
        py_check!(self.checker, "h.17.ln_2", &x);

        // Layer: h.17.mlp.act
        x = self.h_17_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.act", &x);

        // Layer: h.17.mlp.c_fc
        x = self.h_17_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_fc", &x);

        // Layer: h.17.mlp.c_proj
        x = self.h_17_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.c_proj", &x);

        // Layer: h.17.mlp.dropout
        x = self.h_17_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.17.mlp.dropout", &x);

        // Layer: h.18.attn.c_attn
        x = self.h_18_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_attn", &x);

        // Layer: h.18.attn.c_proj
        x = self.h_18_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.attn.c_proj", &x);

        // Layer: h.18.attn.resid_dropout
        x = self.h_18_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.attn.resid_dropout", &x);

        // Layer: h.18.ln_1
        x = self.h_18_ln_1.forward(&x)?;
        py_check!(self.checker, "h.18.ln_1", &x);

        // Layer: h.18.ln_2
        x = self.h_18_ln_2.forward(&x)?;
        py_check!(self.checker, "h.18.ln_2", &x);

        // Layer: h.18.mlp.act
        x = self.h_18_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.act", &x);

        // Layer: h.18.mlp.c_fc
        x = self.h_18_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_fc", &x);

        // Layer: h.18.mlp.c_proj
        x = self.h_18_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.c_proj", &x);

        // Layer: h.18.mlp.dropout
        x = self.h_18_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.18.mlp.dropout", &x);

        // Layer: h.19.attn.c_attn
        x = self.h_19_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_attn", &x);

        // Layer: h.19.attn.c_proj
        x = self.h_19_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.attn.c_proj", &x);

        // Layer: h.19.attn.resid_dropout
        x = self.h_19_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.attn.resid_dropout", &x);

        // Layer: h.19.ln_1
        x = self.h_19_ln_1.forward(&x)?;
        py_check!(self.checker, "h.19.ln_1", &x);

        // Layer: h.19.ln_2
        x = self.h_19_ln_2.forward(&x)?;
        py_check!(self.checker, "h.19.ln_2", &x);

        // Layer: h.19.mlp.act
        x = self.h_19_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.act", &x);

        // Layer: h.19.mlp.c_fc
        x = self.h_19_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_fc", &x);

        // Layer: h.19.mlp.c_proj
        x = self.h_19_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.c_proj", &x);

        // Layer: h.19.mlp.dropout
        x = self.h_19_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.19.mlp.dropout", &x);

        // Layer: h.2.attn.c_attn
        x = self.h_2_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_attn", &x);

        // Layer: h.2.attn.c_proj
        x = self.h_2_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.attn.c_proj", &x);

        // Layer: h.2.attn.resid_dropout
        x = self.h_2_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.attn.resid_dropout", &x);

        // Layer: h.2.ln_1
        x = self.h_2_ln_1.forward(&x)?;
        py_check!(self.checker, "h.2.ln_1", &x);

        // Layer: h.2.ln_2
        x = self.h_2_ln_2.forward(&x)?;
        py_check!(self.checker, "h.2.ln_2", &x);

        // Layer: h.2.mlp.act
        x = self.h_2_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.act", &x);

        // Layer: h.2.mlp.c_fc
        x = self.h_2_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_fc", &x);

        // Layer: h.2.mlp.c_proj
        x = self.h_2_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.c_proj", &x);

        // Layer: h.2.mlp.dropout
        x = self.h_2_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.2.mlp.dropout", &x);

        // Layer: h.20.attn.c_attn
        x = self.h_20_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_attn", &x);

        // Layer: h.20.attn.c_proj
        x = self.h_20_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.attn.c_proj", &x);

        // Layer: h.20.attn.resid_dropout
        x = self.h_20_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.attn.resid_dropout", &x);

        // Layer: h.20.ln_1
        x = self.h_20_ln_1.forward(&x)?;
        py_check!(self.checker, "h.20.ln_1", &x);

        // Layer: h.20.ln_2
        x = self.h_20_ln_2.forward(&x)?;
        py_check!(self.checker, "h.20.ln_2", &x);

        // Layer: h.20.mlp.act
        x = self.h_20_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.act", &x);

        // Layer: h.20.mlp.c_fc
        x = self.h_20_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_fc", &x);

        // Layer: h.20.mlp.c_proj
        x = self.h_20_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.c_proj", &x);

        // Layer: h.20.mlp.dropout
        x = self.h_20_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.20.mlp.dropout", &x);

        // Layer: h.21.attn.c_attn
        x = self.h_21_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_attn", &x);

        // Layer: h.21.attn.c_proj
        x = self.h_21_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.attn.c_proj", &x);

        // Layer: h.21.attn.resid_dropout
        x = self.h_21_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.attn.resid_dropout", &x);

        // Layer: h.21.ln_1
        x = self.h_21_ln_1.forward(&x)?;
        py_check!(self.checker, "h.21.ln_1", &x);

        // Layer: h.21.ln_2
        x = self.h_21_ln_2.forward(&x)?;
        py_check!(self.checker, "h.21.ln_2", &x);

        // Layer: h.21.mlp.act
        x = self.h_21_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.act", &x);

        // Layer: h.21.mlp.c_fc
        x = self.h_21_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_fc", &x);

        // Layer: h.21.mlp.c_proj
        x = self.h_21_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.c_proj", &x);

        // Layer: h.21.mlp.dropout
        x = self.h_21_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.21.mlp.dropout", &x);

        // Layer: h.22.attn.c_attn
        x = self.h_22_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_attn", &x);

        // Layer: h.22.attn.c_proj
        x = self.h_22_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.attn.c_proj", &x);

        // Layer: h.22.attn.resid_dropout
        x = self.h_22_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.attn.resid_dropout", &x);

        // Layer: h.22.ln_1
        x = self.h_22_ln_1.forward(&x)?;
        py_check!(self.checker, "h.22.ln_1", &x);

        // Layer: h.22.ln_2
        x = self.h_22_ln_2.forward(&x)?;
        py_check!(self.checker, "h.22.ln_2", &x);

        // Layer: h.22.mlp.act
        x = self.h_22_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.act", &x);

        // Layer: h.22.mlp.c_fc
        x = self.h_22_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_fc", &x);

        // Layer: h.22.mlp.c_proj
        x = self.h_22_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.c_proj", &x);

        // Layer: h.22.mlp.dropout
        x = self.h_22_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.22.mlp.dropout", &x);

        // Layer: h.23.attn.c_attn
        x = self.h_23_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_attn", &x);

        // Layer: h.23.attn.c_proj
        x = self.h_23_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.attn.c_proj", &x);

        // Layer: h.23.attn.resid_dropout
        x = self.h_23_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.attn.resid_dropout", &x);

        // Layer: h.23.ln_1
        x = self.h_23_ln_1.forward(&x)?;
        py_check!(self.checker, "h.23.ln_1", &x);

        // Layer: h.23.ln_2
        x = self.h_23_ln_2.forward(&x)?;
        py_check!(self.checker, "h.23.ln_2", &x);

        // Layer: h.23.mlp.act
        x = self.h_23_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.act", &x);

        // Layer: h.23.mlp.c_fc
        x = self.h_23_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_fc", &x);

        // Layer: h.23.mlp.c_proj
        x = self.h_23_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.c_proj", &x);

        // Layer: h.23.mlp.dropout
        x = self.h_23_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.23.mlp.dropout", &x);

        // Layer: h.3.attn.c_attn
        x = self.h_3_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_attn", &x);

        // Layer: h.3.attn.c_proj
        x = self.h_3_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.attn.c_proj", &x);

        // Layer: h.3.attn.resid_dropout
        x = self.h_3_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.attn.resid_dropout", &x);

        // Layer: h.3.ln_1
        x = self.h_3_ln_1.forward(&x)?;
        py_check!(self.checker, "h.3.ln_1", &x);

        // Layer: h.3.ln_2
        x = self.h_3_ln_2.forward(&x)?;
        py_check!(self.checker, "h.3.ln_2", &x);

        // Layer: h.3.mlp.act
        x = self.h_3_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.act", &x);

        // Layer: h.3.mlp.c_fc
        x = self.h_3_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_fc", &x);

        // Layer: h.3.mlp.c_proj
        x = self.h_3_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.c_proj", &x);

        // Layer: h.3.mlp.dropout
        x = self.h_3_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.3.mlp.dropout", &x);

        // Layer: h.4.attn.c_attn
        x = self.h_4_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_attn", &x);

        // Layer: h.4.attn.c_proj
        x = self.h_4_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.attn.c_proj", &x);

        // Layer: h.4.attn.resid_dropout
        x = self.h_4_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.attn.resid_dropout", &x);

        // Layer: h.4.ln_1
        x = self.h_4_ln_1.forward(&x)?;
        py_check!(self.checker, "h.4.ln_1", &x);

        // Layer: h.4.ln_2
        x = self.h_4_ln_2.forward(&x)?;
        py_check!(self.checker, "h.4.ln_2", &x);

        // Layer: h.4.mlp.act
        x = self.h_4_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.act", &x);

        // Layer: h.4.mlp.c_fc
        x = self.h_4_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_fc", &x);

        // Layer: h.4.mlp.c_proj
        x = self.h_4_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.c_proj", &x);

        // Layer: h.4.mlp.dropout
        x = self.h_4_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.4.mlp.dropout", &x);

        // Layer: h.5.attn.c_attn
        x = self.h_5_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_attn", &x);

        // Layer: h.5.attn.c_proj
        x = self.h_5_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.attn.c_proj", &x);

        // Layer: h.5.attn.resid_dropout
        x = self.h_5_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.attn.resid_dropout", &x);

        // Layer: h.5.ln_1
        x = self.h_5_ln_1.forward(&x)?;
        py_check!(self.checker, "h.5.ln_1", &x);

        // Layer: h.5.ln_2
        x = self.h_5_ln_2.forward(&x)?;
        py_check!(self.checker, "h.5.ln_2", &x);

        // Layer: h.5.mlp.act
        x = self.h_5_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.act", &x);

        // Layer: h.5.mlp.c_fc
        x = self.h_5_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_fc", &x);

        // Layer: h.5.mlp.c_proj
        x = self.h_5_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.c_proj", &x);

        // Layer: h.5.mlp.dropout
        x = self.h_5_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.5.mlp.dropout", &x);

        // Layer: h.6.attn.c_attn
        x = self.h_6_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_attn", &x);

        // Layer: h.6.attn.c_proj
        x = self.h_6_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.attn.c_proj", &x);

        // Layer: h.6.attn.resid_dropout
        x = self.h_6_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.attn.resid_dropout", &x);

        // Layer: h.6.ln_1
        x = self.h_6_ln_1.forward(&x)?;
        py_check!(self.checker, "h.6.ln_1", &x);

        // Layer: h.6.ln_2
        x = self.h_6_ln_2.forward(&x)?;
        py_check!(self.checker, "h.6.ln_2", &x);

        // Layer: h.6.mlp.act
        x = self.h_6_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.act", &x);

        // Layer: h.6.mlp.c_fc
        x = self.h_6_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_fc", &x);

        // Layer: h.6.mlp.c_proj
        x = self.h_6_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.c_proj", &x);

        // Layer: h.6.mlp.dropout
        x = self.h_6_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.6.mlp.dropout", &x);

        // Layer: h.7.attn.c_attn
        x = self.h_7_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_attn", &x);

        // Layer: h.7.attn.c_proj
        x = self.h_7_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.attn.c_proj", &x);

        // Layer: h.7.attn.resid_dropout
        x = self.h_7_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.attn.resid_dropout", &x);

        // Layer: h.7.ln_1
        x = self.h_7_ln_1.forward(&x)?;
        py_check!(self.checker, "h.7.ln_1", &x);

        // Layer: h.7.ln_2
        x = self.h_7_ln_2.forward(&x)?;
        py_check!(self.checker, "h.7.ln_2", &x);

        // Layer: h.7.mlp.act
        x = self.h_7_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.act", &x);

        // Layer: h.7.mlp.c_fc
        x = self.h_7_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_fc", &x);

        // Layer: h.7.mlp.c_proj
        x = self.h_7_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.c_proj", &x);

        // Layer: h.7.mlp.dropout
        x = self.h_7_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.7.mlp.dropout", &x);

        // Layer: h.8.attn.c_attn
        x = self.h_8_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_attn", &x);

        // Layer: h.8.attn.c_proj
        x = self.h_8_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.attn.c_proj", &x);

        // Layer: h.8.attn.resid_dropout
        x = self.h_8_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.attn.resid_dropout", &x);

        // Layer: h.8.ln_1
        x = self.h_8_ln_1.forward(&x)?;
        py_check!(self.checker, "h.8.ln_1", &x);

        // Layer: h.8.ln_2
        x = self.h_8_ln_2.forward(&x)?;
        py_check!(self.checker, "h.8.ln_2", &x);

        // Layer: h.8.mlp.act
        x = self.h_8_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.act", &x);

        // Layer: h.8.mlp.c_fc
        x = self.h_8_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_fc", &x);

        // Layer: h.8.mlp.c_proj
        x = self.h_8_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.c_proj", &x);

        // Layer: h.8.mlp.dropout
        x = self.h_8_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.8.mlp.dropout", &x);

        // Layer: h.9.attn.c_attn
        x = self.h_9_attn_c_attn.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_attn", &x);

        // Layer: h.9.attn.c_proj
        x = self.h_9_attn_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.attn.c_proj", &x);

        // Layer: h.9.attn.resid_dropout
        x = self.h_9_attn_resid_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.attn.resid_dropout", &x);

        // Layer: h.9.ln_1
        x = self.h_9_ln_1.forward(&x)?;
        py_check!(self.checker, "h.9.ln_1", &x);

        // Layer: h.9.ln_2
        x = self.h_9_ln_2.forward(&x)?;
        py_check!(self.checker, "h.9.ln_2", &x);

        // Layer: h.9.mlp.act
        x = self.h_9_mlp_act.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.act", &x);

        // Layer: h.9.mlp.c_fc
        x = self.h_9_mlp_c_fc.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_fc", &x);

        // Layer: h.9.mlp.c_proj
        x = self.h_9_mlp_c_proj.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.c_proj", &x);

        // Layer: h.9.mlp.dropout
        x = self.h_9_mlp_dropout.forward(&x)?;
        py_check!(self.checker, "h.9.mlp.dropout", &x);

        // Layer: ln_f
        x = self.ln_f.forward(&x)?;
        py_check!(self.checker, "ln_f", &x);

        // Layer: wpe
        x = self.wpe.forward(&x)?;
        py_check!(self.checker, "wpe", &x);

        Ok(x)
    }
}
</file>

<file path="dx_simulation/src/voice_encoder.rs">
use candle_core::{Result, Tensor};
use candle_nn::{Module, VarBuilder};
use pycandle_core::{PyChecker, py_check, layers::*};

pub struct Config {}
pub struct VoiceEncoder {
    pub lstm: LSTM,
    pub proj: candle_nn::Linear,
    pub checker: Option<PyChecker>,
}

impl VoiceEncoder {
    #[allow(unused_variables)]
    pub fn load(config: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let lstm = LSTM::load(vb.pp("lstm"), 40, 256, 3)?;
        let proj = {
            let w = vb.pp("proj").get((256, 256), "weight")?.t()?;
            let b = Some(vb.pp("proj").get(256, "bias")?);
            candle_nn::Linear::new(w, b)
        };
        Ok(Self {
            lstm,
            proj,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: lstm
        x = self.lstm.forward(&x)?.0;
        py_check!(self.checker, "lstm", &x);

        // Layer: proj
        x = self.proj.forward(&x)?;
        py_check!(self.checker, "proj", &x);

        // L2 normalize
        let norm = x.sqr()?.sum_keepdim(1)?.sqrt()?;
        x.broadcast_div(&norm)
    }
}
</file>

<file path="s3gen_keys.txt">
flow.decoder.estimator.down_blocks.0.0.block1.block.0.bias
flow.decoder.estimator.down_blocks.0.0.block1.block.0.weight
flow.decoder.estimator.down_blocks.0.0.block1.block.2.bias
flow.decoder.estimator.down_blocks.0.0.block1.block.2.weight
flow.decoder.estimator.down_blocks.0.0.block2.block.0.bias
flow.decoder.estimator.down_blocks.0.0.block2.block.0.weight
flow.decoder.estimator.down_blocks.0.0.block2.block.2.bias
flow.decoder.estimator.down_blocks.0.0.block2.block.2.weight
flow.decoder.estimator.down_blocks.0.0.mlp.1.bias
flow.decoder.estimator.down_blocks.0.0.mlp.1.weight
flow.decoder.estimator.down_blocks.0.0.res_conv.bias
flow.decoder.estimator.down_blocks.0.0.res_conv.weight
flow.decoder.estimator.down_blocks.0.1.0.attn1.to_k.weight
flow.decoder.estimator.down_blocks.0.1.0.attn1.to_out.0.bias
flow.decoder.estimator.down_blocks.0.1.0.attn1.to_out.0.weight
flow.decoder.estimator.down_blocks.0.1.0.attn1.to_q.weight
flow.decoder.estimator.down_blocks.0.1.0.attn1.to_v.weight
flow.decoder.estimator.down_blocks.0.1.0.ff.net.0.proj.bias
flow.decoder.estimator.down_blocks.0.1.0.ff.net.0.proj.weight
flow.decoder.estimator.down_blocks.0.1.0.ff.net.2.bias
flow.decoder.estimator.down_blocks.0.1.0.ff.net.2.weight
flow.decoder.estimator.down_blocks.0.1.0.norm1.bias
flow.decoder.estimator.down_blocks.0.1.0.norm1.weight
flow.decoder.estimator.down_blocks.0.1.0.norm3.bias
flow.decoder.estimator.down_blocks.0.1.0.norm3.weight
flow.decoder.estimator.down_blocks.0.1.1.attn1.to_k.weight
flow.decoder.estimator.down_blocks.0.1.1.attn1.to_out.0.bias
flow.decoder.estimator.down_blocks.0.1.1.attn1.to_out.0.weight
flow.decoder.estimator.down_blocks.0.1.1.attn1.to_q.weight
flow.decoder.estimator.down_blocks.0.1.1.attn1.to_v.weight
flow.decoder.estimator.down_blocks.0.1.1.ff.net.0.proj.bias
flow.decoder.estimator.down_blocks.0.1.1.ff.net.0.proj.weight
flow.decoder.estimator.down_blocks.0.1.1.ff.net.2.bias
flow.decoder.estimator.down_blocks.0.1.1.ff.net.2.weight
flow.decoder.estimator.down_blocks.0.1.1.norm1.bias
flow.decoder.estimator.down_blocks.0.1.1.norm1.weight
flow.decoder.estimator.down_blocks.0.1.1.norm3.bias
flow.decoder.estimator.down_blocks.0.1.1.norm3.weight
flow.decoder.estimator.down_blocks.0.1.2.attn1.to_k.weight
flow.decoder.estimator.down_blocks.0.1.2.attn1.to_out.0.bias
flow.decoder.estimator.down_blocks.0.1.2.attn1.to_out.0.weight
flow.decoder.estimator.down_blocks.0.1.2.attn1.to_q.weight
flow.decoder.estimator.down_blocks.0.1.2.attn1.to_v.weight
flow.decoder.estimator.down_blocks.0.1.2.ff.net.0.proj.bias
flow.decoder.estimator.down_blocks.0.1.2.ff.net.0.proj.weight
flow.decoder.estimator.down_blocks.0.1.2.ff.net.2.bias
flow.decoder.estimator.down_blocks.0.1.2.ff.net.2.weight
flow.decoder.estimator.down_blocks.0.1.2.norm1.bias
flow.decoder.estimator.down_blocks.0.1.2.norm1.weight
flow.decoder.estimator.down_blocks.0.1.2.norm3.bias
flow.decoder.estimator.down_blocks.0.1.2.norm3.weight
flow.decoder.estimator.down_blocks.0.1.3.attn1.to_k.weight
flow.decoder.estimator.down_blocks.0.1.3.attn1.to_out.0.bias
flow.decoder.estimator.down_blocks.0.1.3.attn1.to_out.0.weight
flow.decoder.estimator.down_blocks.0.1.3.attn1.to_q.weight
flow.decoder.estimator.down_blocks.0.1.3.attn1.to_v.weight
flow.decoder.estimator.down_blocks.0.1.3.ff.net.0.proj.bias
flow.decoder.estimator.down_blocks.0.1.3.ff.net.0.proj.weight
flow.decoder.estimator.down_blocks.0.1.3.ff.net.2.bias
flow.decoder.estimator.down_blocks.0.1.3.ff.net.2.weight
flow.decoder.estimator.down_blocks.0.1.3.norm1.bias
flow.decoder.estimator.down_blocks.0.1.3.norm1.weight
flow.decoder.estimator.down_blocks.0.1.3.norm3.bias
flow.decoder.estimator.down_blocks.0.1.3.norm3.weight
flow.decoder.estimator.down_blocks.0.2.bias
flow.decoder.estimator.down_blocks.0.2.weight
flow.decoder.estimator.final_block.block.0.bias
flow.decoder.estimator.final_block.block.0.weight
flow.decoder.estimator.final_block.block.2.bias
flow.decoder.estimator.final_block.block.2.weight
flow.decoder.estimator.final_proj.bias
flow.decoder.estimator.final_proj.weight
flow.decoder.estimator.mid_blocks.0.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.0.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.0.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.0.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.0.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.0.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.0.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.0.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.0.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.0.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.0.0.res_conv.bias
flow.decoder.estimator.mid_blocks.0.0.res_conv.weight
flow.decoder.estimator.mid_blocks.0.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.0.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.0.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.0.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.0.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.0.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.0.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.0.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.0.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.0.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.0.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.0.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.0.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.0.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.0.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.0.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.0.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.0.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.0.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.0.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.0.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.0.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.0.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.0.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.0.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.0.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.0.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.0.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.0.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.0.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.0.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.0.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.0.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.0.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.0.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.0.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.0.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.0.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.0.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.0.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.0.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.0.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.0.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.0.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.1.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.1.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.1.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.1.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.1.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.1.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.1.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.1.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.1.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.1.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.1.0.res_conv.bias
flow.decoder.estimator.mid_blocks.1.0.res_conv.weight
flow.decoder.estimator.mid_blocks.1.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.1.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.1.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.1.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.1.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.1.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.1.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.1.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.1.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.1.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.1.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.1.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.1.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.1.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.1.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.1.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.1.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.1.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.1.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.1.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.1.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.1.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.1.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.1.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.1.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.1.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.1.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.1.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.1.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.1.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.1.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.1.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.1.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.1.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.1.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.1.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.1.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.1.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.1.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.1.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.1.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.1.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.1.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.1.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.10.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.10.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.10.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.10.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.10.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.10.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.10.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.10.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.10.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.10.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.10.0.res_conv.bias
flow.decoder.estimator.mid_blocks.10.0.res_conv.weight
flow.decoder.estimator.mid_blocks.10.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.10.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.10.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.10.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.10.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.10.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.10.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.10.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.10.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.10.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.10.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.10.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.10.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.10.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.10.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.10.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.10.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.10.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.10.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.10.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.10.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.10.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.10.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.10.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.10.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.10.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.10.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.10.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.10.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.10.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.10.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.10.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.10.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.10.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.10.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.10.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.10.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.10.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.10.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.10.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.10.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.10.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.10.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.10.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.11.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.11.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.11.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.11.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.11.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.11.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.11.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.11.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.11.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.11.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.11.0.res_conv.bias
flow.decoder.estimator.mid_blocks.11.0.res_conv.weight
flow.decoder.estimator.mid_blocks.11.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.11.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.11.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.11.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.11.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.11.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.11.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.11.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.11.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.11.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.11.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.11.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.11.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.11.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.11.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.11.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.11.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.11.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.11.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.11.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.11.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.11.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.11.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.11.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.11.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.11.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.11.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.11.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.11.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.11.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.11.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.11.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.11.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.11.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.11.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.11.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.11.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.11.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.11.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.11.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.11.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.11.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.11.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.11.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.2.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.2.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.2.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.2.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.2.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.2.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.2.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.2.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.2.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.2.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.2.0.res_conv.bias
flow.decoder.estimator.mid_blocks.2.0.res_conv.weight
flow.decoder.estimator.mid_blocks.2.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.2.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.2.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.2.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.2.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.2.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.2.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.2.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.2.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.2.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.2.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.2.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.2.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.2.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.2.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.2.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.2.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.2.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.2.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.2.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.2.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.2.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.2.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.2.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.2.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.2.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.2.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.2.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.2.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.2.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.2.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.2.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.2.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.2.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.2.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.2.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.2.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.2.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.2.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.2.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.2.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.2.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.2.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.2.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.3.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.3.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.3.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.3.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.3.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.3.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.3.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.3.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.3.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.3.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.3.0.res_conv.bias
flow.decoder.estimator.mid_blocks.3.0.res_conv.weight
flow.decoder.estimator.mid_blocks.3.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.3.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.3.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.3.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.3.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.3.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.3.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.3.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.3.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.3.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.3.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.3.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.3.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.3.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.3.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.3.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.3.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.3.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.3.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.3.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.3.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.3.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.3.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.3.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.3.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.3.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.3.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.3.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.3.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.3.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.3.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.3.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.3.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.3.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.3.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.3.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.3.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.3.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.3.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.3.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.3.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.3.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.3.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.3.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.4.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.4.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.4.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.4.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.4.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.4.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.4.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.4.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.4.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.4.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.4.0.res_conv.bias
flow.decoder.estimator.mid_blocks.4.0.res_conv.weight
flow.decoder.estimator.mid_blocks.4.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.4.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.4.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.4.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.4.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.4.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.4.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.4.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.4.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.4.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.4.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.4.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.4.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.4.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.4.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.4.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.4.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.4.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.4.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.4.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.4.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.4.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.4.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.4.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.4.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.4.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.4.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.4.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.4.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.4.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.4.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.4.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.4.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.4.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.4.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.4.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.4.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.4.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.4.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.4.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.4.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.4.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.4.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.4.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.5.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.5.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.5.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.5.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.5.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.5.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.5.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.5.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.5.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.5.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.5.0.res_conv.bias
flow.decoder.estimator.mid_blocks.5.0.res_conv.weight
flow.decoder.estimator.mid_blocks.5.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.5.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.5.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.5.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.5.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.5.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.5.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.5.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.5.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.5.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.5.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.5.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.5.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.5.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.5.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.5.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.5.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.5.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.5.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.5.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.5.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.5.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.5.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.5.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.5.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.5.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.5.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.5.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.5.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.5.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.5.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.5.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.5.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.5.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.5.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.5.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.5.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.5.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.5.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.5.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.5.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.5.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.5.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.5.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.6.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.6.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.6.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.6.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.6.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.6.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.6.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.6.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.6.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.6.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.6.0.res_conv.bias
flow.decoder.estimator.mid_blocks.6.0.res_conv.weight
flow.decoder.estimator.mid_blocks.6.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.6.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.6.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.6.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.6.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.6.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.6.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.6.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.6.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.6.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.6.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.6.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.6.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.6.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.6.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.6.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.6.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.6.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.6.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.6.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.6.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.6.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.6.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.6.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.6.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.6.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.6.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.6.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.6.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.6.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.6.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.6.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.6.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.6.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.6.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.6.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.6.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.6.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.6.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.6.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.6.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.6.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.6.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.6.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.7.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.7.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.7.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.7.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.7.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.7.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.7.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.7.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.7.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.7.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.7.0.res_conv.bias
flow.decoder.estimator.mid_blocks.7.0.res_conv.weight
flow.decoder.estimator.mid_blocks.7.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.7.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.7.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.7.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.7.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.7.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.7.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.7.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.7.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.7.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.7.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.7.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.7.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.7.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.7.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.7.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.7.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.7.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.7.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.7.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.7.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.7.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.7.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.7.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.7.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.7.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.7.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.7.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.7.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.7.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.7.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.7.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.7.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.7.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.7.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.7.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.7.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.7.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.7.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.7.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.7.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.7.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.7.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.7.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.8.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.8.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.8.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.8.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.8.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.8.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.8.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.8.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.8.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.8.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.8.0.res_conv.bias
flow.decoder.estimator.mid_blocks.8.0.res_conv.weight
flow.decoder.estimator.mid_blocks.8.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.8.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.8.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.8.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.8.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.8.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.8.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.8.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.8.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.8.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.8.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.8.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.8.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.8.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.8.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.8.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.8.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.8.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.8.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.8.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.8.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.8.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.8.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.8.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.8.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.8.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.8.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.8.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.8.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.8.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.8.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.8.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.8.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.8.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.8.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.8.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.8.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.8.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.8.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.8.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.8.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.8.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.8.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.8.1.3.norm3.weight
flow.decoder.estimator.mid_blocks.9.0.block1.block.0.bias
flow.decoder.estimator.mid_blocks.9.0.block1.block.0.weight
flow.decoder.estimator.mid_blocks.9.0.block1.block.2.bias
flow.decoder.estimator.mid_blocks.9.0.block1.block.2.weight
flow.decoder.estimator.mid_blocks.9.0.block2.block.0.bias
flow.decoder.estimator.mid_blocks.9.0.block2.block.0.weight
flow.decoder.estimator.mid_blocks.9.0.block2.block.2.bias
flow.decoder.estimator.mid_blocks.9.0.block2.block.2.weight
flow.decoder.estimator.mid_blocks.9.0.mlp.1.bias
flow.decoder.estimator.mid_blocks.9.0.mlp.1.weight
flow.decoder.estimator.mid_blocks.9.0.res_conv.bias
flow.decoder.estimator.mid_blocks.9.0.res_conv.weight
flow.decoder.estimator.mid_blocks.9.1.0.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.9.1.0.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.9.1.0.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.9.1.0.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.9.1.0.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.9.1.0.ff.net.2.bias
flow.decoder.estimator.mid_blocks.9.1.0.ff.net.2.weight
flow.decoder.estimator.mid_blocks.9.1.0.norm1.bias
flow.decoder.estimator.mid_blocks.9.1.0.norm1.weight
flow.decoder.estimator.mid_blocks.9.1.0.norm3.bias
flow.decoder.estimator.mid_blocks.9.1.0.norm3.weight
flow.decoder.estimator.mid_blocks.9.1.1.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.9.1.1.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.9.1.1.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.9.1.1.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.9.1.1.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.9.1.1.ff.net.2.bias
flow.decoder.estimator.mid_blocks.9.1.1.ff.net.2.weight
flow.decoder.estimator.mid_blocks.9.1.1.norm1.bias
flow.decoder.estimator.mid_blocks.9.1.1.norm1.weight
flow.decoder.estimator.mid_blocks.9.1.1.norm3.bias
flow.decoder.estimator.mid_blocks.9.1.1.norm3.weight
flow.decoder.estimator.mid_blocks.9.1.2.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.9.1.2.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.9.1.2.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.9.1.2.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.9.1.2.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.9.1.2.ff.net.2.bias
flow.decoder.estimator.mid_blocks.9.1.2.ff.net.2.weight
flow.decoder.estimator.mid_blocks.9.1.2.norm1.bias
flow.decoder.estimator.mid_blocks.9.1.2.norm1.weight
flow.decoder.estimator.mid_blocks.9.1.2.norm3.bias
flow.decoder.estimator.mid_blocks.9.1.2.norm3.weight
flow.decoder.estimator.mid_blocks.9.1.3.attn1.to_k.weight
flow.decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0.bias
flow.decoder.estimator.mid_blocks.9.1.3.attn1.to_out.0.weight
flow.decoder.estimator.mid_blocks.9.1.3.attn1.to_q.weight
flow.decoder.estimator.mid_blocks.9.1.3.attn1.to_v.weight
flow.decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj.bias
flow.decoder.estimator.mid_blocks.9.1.3.ff.net.0.proj.weight
flow.decoder.estimator.mid_blocks.9.1.3.ff.net.2.bias
flow.decoder.estimator.mid_blocks.9.1.3.ff.net.2.weight
flow.decoder.estimator.mid_blocks.9.1.3.norm1.bias
flow.decoder.estimator.mid_blocks.9.1.3.norm1.weight
flow.decoder.estimator.mid_blocks.9.1.3.norm3.bias
flow.decoder.estimator.mid_blocks.9.1.3.norm3.weight
flow.decoder.estimator.time_embed_mixer.weight
flow.decoder.estimator.time_mlp.linear_1.bias
flow.decoder.estimator.time_mlp.linear_1.weight
flow.decoder.estimator.time_mlp.linear_2.bias
flow.decoder.estimator.time_mlp.linear_2.weight
flow.decoder.estimator.up_blocks.0.0.block1.block.0.bias
flow.decoder.estimator.up_blocks.0.0.block1.block.0.weight
flow.decoder.estimator.up_blocks.0.0.block1.block.2.bias
flow.decoder.estimator.up_blocks.0.0.block1.block.2.weight
flow.decoder.estimator.up_blocks.0.0.block2.block.0.bias
flow.decoder.estimator.up_blocks.0.0.block2.block.0.weight
flow.decoder.estimator.up_blocks.0.0.block2.block.2.bias
flow.decoder.estimator.up_blocks.0.0.block2.block.2.weight
flow.decoder.estimator.up_blocks.0.0.mlp.1.bias
flow.decoder.estimator.up_blocks.0.0.mlp.1.weight
flow.decoder.estimator.up_blocks.0.0.res_conv.bias
flow.decoder.estimator.up_blocks.0.0.res_conv.weight
flow.decoder.estimator.up_blocks.0.1.0.attn1.to_k.weight
flow.decoder.estimator.up_blocks.0.1.0.attn1.to_out.0.bias
flow.decoder.estimator.up_blocks.0.1.0.attn1.to_out.0.weight
flow.decoder.estimator.up_blocks.0.1.0.attn1.to_q.weight
flow.decoder.estimator.up_blocks.0.1.0.attn1.to_v.weight
flow.decoder.estimator.up_blocks.0.1.0.ff.net.0.proj.bias
flow.decoder.estimator.up_blocks.0.1.0.ff.net.0.proj.weight
flow.decoder.estimator.up_blocks.0.1.0.ff.net.2.bias
flow.decoder.estimator.up_blocks.0.1.0.ff.net.2.weight
flow.decoder.estimator.up_blocks.0.1.0.norm1.bias
flow.decoder.estimator.up_blocks.0.1.0.norm1.weight
flow.decoder.estimator.up_blocks.0.1.0.norm3.bias
flow.decoder.estimator.up_blocks.0.1.0.norm3.weight
flow.decoder.estimator.up_blocks.0.1.1.attn1.to_k.weight
flow.decoder.estimator.up_blocks.0.1.1.attn1.to_out.0.bias
flow.decoder.estimator.up_blocks.0.1.1.attn1.to_out.0.weight
flow.decoder.estimator.up_blocks.0.1.1.attn1.to_q.weight
flow.decoder.estimator.up_blocks.0.1.1.attn1.to_v.weight
flow.decoder.estimator.up_blocks.0.1.1.ff.net.0.proj.bias
flow.decoder.estimator.up_blocks.0.1.1.ff.net.0.proj.weight
flow.decoder.estimator.up_blocks.0.1.1.ff.net.2.bias
flow.decoder.estimator.up_blocks.0.1.1.ff.net.2.weight
flow.decoder.estimator.up_blocks.0.1.1.norm1.bias
flow.decoder.estimator.up_blocks.0.1.1.norm1.weight
flow.decoder.estimator.up_blocks.0.1.1.norm3.bias
flow.decoder.estimator.up_blocks.0.1.1.norm3.weight
flow.decoder.estimator.up_blocks.0.1.2.attn1.to_k.weight
flow.decoder.estimator.up_blocks.0.1.2.attn1.to_out.0.bias
flow.decoder.estimator.up_blocks.0.1.2.attn1.to_out.0.weight
flow.decoder.estimator.up_blocks.0.1.2.attn1.to_q.weight
flow.decoder.estimator.up_blocks.0.1.2.attn1.to_v.weight
flow.decoder.estimator.up_blocks.0.1.2.ff.net.0.proj.bias
flow.decoder.estimator.up_blocks.0.1.2.ff.net.0.proj.weight
flow.decoder.estimator.up_blocks.0.1.2.ff.net.2.bias
flow.decoder.estimator.up_blocks.0.1.2.ff.net.2.weight
flow.decoder.estimator.up_blocks.0.1.2.norm1.bias
flow.decoder.estimator.up_blocks.0.1.2.norm1.weight
flow.decoder.estimator.up_blocks.0.1.2.norm3.bias
flow.decoder.estimator.up_blocks.0.1.2.norm3.weight
flow.decoder.estimator.up_blocks.0.1.3.attn1.to_k.weight
flow.decoder.estimator.up_blocks.0.1.3.attn1.to_out.0.bias
flow.decoder.estimator.up_blocks.0.1.3.attn1.to_out.0.weight
flow.decoder.estimator.up_blocks.0.1.3.attn1.to_q.weight
flow.decoder.estimator.up_blocks.0.1.3.attn1.to_v.weight
flow.decoder.estimator.up_blocks.0.1.3.ff.net.0.proj.bias
flow.decoder.estimator.up_blocks.0.1.3.ff.net.0.proj.weight
flow.decoder.estimator.up_blocks.0.1.3.ff.net.2.bias
flow.decoder.estimator.up_blocks.0.1.3.ff.net.2.weight
flow.decoder.estimator.up_blocks.0.1.3.norm1.bias
flow.decoder.estimator.up_blocks.0.1.3.norm1.weight
flow.decoder.estimator.up_blocks.0.1.3.norm3.bias
flow.decoder.estimator.up_blocks.0.1.3.norm3.weight
flow.decoder.estimator.up_blocks.0.2.bias
flow.decoder.estimator.up_blocks.0.2.weight
flow.encoder.after_norm.bias
flow.encoder.after_norm.weight
flow.encoder.embed.out.0.bias
flow.encoder.embed.out.0.weight
flow.encoder.embed.out.1.bias
flow.encoder.embed.out.1.weight
flow.encoder.encoders.0.feed_forward.w_1.bias
flow.encoder.encoders.0.feed_forward.w_1.weight
flow.encoder.encoders.0.feed_forward.w_2.bias
flow.encoder.encoders.0.feed_forward.w_2.weight
flow.encoder.encoders.0.norm_ff.bias
flow.encoder.encoders.0.norm_ff.weight
flow.encoder.encoders.0.norm_mha.bias
flow.encoder.encoders.0.norm_mha.weight
flow.encoder.encoders.0.self_attn.linear_k.bias
flow.encoder.encoders.0.self_attn.linear_k.weight
flow.encoder.encoders.0.self_attn.linear_out.bias
flow.encoder.encoders.0.self_attn.linear_out.weight
flow.encoder.encoders.0.self_attn.linear_pos.weight
flow.encoder.encoders.0.self_attn.linear_q.bias
flow.encoder.encoders.0.self_attn.linear_q.weight
flow.encoder.encoders.0.self_attn.linear_v.bias
flow.encoder.encoders.0.self_attn.linear_v.weight
flow.encoder.encoders.0.self_attn.pos_bias_u
flow.encoder.encoders.0.self_attn.pos_bias_v
flow.encoder.encoders.1.feed_forward.w_1.bias
flow.encoder.encoders.1.feed_forward.w_1.weight
flow.encoder.encoders.1.feed_forward.w_2.bias
flow.encoder.encoders.1.feed_forward.w_2.weight
flow.encoder.encoders.1.norm_ff.bias
flow.encoder.encoders.1.norm_ff.weight
flow.encoder.encoders.1.norm_mha.bias
flow.encoder.encoders.1.norm_mha.weight
flow.encoder.encoders.1.self_attn.linear_k.bias
flow.encoder.encoders.1.self_attn.linear_k.weight
flow.encoder.encoders.1.self_attn.linear_out.bias
flow.encoder.encoders.1.self_attn.linear_out.weight
flow.encoder.encoders.1.self_attn.linear_pos.weight
flow.encoder.encoders.1.self_attn.linear_q.bias
flow.encoder.encoders.1.self_attn.linear_q.weight
flow.encoder.encoders.1.self_attn.linear_v.bias
flow.encoder.encoders.1.self_attn.linear_v.weight
flow.encoder.encoders.1.self_attn.pos_bias_u
flow.encoder.encoders.1.self_attn.pos_bias_v
flow.encoder.encoders.2.feed_forward.w_1.bias
flow.encoder.encoders.2.feed_forward.w_1.weight
flow.encoder.encoders.2.feed_forward.w_2.bias
flow.encoder.encoders.2.feed_forward.w_2.weight
flow.encoder.encoders.2.norm_ff.bias
flow.encoder.encoders.2.norm_ff.weight
flow.encoder.encoders.2.norm_mha.bias
flow.encoder.encoders.2.norm_mha.weight
flow.encoder.encoders.2.self_attn.linear_k.bias
flow.encoder.encoders.2.self_attn.linear_k.weight
flow.encoder.encoders.2.self_attn.linear_out.bias
flow.encoder.encoders.2.self_attn.linear_out.weight
flow.encoder.encoders.2.self_attn.linear_pos.weight
flow.encoder.encoders.2.self_attn.linear_q.bias
flow.encoder.encoders.2.self_attn.linear_q.weight
flow.encoder.encoders.2.self_attn.linear_v.bias
flow.encoder.encoders.2.self_attn.linear_v.weight
flow.encoder.encoders.2.self_attn.pos_bias_u
flow.encoder.encoders.2.self_attn.pos_bias_v
flow.encoder.encoders.3.feed_forward.w_1.bias
flow.encoder.encoders.3.feed_forward.w_1.weight
flow.encoder.encoders.3.feed_forward.w_2.bias
flow.encoder.encoders.3.feed_forward.w_2.weight
flow.encoder.encoders.3.norm_ff.bias
flow.encoder.encoders.3.norm_ff.weight
flow.encoder.encoders.3.norm_mha.bias
flow.encoder.encoders.3.norm_mha.weight
flow.encoder.encoders.3.self_attn.linear_k.bias
flow.encoder.encoders.3.self_attn.linear_k.weight
flow.encoder.encoders.3.self_attn.linear_out.bias
flow.encoder.encoders.3.self_attn.linear_out.weight
flow.encoder.encoders.3.self_attn.linear_pos.weight
flow.encoder.encoders.3.self_attn.linear_q.bias
flow.encoder.encoders.3.self_attn.linear_q.weight
flow.encoder.encoders.3.self_attn.linear_v.bias
flow.encoder.encoders.3.self_attn.linear_v.weight
flow.encoder.encoders.3.self_attn.pos_bias_u
flow.encoder.encoders.3.self_attn.pos_bias_v
flow.encoder.encoders.4.feed_forward.w_1.bias
flow.encoder.encoders.4.feed_forward.w_1.weight
flow.encoder.encoders.4.feed_forward.w_2.bias
flow.encoder.encoders.4.feed_forward.w_2.weight
flow.encoder.encoders.4.norm_ff.bias
flow.encoder.encoders.4.norm_ff.weight
flow.encoder.encoders.4.norm_mha.bias
flow.encoder.encoders.4.norm_mha.weight
flow.encoder.encoders.4.self_attn.linear_k.bias
flow.encoder.encoders.4.self_attn.linear_k.weight
flow.encoder.encoders.4.self_attn.linear_out.bias
flow.encoder.encoders.4.self_attn.linear_out.weight
flow.encoder.encoders.4.self_attn.linear_pos.weight
flow.encoder.encoders.4.self_attn.linear_q.bias
flow.encoder.encoders.4.self_attn.linear_q.weight
flow.encoder.encoders.4.self_attn.linear_v.bias
flow.encoder.encoders.4.self_attn.linear_v.weight
flow.encoder.encoders.4.self_attn.pos_bias_u
flow.encoder.encoders.4.self_attn.pos_bias_v
flow.encoder.encoders.5.feed_forward.w_1.bias
flow.encoder.encoders.5.feed_forward.w_1.weight
flow.encoder.encoders.5.feed_forward.w_2.bias
flow.encoder.encoders.5.feed_forward.w_2.weight
flow.encoder.encoders.5.norm_ff.bias
flow.encoder.encoders.5.norm_ff.weight
flow.encoder.encoders.5.norm_mha.bias
flow.encoder.encoders.5.norm_mha.weight
flow.encoder.encoders.5.self_attn.linear_k.bias
flow.encoder.encoders.5.self_attn.linear_k.weight
flow.encoder.encoders.5.self_attn.linear_out.bias
flow.encoder.encoders.5.self_attn.linear_out.weight
flow.encoder.encoders.5.self_attn.linear_pos.weight
flow.encoder.encoders.5.self_attn.linear_q.bias
flow.encoder.encoders.5.self_attn.linear_q.weight
flow.encoder.encoders.5.self_attn.linear_v.bias
flow.encoder.encoders.5.self_attn.linear_v.weight
flow.encoder.encoders.5.self_attn.pos_bias_u
flow.encoder.encoders.5.self_attn.pos_bias_v
flow.encoder.pre_lookahead_layer.conv1.bias
flow.encoder.pre_lookahead_layer.conv1.weight
flow.encoder.pre_lookahead_layer.conv2.bias
flow.encoder.pre_lookahead_layer.conv2.weight
flow.encoder.up_embed.out.0.bias
flow.encoder.up_embed.out.0.weight
flow.encoder.up_embed.out.1.bias
flow.encoder.up_embed.out.1.weight
flow.encoder.up_encoders.0.feed_forward.w_1.bias
flow.encoder.up_encoders.0.feed_forward.w_1.weight
flow.encoder.up_encoders.0.feed_forward.w_2.bias
flow.encoder.up_encoders.0.feed_forward.w_2.weight
flow.encoder.up_encoders.0.norm_ff.bias
flow.encoder.up_encoders.0.norm_ff.weight
flow.encoder.up_encoders.0.norm_mha.bias
flow.encoder.up_encoders.0.norm_mha.weight
flow.encoder.up_encoders.0.self_attn.linear_k.bias
flow.encoder.up_encoders.0.self_attn.linear_k.weight
flow.encoder.up_encoders.0.self_attn.linear_out.bias
flow.encoder.up_encoders.0.self_attn.linear_out.weight
flow.encoder.up_encoders.0.self_attn.linear_pos.weight
flow.encoder.up_encoders.0.self_attn.linear_q.bias
flow.encoder.up_encoders.0.self_attn.linear_q.weight
flow.encoder.up_encoders.0.self_attn.linear_v.bias
flow.encoder.up_encoders.0.self_attn.linear_v.weight
flow.encoder.up_encoders.0.self_attn.pos_bias_u
flow.encoder.up_encoders.0.self_attn.pos_bias_v
flow.encoder.up_encoders.1.feed_forward.w_1.bias
flow.encoder.up_encoders.1.feed_forward.w_1.weight
flow.encoder.up_encoders.1.feed_forward.w_2.bias
flow.encoder.up_encoders.1.feed_forward.w_2.weight
flow.encoder.up_encoders.1.norm_ff.bias
flow.encoder.up_encoders.1.norm_ff.weight
flow.encoder.up_encoders.1.norm_mha.bias
flow.encoder.up_encoders.1.norm_mha.weight
flow.encoder.up_encoders.1.self_attn.linear_k.bias
flow.encoder.up_encoders.1.self_attn.linear_k.weight
flow.encoder.up_encoders.1.self_attn.linear_out.bias
flow.encoder.up_encoders.1.self_attn.linear_out.weight
flow.encoder.up_encoders.1.self_attn.linear_pos.weight
flow.encoder.up_encoders.1.self_attn.linear_q.bias
flow.encoder.up_encoders.1.self_attn.linear_q.weight
flow.encoder.up_encoders.1.self_attn.linear_v.bias
flow.encoder.up_encoders.1.self_attn.linear_v.weight
flow.encoder.up_encoders.1.self_attn.pos_bias_u
flow.encoder.up_encoders.1.self_attn.pos_bias_v
flow.encoder.up_encoders.2.feed_forward.w_1.bias
flow.encoder.up_encoders.2.feed_forward.w_1.weight
flow.encoder.up_encoders.2.feed_forward.w_2.bias
flow.encoder.up_encoders.2.feed_forward.w_2.weight
flow.encoder.up_encoders.2.norm_ff.bias
flow.encoder.up_encoders.2.norm_ff.weight
flow.encoder.up_encoders.2.norm_mha.bias
flow.encoder.up_encoders.2.norm_mha.weight
flow.encoder.up_encoders.2.self_attn.linear_k.bias
flow.encoder.up_encoders.2.self_attn.linear_k.weight
flow.encoder.up_encoders.2.self_attn.linear_out.bias
flow.encoder.up_encoders.2.self_attn.linear_out.weight
flow.encoder.up_encoders.2.self_attn.linear_pos.weight
flow.encoder.up_encoders.2.self_attn.linear_q.bias
flow.encoder.up_encoders.2.self_attn.linear_q.weight
flow.encoder.up_encoders.2.self_attn.linear_v.bias
flow.encoder.up_encoders.2.self_attn.linear_v.weight
flow.encoder.up_encoders.2.self_attn.pos_bias_u
flow.encoder.up_encoders.2.self_attn.pos_bias_v
flow.encoder.up_encoders.3.feed_forward.w_1.bias
flow.encoder.up_encoders.3.feed_forward.w_1.weight
flow.encoder.up_encoders.3.feed_forward.w_2.bias
flow.encoder.up_encoders.3.feed_forward.w_2.weight
flow.encoder.up_encoders.3.norm_ff.bias
flow.encoder.up_encoders.3.norm_ff.weight
flow.encoder.up_encoders.3.norm_mha.bias
flow.encoder.up_encoders.3.norm_mha.weight
flow.encoder.up_encoders.3.self_attn.linear_k.bias
flow.encoder.up_encoders.3.self_attn.linear_k.weight
flow.encoder.up_encoders.3.self_attn.linear_out.bias
flow.encoder.up_encoders.3.self_attn.linear_out.weight
flow.encoder.up_encoders.3.self_attn.linear_pos.weight
flow.encoder.up_encoders.3.self_attn.linear_q.bias
flow.encoder.up_encoders.3.self_attn.linear_q.weight
flow.encoder.up_encoders.3.self_attn.linear_v.bias
flow.encoder.up_encoders.3.self_attn.linear_v.weight
flow.encoder.up_encoders.3.self_attn.pos_bias_u
flow.encoder.up_encoders.3.self_attn.pos_bias_v
flow.encoder.up_layer.conv.bias
flow.encoder.up_layer.conv.weight
flow.encoder_proj.bias
flow.encoder_proj.weight
flow.input_embedding.weight
flow.spk_embed_affine_layer.bias
flow.spk_embed_affine_layer.weight
mel2wav.conv_post.bias
mel2wav.conv_post.parametrizations.weight.original0
mel2wav.conv_post.parametrizations.weight.original1
mel2wav.conv_pre.bias
mel2wav.conv_pre.parametrizations.weight.original0
mel2wav.conv_pre.parametrizations.weight.original1
mel2wav.f0_predictor.classifier.bias
mel2wav.f0_predictor.classifier.weight
mel2wav.f0_predictor.condnet.0.bias
mel2wav.f0_predictor.condnet.0.parametrizations.weight.original0
mel2wav.f0_predictor.condnet.0.parametrizations.weight.original1
mel2wav.f0_predictor.condnet.2.bias
mel2wav.f0_predictor.condnet.2.parametrizations.weight.original0
mel2wav.f0_predictor.condnet.2.parametrizations.weight.original1
mel2wav.f0_predictor.condnet.4.bias
mel2wav.f0_predictor.condnet.4.parametrizations.weight.original0
mel2wav.f0_predictor.condnet.4.parametrizations.weight.original1
mel2wav.f0_predictor.condnet.6.bias
mel2wav.f0_predictor.condnet.6.parametrizations.weight.original0
mel2wav.f0_predictor.condnet.6.parametrizations.weight.original1
mel2wav.f0_predictor.condnet.8.bias
mel2wav.f0_predictor.condnet.8.parametrizations.weight.original0
mel2wav.f0_predictor.condnet.8.parametrizations.weight.original1
mel2wav.m_source.l_linear.bias
mel2wav.m_source.l_linear.weight
mel2wav.resblocks.0.activations1.0.alpha
mel2wav.resblocks.0.activations1.1.alpha
mel2wav.resblocks.0.activations1.2.alpha
mel2wav.resblocks.0.activations2.0.alpha
mel2wav.resblocks.0.activations2.1.alpha
mel2wav.resblocks.0.activations2.2.alpha
mel2wav.resblocks.0.convs1.0.bias
mel2wav.resblocks.0.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.0.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.0.convs1.1.bias
mel2wav.resblocks.0.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.0.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.0.convs1.2.bias
mel2wav.resblocks.0.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.0.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.0.convs2.0.bias
mel2wav.resblocks.0.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.0.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.0.convs2.1.bias
mel2wav.resblocks.0.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.0.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.0.convs2.2.bias
mel2wav.resblocks.0.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.0.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.1.activations1.0.alpha
mel2wav.resblocks.1.activations1.1.alpha
mel2wav.resblocks.1.activations1.2.alpha
mel2wav.resblocks.1.activations2.0.alpha
mel2wav.resblocks.1.activations2.1.alpha
mel2wav.resblocks.1.activations2.2.alpha
mel2wav.resblocks.1.convs1.0.bias
mel2wav.resblocks.1.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.1.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.1.convs1.1.bias
mel2wav.resblocks.1.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.1.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.1.convs1.2.bias
mel2wav.resblocks.1.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.1.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.1.convs2.0.bias
mel2wav.resblocks.1.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.1.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.1.convs2.1.bias
mel2wav.resblocks.1.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.1.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.1.convs2.2.bias
mel2wav.resblocks.1.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.1.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.2.activations1.0.alpha
mel2wav.resblocks.2.activations1.1.alpha
mel2wav.resblocks.2.activations1.2.alpha
mel2wav.resblocks.2.activations2.0.alpha
mel2wav.resblocks.2.activations2.1.alpha
mel2wav.resblocks.2.activations2.2.alpha
mel2wav.resblocks.2.convs1.0.bias
mel2wav.resblocks.2.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.2.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.2.convs1.1.bias
mel2wav.resblocks.2.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.2.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.2.convs1.2.bias
mel2wav.resblocks.2.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.2.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.2.convs2.0.bias
mel2wav.resblocks.2.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.2.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.2.convs2.1.bias
mel2wav.resblocks.2.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.2.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.2.convs2.2.bias
mel2wav.resblocks.2.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.2.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.3.activations1.0.alpha
mel2wav.resblocks.3.activations1.1.alpha
mel2wav.resblocks.3.activations1.2.alpha
mel2wav.resblocks.3.activations2.0.alpha
mel2wav.resblocks.3.activations2.1.alpha
mel2wav.resblocks.3.activations2.2.alpha
mel2wav.resblocks.3.convs1.0.bias
mel2wav.resblocks.3.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.3.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.3.convs1.1.bias
mel2wav.resblocks.3.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.3.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.3.convs1.2.bias
mel2wav.resblocks.3.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.3.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.3.convs2.0.bias
mel2wav.resblocks.3.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.3.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.3.convs2.1.bias
mel2wav.resblocks.3.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.3.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.3.convs2.2.bias
mel2wav.resblocks.3.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.3.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.4.activations1.0.alpha
mel2wav.resblocks.4.activations1.1.alpha
mel2wav.resblocks.4.activations1.2.alpha
mel2wav.resblocks.4.activations2.0.alpha
mel2wav.resblocks.4.activations2.1.alpha
mel2wav.resblocks.4.activations2.2.alpha
mel2wav.resblocks.4.convs1.0.bias
mel2wav.resblocks.4.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.4.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.4.convs1.1.bias
mel2wav.resblocks.4.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.4.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.4.convs1.2.bias
mel2wav.resblocks.4.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.4.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.4.convs2.0.bias
mel2wav.resblocks.4.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.4.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.4.convs2.1.bias
mel2wav.resblocks.4.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.4.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.4.convs2.2.bias
mel2wav.resblocks.4.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.4.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.5.activations1.0.alpha
mel2wav.resblocks.5.activations1.1.alpha
mel2wav.resblocks.5.activations1.2.alpha
mel2wav.resblocks.5.activations2.0.alpha
mel2wav.resblocks.5.activations2.1.alpha
mel2wav.resblocks.5.activations2.2.alpha
mel2wav.resblocks.5.convs1.0.bias
mel2wav.resblocks.5.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.5.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.5.convs1.1.bias
mel2wav.resblocks.5.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.5.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.5.convs1.2.bias
mel2wav.resblocks.5.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.5.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.5.convs2.0.bias
mel2wav.resblocks.5.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.5.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.5.convs2.1.bias
mel2wav.resblocks.5.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.5.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.5.convs2.2.bias
mel2wav.resblocks.5.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.5.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.6.activations1.0.alpha
mel2wav.resblocks.6.activations1.1.alpha
mel2wav.resblocks.6.activations1.2.alpha
mel2wav.resblocks.6.activations2.0.alpha
mel2wav.resblocks.6.activations2.1.alpha
mel2wav.resblocks.6.activations2.2.alpha
mel2wav.resblocks.6.convs1.0.bias
mel2wav.resblocks.6.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.6.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.6.convs1.1.bias
mel2wav.resblocks.6.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.6.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.6.convs1.2.bias
mel2wav.resblocks.6.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.6.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.6.convs2.0.bias
mel2wav.resblocks.6.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.6.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.6.convs2.1.bias
mel2wav.resblocks.6.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.6.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.6.convs2.2.bias
mel2wav.resblocks.6.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.6.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.7.activations1.0.alpha
mel2wav.resblocks.7.activations1.1.alpha
mel2wav.resblocks.7.activations1.2.alpha
mel2wav.resblocks.7.activations2.0.alpha
mel2wav.resblocks.7.activations2.1.alpha
mel2wav.resblocks.7.activations2.2.alpha
mel2wav.resblocks.7.convs1.0.bias
mel2wav.resblocks.7.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.7.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.7.convs1.1.bias
mel2wav.resblocks.7.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.7.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.7.convs1.2.bias
mel2wav.resblocks.7.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.7.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.7.convs2.0.bias
mel2wav.resblocks.7.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.7.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.7.convs2.1.bias
mel2wav.resblocks.7.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.7.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.7.convs2.2.bias
mel2wav.resblocks.7.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.7.convs2.2.parametrizations.weight.original1
mel2wav.resblocks.8.activations1.0.alpha
mel2wav.resblocks.8.activations1.1.alpha
mel2wav.resblocks.8.activations1.2.alpha
mel2wav.resblocks.8.activations2.0.alpha
mel2wav.resblocks.8.activations2.1.alpha
mel2wav.resblocks.8.activations2.2.alpha
mel2wav.resblocks.8.convs1.0.bias
mel2wav.resblocks.8.convs1.0.parametrizations.weight.original0
mel2wav.resblocks.8.convs1.0.parametrizations.weight.original1
mel2wav.resblocks.8.convs1.1.bias
mel2wav.resblocks.8.convs1.1.parametrizations.weight.original0
mel2wav.resblocks.8.convs1.1.parametrizations.weight.original1
mel2wav.resblocks.8.convs1.2.bias
mel2wav.resblocks.8.convs1.2.parametrizations.weight.original0
mel2wav.resblocks.8.convs1.2.parametrizations.weight.original1
mel2wav.resblocks.8.convs2.0.bias
mel2wav.resblocks.8.convs2.0.parametrizations.weight.original0
mel2wav.resblocks.8.convs2.0.parametrizations.weight.original1
mel2wav.resblocks.8.convs2.1.bias
mel2wav.resblocks.8.convs2.1.parametrizations.weight.original0
mel2wav.resblocks.8.convs2.1.parametrizations.weight.original1
mel2wav.resblocks.8.convs2.2.bias
mel2wav.resblocks.8.convs2.2.parametrizations.weight.original0
mel2wav.resblocks.8.convs2.2.parametrizations.weight.original1
mel2wav.source_downs.0.bias
mel2wav.source_downs.0.weight
mel2wav.source_downs.1.bias
mel2wav.source_downs.1.weight
mel2wav.source_downs.2.bias
mel2wav.source_downs.2.weight
mel2wav.source_resblocks.0.activations1.0.alpha
mel2wav.source_resblocks.0.activations1.1.alpha
mel2wav.source_resblocks.0.activations1.2.alpha
mel2wav.source_resblocks.0.activations2.0.alpha
mel2wav.source_resblocks.0.activations2.1.alpha
mel2wav.source_resblocks.0.activations2.2.alpha
mel2wav.source_resblocks.0.convs1.0.bias
mel2wav.source_resblocks.0.convs1.0.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs1.0.parametrizations.weight.original1
mel2wav.source_resblocks.0.convs1.1.bias
mel2wav.source_resblocks.0.convs1.1.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs1.1.parametrizations.weight.original1
mel2wav.source_resblocks.0.convs1.2.bias
mel2wav.source_resblocks.0.convs1.2.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs1.2.parametrizations.weight.original1
mel2wav.source_resblocks.0.convs2.0.bias
mel2wav.source_resblocks.0.convs2.0.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs2.0.parametrizations.weight.original1
mel2wav.source_resblocks.0.convs2.1.bias
mel2wav.source_resblocks.0.convs2.1.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs2.1.parametrizations.weight.original1
mel2wav.source_resblocks.0.convs2.2.bias
mel2wav.source_resblocks.0.convs2.2.parametrizations.weight.original0
mel2wav.source_resblocks.0.convs2.2.parametrizations.weight.original1
mel2wav.source_resblocks.1.activations1.0.alpha
mel2wav.source_resblocks.1.activations1.1.alpha
mel2wav.source_resblocks.1.activations1.2.alpha
mel2wav.source_resblocks.1.activations2.0.alpha
mel2wav.source_resblocks.1.activations2.1.alpha
mel2wav.source_resblocks.1.activations2.2.alpha
mel2wav.source_resblocks.1.convs1.0.bias
mel2wav.source_resblocks.1.convs1.0.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs1.0.parametrizations.weight.original1
mel2wav.source_resblocks.1.convs1.1.bias
mel2wav.source_resblocks.1.convs1.1.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs1.1.parametrizations.weight.original1
mel2wav.source_resblocks.1.convs1.2.bias
mel2wav.source_resblocks.1.convs1.2.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs1.2.parametrizations.weight.original1
mel2wav.source_resblocks.1.convs2.0.bias
mel2wav.source_resblocks.1.convs2.0.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs2.0.parametrizations.weight.original1
mel2wav.source_resblocks.1.convs2.1.bias
mel2wav.source_resblocks.1.convs2.1.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs2.1.parametrizations.weight.original1
mel2wav.source_resblocks.1.convs2.2.bias
mel2wav.source_resblocks.1.convs2.2.parametrizations.weight.original0
mel2wav.source_resblocks.1.convs2.2.parametrizations.weight.original1
mel2wav.source_resblocks.2.activations1.0.alpha
mel2wav.source_resblocks.2.activations1.1.alpha
mel2wav.source_resblocks.2.activations1.2.alpha
mel2wav.source_resblocks.2.activations2.0.alpha
mel2wav.source_resblocks.2.activations2.1.alpha
mel2wav.source_resblocks.2.activations2.2.alpha
mel2wav.source_resblocks.2.convs1.0.bias
mel2wav.source_resblocks.2.convs1.0.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs1.0.parametrizations.weight.original1
mel2wav.source_resblocks.2.convs1.1.bias
mel2wav.source_resblocks.2.convs1.1.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs1.1.parametrizations.weight.original1
mel2wav.source_resblocks.2.convs1.2.bias
mel2wav.source_resblocks.2.convs1.2.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs1.2.parametrizations.weight.original1
mel2wav.source_resblocks.2.convs2.0.bias
mel2wav.source_resblocks.2.convs2.0.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs2.0.parametrizations.weight.original1
mel2wav.source_resblocks.2.convs2.1.bias
mel2wav.source_resblocks.2.convs2.1.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs2.1.parametrizations.weight.original1
mel2wav.source_resblocks.2.convs2.2.bias
mel2wav.source_resblocks.2.convs2.2.parametrizations.weight.original0
mel2wav.source_resblocks.2.convs2.2.parametrizations.weight.original1
mel2wav.ups.0.bias
mel2wav.ups.0.parametrizations.weight.original0
mel2wav.ups.0.parametrizations.weight.original1
mel2wav.ups.1.bias
mel2wav.ups.1.parametrizations.weight.original0
mel2wav.ups.1.parametrizations.weight.original1
mel2wav.ups.2.bias
mel2wav.ups.2.parametrizations.weight.original0
mel2wav.ups.2.parametrizations.weight.original1
speaker_encoder.head.bn1.bias
speaker_encoder.head.bn1.num_batches_tracked
speaker_encoder.head.bn1.running_mean
speaker_encoder.head.bn1.running_var
speaker_encoder.head.bn1.weight
speaker_encoder.head.bn2.bias
speaker_encoder.head.bn2.num_batches_tracked
speaker_encoder.head.bn2.running_mean
speaker_encoder.head.bn2.running_var
speaker_encoder.head.bn2.weight
speaker_encoder.head.conv1.weight
speaker_encoder.head.conv2.weight
speaker_encoder.head.layer1.0.bn1.bias
speaker_encoder.head.layer1.0.bn1.num_batches_tracked
speaker_encoder.head.layer1.0.bn1.running_mean
speaker_encoder.head.layer1.0.bn1.running_var
speaker_encoder.head.layer1.0.bn1.weight
speaker_encoder.head.layer1.0.bn2.bias
speaker_encoder.head.layer1.0.bn2.num_batches_tracked
speaker_encoder.head.layer1.0.bn2.running_mean
speaker_encoder.head.layer1.0.bn2.running_var
speaker_encoder.head.layer1.0.bn2.weight
speaker_encoder.head.layer1.0.conv1.weight
speaker_encoder.head.layer1.0.conv2.weight
speaker_encoder.head.layer1.0.shortcut.0.weight
speaker_encoder.head.layer1.0.shortcut.1.bias
speaker_encoder.head.layer1.0.shortcut.1.num_batches_tracked
speaker_encoder.head.layer1.0.shortcut.1.running_mean
speaker_encoder.head.layer1.0.shortcut.1.running_var
speaker_encoder.head.layer1.0.shortcut.1.weight
speaker_encoder.head.layer1.1.bn1.bias
speaker_encoder.head.layer1.1.bn1.num_batches_tracked
speaker_encoder.head.layer1.1.bn1.running_mean
speaker_encoder.head.layer1.1.bn1.running_var
speaker_encoder.head.layer1.1.bn1.weight
speaker_encoder.head.layer1.1.bn2.bias
speaker_encoder.head.layer1.1.bn2.num_batches_tracked
speaker_encoder.head.layer1.1.bn2.running_mean
speaker_encoder.head.layer1.1.bn2.running_var
speaker_encoder.head.layer1.1.bn2.weight
speaker_encoder.head.layer1.1.conv1.weight
speaker_encoder.head.layer1.1.conv2.weight
speaker_encoder.head.layer2.0.bn1.bias
speaker_encoder.head.layer2.0.bn1.num_batches_tracked
speaker_encoder.head.layer2.0.bn1.running_mean
speaker_encoder.head.layer2.0.bn1.running_var
speaker_encoder.head.layer2.0.bn1.weight
speaker_encoder.head.layer2.0.bn2.bias
speaker_encoder.head.layer2.0.bn2.num_batches_tracked
speaker_encoder.head.layer2.0.bn2.running_mean
speaker_encoder.head.layer2.0.bn2.running_var
speaker_encoder.head.layer2.0.bn2.weight
speaker_encoder.head.layer2.0.conv1.weight
speaker_encoder.head.layer2.0.conv2.weight
speaker_encoder.head.layer2.0.shortcut.0.weight
speaker_encoder.head.layer2.0.shortcut.1.bias
speaker_encoder.head.layer2.0.shortcut.1.num_batches_tracked
speaker_encoder.head.layer2.0.shortcut.1.running_mean
speaker_encoder.head.layer2.0.shortcut.1.running_var
speaker_encoder.head.layer2.0.shortcut.1.weight
speaker_encoder.head.layer2.1.bn1.bias
speaker_encoder.head.layer2.1.bn1.num_batches_tracked
speaker_encoder.head.layer2.1.bn1.running_mean
speaker_encoder.head.layer2.1.bn1.running_var
speaker_encoder.head.layer2.1.bn1.weight
speaker_encoder.head.layer2.1.bn2.bias
speaker_encoder.head.layer2.1.bn2.num_batches_tracked
speaker_encoder.head.layer2.1.bn2.running_mean
speaker_encoder.head.layer2.1.bn2.running_var
speaker_encoder.head.layer2.1.bn2.weight
speaker_encoder.head.layer2.1.conv1.weight
speaker_encoder.head.layer2.1.conv2.weight
speaker_encoder.xvector.block1.tdnnd1.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd1.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd1.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd1.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd1.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd1.linear1.weight
speaker_encoder.xvector.block1.tdnnd1.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd1.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd1.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd1.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd1.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd1.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd1.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd1.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd1.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd1.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd10.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd10.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd10.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd10.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd10.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd10.linear1.weight
speaker_encoder.xvector.block1.tdnnd10.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd10.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd10.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd10.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd10.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd10.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd10.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd10.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd10.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd10.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd11.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd11.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd11.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd11.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd11.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd11.linear1.weight
speaker_encoder.xvector.block1.tdnnd11.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd11.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd11.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd11.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd11.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd11.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd11.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd11.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd11.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd11.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd12.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd12.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd12.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd12.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd12.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd12.linear1.weight
speaker_encoder.xvector.block1.tdnnd12.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd12.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd12.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd12.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd12.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd12.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd12.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd12.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd12.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd12.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd2.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd2.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd2.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd2.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd2.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd2.linear1.weight
speaker_encoder.xvector.block1.tdnnd2.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd2.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd2.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd2.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd2.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd2.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd2.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd2.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd2.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd2.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd3.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd3.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd3.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd3.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd3.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd3.linear1.weight
speaker_encoder.xvector.block1.tdnnd3.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd3.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd3.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd3.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd3.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd3.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd3.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd3.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd3.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd3.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd4.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd4.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd4.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd4.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd4.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd4.linear1.weight
speaker_encoder.xvector.block1.tdnnd4.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd4.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd4.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd4.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd4.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd4.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd4.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd4.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd4.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd4.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd5.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd5.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd5.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd5.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd5.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd5.linear1.weight
speaker_encoder.xvector.block1.tdnnd5.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd5.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd5.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd5.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd5.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd5.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd5.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd5.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd5.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd5.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd6.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd6.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd6.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd6.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd6.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd6.linear1.weight
speaker_encoder.xvector.block1.tdnnd6.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd6.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd6.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd6.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd6.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd6.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd6.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd6.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd6.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd6.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd7.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd7.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd7.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd7.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd7.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd7.linear1.weight
speaker_encoder.xvector.block1.tdnnd7.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd7.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd7.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd7.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd7.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd7.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd7.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd7.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd7.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd7.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd8.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd8.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd8.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd8.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd8.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd8.linear1.weight
speaker_encoder.xvector.block1.tdnnd8.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd8.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd8.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd8.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd8.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd8.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd8.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd8.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd8.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd8.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd9.cam_layer.linear1.bias
speaker_encoder.xvector.block1.tdnnd9.cam_layer.linear1.weight
speaker_encoder.xvector.block1.tdnnd9.cam_layer.linear2.bias
speaker_encoder.xvector.block1.tdnnd9.cam_layer.linear2.weight
speaker_encoder.xvector.block1.tdnnd9.cam_layer.linear_local.weight
speaker_encoder.xvector.block1.tdnnd9.linear1.weight
speaker_encoder.xvector.block1.tdnnd9.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd9.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd9.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd9.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd9.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block1.tdnnd9.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block1.tdnnd9.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block1.tdnnd9.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block1.tdnnd9.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block1.tdnnd9.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd1.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd1.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd1.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd1.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd1.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd1.linear1.weight
speaker_encoder.xvector.block2.tdnnd1.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd1.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd1.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd1.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd1.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd1.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd1.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd1.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd1.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd1.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd10.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd10.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd10.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd10.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd10.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd10.linear1.weight
speaker_encoder.xvector.block2.tdnnd10.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd10.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd10.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd10.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd10.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd10.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd10.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd10.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd10.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd10.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd11.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd11.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd11.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd11.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd11.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd11.linear1.weight
speaker_encoder.xvector.block2.tdnnd11.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd11.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd11.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd11.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd11.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd11.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd11.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd11.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd11.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd11.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd12.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd12.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd12.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd12.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd12.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd12.linear1.weight
speaker_encoder.xvector.block2.tdnnd12.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd12.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd12.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd12.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd12.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd12.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd12.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd12.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd12.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd12.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd13.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd13.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd13.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd13.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd13.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd13.linear1.weight
speaker_encoder.xvector.block2.tdnnd13.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd13.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd13.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd13.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd13.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd13.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd13.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd13.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd13.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd13.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd14.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd14.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd14.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd14.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd14.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd14.linear1.weight
speaker_encoder.xvector.block2.tdnnd14.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd14.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd14.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd14.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd14.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd14.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd14.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd14.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd14.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd14.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd15.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd15.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd15.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd15.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd15.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd15.linear1.weight
speaker_encoder.xvector.block2.tdnnd15.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd15.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd15.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd15.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd15.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd15.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd15.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd15.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd15.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd15.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd16.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd16.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd16.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd16.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd16.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd16.linear1.weight
speaker_encoder.xvector.block2.tdnnd16.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd16.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd16.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd16.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd16.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd16.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd16.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd16.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd16.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd16.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd17.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd17.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd17.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd17.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd17.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd17.linear1.weight
speaker_encoder.xvector.block2.tdnnd17.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd17.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd17.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd17.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd17.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd17.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd17.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd17.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd17.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd17.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd18.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd18.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd18.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd18.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd18.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd18.linear1.weight
speaker_encoder.xvector.block2.tdnnd18.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd18.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd18.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd18.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd18.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd18.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd18.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd18.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd18.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd18.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd19.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd19.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd19.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd19.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd19.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd19.linear1.weight
speaker_encoder.xvector.block2.tdnnd19.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd19.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd19.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd19.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd19.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd19.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd19.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd19.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd19.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd19.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd2.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd2.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd2.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd2.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd2.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd2.linear1.weight
speaker_encoder.xvector.block2.tdnnd2.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd2.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd2.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd2.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd2.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd2.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd2.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd2.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd2.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd2.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd20.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd20.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd20.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd20.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd20.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd20.linear1.weight
speaker_encoder.xvector.block2.tdnnd20.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd20.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd20.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd20.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd20.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd20.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd20.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd20.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd20.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd20.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd21.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd21.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd21.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd21.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd21.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd21.linear1.weight
speaker_encoder.xvector.block2.tdnnd21.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd21.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd21.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd21.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd21.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd21.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd21.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd21.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd21.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd21.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd22.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd22.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd22.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd22.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd22.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd22.linear1.weight
speaker_encoder.xvector.block2.tdnnd22.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd22.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd22.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd22.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd22.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd22.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd22.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd22.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd22.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd22.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd23.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd23.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd23.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd23.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd23.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd23.linear1.weight
speaker_encoder.xvector.block2.tdnnd23.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd23.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd23.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd23.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd23.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd23.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd23.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd23.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd23.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd23.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd24.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd24.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd24.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd24.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd24.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd24.linear1.weight
speaker_encoder.xvector.block2.tdnnd24.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd24.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd24.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd24.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd24.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd24.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd24.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd24.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd24.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd24.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd3.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd3.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd3.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd3.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd3.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd3.linear1.weight
speaker_encoder.xvector.block2.tdnnd3.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd3.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd3.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd3.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd3.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd3.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd3.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd3.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd3.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd3.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd4.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd4.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd4.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd4.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd4.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd4.linear1.weight
speaker_encoder.xvector.block2.tdnnd4.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd4.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd4.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd4.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd4.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd4.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd4.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd4.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd4.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd4.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd5.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd5.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd5.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd5.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd5.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd5.linear1.weight
speaker_encoder.xvector.block2.tdnnd5.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd5.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd5.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd5.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd5.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd5.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd5.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd5.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd5.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd5.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd6.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd6.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd6.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd6.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd6.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd6.linear1.weight
speaker_encoder.xvector.block2.tdnnd6.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd6.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd6.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd6.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd6.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd6.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd6.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd6.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd6.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd6.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd7.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd7.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd7.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd7.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd7.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd7.linear1.weight
speaker_encoder.xvector.block2.tdnnd7.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd7.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd7.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd7.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd7.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd7.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd7.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd7.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd7.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd7.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd8.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd8.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd8.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd8.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd8.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd8.linear1.weight
speaker_encoder.xvector.block2.tdnnd8.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd8.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd8.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd8.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd8.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd8.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd8.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd8.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd8.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd8.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd9.cam_layer.linear1.bias
speaker_encoder.xvector.block2.tdnnd9.cam_layer.linear1.weight
speaker_encoder.xvector.block2.tdnnd9.cam_layer.linear2.bias
speaker_encoder.xvector.block2.tdnnd9.cam_layer.linear2.weight
speaker_encoder.xvector.block2.tdnnd9.cam_layer.linear_local.weight
speaker_encoder.xvector.block2.tdnnd9.linear1.weight
speaker_encoder.xvector.block2.tdnnd9.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd9.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd9.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd9.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd9.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block2.tdnnd9.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block2.tdnnd9.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block2.tdnnd9.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block2.tdnnd9.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block2.tdnnd9.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd1.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd1.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd1.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd1.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd1.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd1.linear1.weight
speaker_encoder.xvector.block3.tdnnd1.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd1.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd1.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd1.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd1.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd1.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd1.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd1.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd1.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd1.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd10.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd10.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd10.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd10.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd10.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd10.linear1.weight
speaker_encoder.xvector.block3.tdnnd10.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd10.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd10.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd10.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd10.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd10.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd10.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd10.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd10.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd10.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd11.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd11.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd11.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd11.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd11.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd11.linear1.weight
speaker_encoder.xvector.block3.tdnnd11.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd11.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd11.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd11.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd11.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd11.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd11.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd11.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd11.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd11.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd12.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd12.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd12.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd12.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd12.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd12.linear1.weight
speaker_encoder.xvector.block3.tdnnd12.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd12.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd12.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd12.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd12.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd12.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd12.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd12.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd12.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd12.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd13.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd13.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd13.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd13.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd13.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd13.linear1.weight
speaker_encoder.xvector.block3.tdnnd13.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd13.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd13.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd13.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd13.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd13.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd13.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd13.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd13.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd13.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd14.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd14.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd14.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd14.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd14.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd14.linear1.weight
speaker_encoder.xvector.block3.tdnnd14.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd14.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd14.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd14.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd14.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd14.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd14.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd14.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd14.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd14.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd15.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd15.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd15.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd15.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd15.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd15.linear1.weight
speaker_encoder.xvector.block3.tdnnd15.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd15.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd15.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd15.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd15.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd15.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd15.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd15.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd15.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd15.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd16.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd16.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd16.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd16.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd16.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd16.linear1.weight
speaker_encoder.xvector.block3.tdnnd16.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd16.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd16.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd16.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd16.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd16.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd16.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd16.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd16.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd16.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd2.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd2.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd2.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd2.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd2.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd2.linear1.weight
speaker_encoder.xvector.block3.tdnnd2.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd2.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd2.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd2.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd2.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd2.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd2.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd2.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd2.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd2.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd3.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd3.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd3.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd3.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd3.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd3.linear1.weight
speaker_encoder.xvector.block3.tdnnd3.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd3.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd3.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd3.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd3.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd3.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd3.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd3.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd3.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd3.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd4.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd4.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd4.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd4.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd4.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd4.linear1.weight
speaker_encoder.xvector.block3.tdnnd4.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd4.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd4.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd4.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd4.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd4.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd4.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd4.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd4.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd4.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd5.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd5.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd5.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd5.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd5.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd5.linear1.weight
speaker_encoder.xvector.block3.tdnnd5.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd5.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd5.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd5.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd5.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd5.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd5.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd5.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd5.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd5.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd6.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd6.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd6.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd6.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd6.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd6.linear1.weight
speaker_encoder.xvector.block3.tdnnd6.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd6.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd6.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd6.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd6.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd6.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd6.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd6.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd6.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd6.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd7.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd7.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd7.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd7.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd7.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd7.linear1.weight
speaker_encoder.xvector.block3.tdnnd7.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd7.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd7.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd7.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd7.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd7.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd7.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd7.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd7.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd7.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd8.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd8.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd8.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd8.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd8.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd8.linear1.weight
speaker_encoder.xvector.block3.tdnnd8.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd8.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd8.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd8.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd8.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd8.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd8.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd8.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd8.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd8.nonlinear2.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd9.cam_layer.linear1.bias
speaker_encoder.xvector.block3.tdnnd9.cam_layer.linear1.weight
speaker_encoder.xvector.block3.tdnnd9.cam_layer.linear2.bias
speaker_encoder.xvector.block3.tdnnd9.cam_layer.linear2.weight
speaker_encoder.xvector.block3.tdnnd9.cam_layer.linear_local.weight
speaker_encoder.xvector.block3.tdnnd9.linear1.weight
speaker_encoder.xvector.block3.tdnnd9.nonlinear1.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd9.nonlinear1.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd9.nonlinear1.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd9.nonlinear1.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd9.nonlinear1.batchnorm.weight
speaker_encoder.xvector.block3.tdnnd9.nonlinear2.batchnorm.bias
speaker_encoder.xvector.block3.tdnnd9.nonlinear2.batchnorm.num_batches_tracked
speaker_encoder.xvector.block3.tdnnd9.nonlinear2.batchnorm.running_mean
speaker_encoder.xvector.block3.tdnnd9.nonlinear2.batchnorm.running_var
speaker_encoder.xvector.block3.tdnnd9.nonlinear2.batchnorm.weight
speaker_encoder.xvector.dense.linear.weight
speaker_encoder.xvector.dense.nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.dense.nonlinear.batchnorm.running_mean
speaker_encoder.xvector.dense.nonlinear.batchnorm.running_var
speaker_encoder.xvector.out_nonlinear.batchnorm.bias
speaker_encoder.xvector.out_nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.out_nonlinear.batchnorm.running_mean
speaker_encoder.xvector.out_nonlinear.batchnorm.running_var
speaker_encoder.xvector.out_nonlinear.batchnorm.weight
speaker_encoder.xvector.tdnn.linear.weight
speaker_encoder.xvector.tdnn.nonlinear.batchnorm.bias
speaker_encoder.xvector.tdnn.nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.tdnn.nonlinear.batchnorm.running_mean
speaker_encoder.xvector.tdnn.nonlinear.batchnorm.running_var
speaker_encoder.xvector.tdnn.nonlinear.batchnorm.weight
speaker_encoder.xvector.transit1.linear.weight
speaker_encoder.xvector.transit1.nonlinear.batchnorm.bias
speaker_encoder.xvector.transit1.nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.transit1.nonlinear.batchnorm.running_mean
speaker_encoder.xvector.transit1.nonlinear.batchnorm.running_var
speaker_encoder.xvector.transit1.nonlinear.batchnorm.weight
speaker_encoder.xvector.transit2.linear.weight
speaker_encoder.xvector.transit2.nonlinear.batchnorm.bias
speaker_encoder.xvector.transit2.nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.transit2.nonlinear.batchnorm.running_mean
speaker_encoder.xvector.transit2.nonlinear.batchnorm.running_var
speaker_encoder.xvector.transit2.nonlinear.batchnorm.weight
speaker_encoder.xvector.transit3.linear.weight
speaker_encoder.xvector.transit3.nonlinear.batchnorm.bias
speaker_encoder.xvector.transit3.nonlinear.batchnorm.num_batches_tracked
speaker_encoder.xvector.transit3.nonlinear.batchnorm.running_mean
speaker_encoder.xvector.transit3.nonlinear.batchnorm.running_var
speaker_encoder.xvector.transit3.nonlinear.batchnorm.weight
tokenizer._mel_filters
tokenizer.encoder.blocks.0.attn.fsmn_block.weight
tokenizer.encoder.blocks.0.attn.key.weight
tokenizer.encoder.blocks.0.attn.out.bias
tokenizer.encoder.blocks.0.attn.out.weight
tokenizer.encoder.blocks.0.attn.query.bias
tokenizer.encoder.blocks.0.attn.query.weight
tokenizer.encoder.blocks.0.attn.value.bias
tokenizer.encoder.blocks.0.attn.value.weight
tokenizer.encoder.blocks.0.attn_ln.bias
tokenizer.encoder.blocks.0.attn_ln.weight
tokenizer.encoder.blocks.0.mlp.0.bias
tokenizer.encoder.blocks.0.mlp.0.weight
tokenizer.encoder.blocks.0.mlp.2.bias
tokenizer.encoder.blocks.0.mlp.2.weight
tokenizer.encoder.blocks.0.mlp_ln.bias
tokenizer.encoder.blocks.0.mlp_ln.weight
tokenizer.encoder.blocks.1.attn.fsmn_block.weight
tokenizer.encoder.blocks.1.attn.key.weight
tokenizer.encoder.blocks.1.attn.out.bias
tokenizer.encoder.blocks.1.attn.out.weight
tokenizer.encoder.blocks.1.attn.query.bias
tokenizer.encoder.blocks.1.attn.query.weight
tokenizer.encoder.blocks.1.attn.value.bias
tokenizer.encoder.blocks.1.attn.value.weight
tokenizer.encoder.blocks.1.attn_ln.bias
tokenizer.encoder.blocks.1.attn_ln.weight
tokenizer.encoder.blocks.1.mlp.0.bias
tokenizer.encoder.blocks.1.mlp.0.weight
tokenizer.encoder.blocks.1.mlp.2.bias
tokenizer.encoder.blocks.1.mlp.2.weight
tokenizer.encoder.blocks.1.mlp_ln.bias
tokenizer.encoder.blocks.1.mlp_ln.weight
tokenizer.encoder.blocks.2.attn.fsmn_block.weight
tokenizer.encoder.blocks.2.attn.key.weight
tokenizer.encoder.blocks.2.attn.out.bias
tokenizer.encoder.blocks.2.attn.out.weight
tokenizer.encoder.blocks.2.attn.query.bias
tokenizer.encoder.blocks.2.attn.query.weight
tokenizer.encoder.blocks.2.attn.value.bias
tokenizer.encoder.blocks.2.attn.value.weight
tokenizer.encoder.blocks.2.attn_ln.bias
tokenizer.encoder.blocks.2.attn_ln.weight
tokenizer.encoder.blocks.2.mlp.0.bias
tokenizer.encoder.blocks.2.mlp.0.weight
tokenizer.encoder.blocks.2.mlp.2.bias
tokenizer.encoder.blocks.2.mlp.2.weight
tokenizer.encoder.blocks.2.mlp_ln.bias
tokenizer.encoder.blocks.2.mlp_ln.weight
tokenizer.encoder.blocks.3.attn.fsmn_block.weight
tokenizer.encoder.blocks.3.attn.key.weight
tokenizer.encoder.blocks.3.attn.out.bias
tokenizer.encoder.blocks.3.attn.out.weight
tokenizer.encoder.blocks.3.attn.query.bias
tokenizer.encoder.blocks.3.attn.query.weight
tokenizer.encoder.blocks.3.attn.value.bias
tokenizer.encoder.blocks.3.attn.value.weight
tokenizer.encoder.blocks.3.attn_ln.bias
tokenizer.encoder.blocks.3.attn_ln.weight
tokenizer.encoder.blocks.3.mlp.0.bias
tokenizer.encoder.blocks.3.mlp.0.weight
tokenizer.encoder.blocks.3.mlp.2.bias
tokenizer.encoder.blocks.3.mlp.2.weight
tokenizer.encoder.blocks.3.mlp_ln.bias
tokenizer.encoder.blocks.3.mlp_ln.weight
tokenizer.encoder.blocks.4.attn.fsmn_block.weight
tokenizer.encoder.blocks.4.attn.key.weight
tokenizer.encoder.blocks.4.attn.out.bias
tokenizer.encoder.blocks.4.attn.out.weight
tokenizer.encoder.blocks.4.attn.query.bias
tokenizer.encoder.blocks.4.attn.query.weight
tokenizer.encoder.blocks.4.attn.value.bias
tokenizer.encoder.blocks.4.attn.value.weight
tokenizer.encoder.blocks.4.attn_ln.bias
tokenizer.encoder.blocks.4.attn_ln.weight
tokenizer.encoder.blocks.4.mlp.0.bias
tokenizer.encoder.blocks.4.mlp.0.weight
tokenizer.encoder.blocks.4.mlp.2.bias
tokenizer.encoder.blocks.4.mlp.2.weight
tokenizer.encoder.blocks.4.mlp_ln.bias
tokenizer.encoder.blocks.4.mlp_ln.weight
tokenizer.encoder.blocks.5.attn.fsmn_block.weight
tokenizer.encoder.blocks.5.attn.key.weight
tokenizer.encoder.blocks.5.attn.out.bias
tokenizer.encoder.blocks.5.attn.out.weight
tokenizer.encoder.blocks.5.attn.query.bias
tokenizer.encoder.blocks.5.attn.query.weight
tokenizer.encoder.blocks.5.attn.value.bias
tokenizer.encoder.blocks.5.attn.value.weight
tokenizer.encoder.blocks.5.attn_ln.bias
tokenizer.encoder.blocks.5.attn_ln.weight
tokenizer.encoder.blocks.5.mlp.0.bias
tokenizer.encoder.blocks.5.mlp.0.weight
tokenizer.encoder.blocks.5.mlp.2.bias
tokenizer.encoder.blocks.5.mlp.2.weight
tokenizer.encoder.blocks.5.mlp_ln.bias
tokenizer.encoder.blocks.5.mlp_ln.weight
tokenizer.encoder.conv1.bias
tokenizer.encoder.conv1.weight
tokenizer.encoder.conv2.bias
tokenizer.encoder.conv2.weight
tokenizer.quantizer._codebook.project_down.bias
tokenizer.quantizer._codebook.project_down.weight
tokenizer.window
</file>

<file path=".github/workflows/parity-check.yml">
name: Parity Check

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  CARGO_TERM_COLOR: always

jobs:
  parity-check:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    # 1. Setup Rust
    - name: Set up Rust
      uses: dtolnay/rust-toolchain@stable

    # 2. Setup Python & UV
    - name: Install uv
      uses: astral-sh/setup-uv@v2
      with:
        python-version: '3.12'

    - name: Install Python dependencies
      run: uv pip install torch pycandle-core

    # 3. Compile PyCandle CLI (or use pre-built if available)
    # For now, we assume we build it from source in the workspace
    - name: Build PyCandle CLI
      run: cargo build --release --bin pycandle

    # 4. Generate Traces (Simulating 'pycandle record')
    # Assuming 'recorder.py' is in the root as per SOP
    - name: Generate Traces
      run: uv run recorder.py
      env:
        # Ensure we can find local pycandle if not installed
        PYTHONPATH: ${{ github.workspace }}/py

    # 5. Generate Code (Optional if committed, but good to verify codegen runs)
    # If the user committed generated code, this step might be skipped or used to check for drift
    - name: Run Codegen (Verify)
      run: |
        ./target/release/pycandle codegen \
          --manifest traces/debug_run_manifest.json \
          --out generated_model.rs \
          --model MyModel \
          --analyze-only

    # 6. Run Parity Tests
    - name: Run Parity Tests
      run: cargo test --test parity
</file>

<file path=".repomixignore">
chatterbox-repo/*
</file>

<file path="crates/pycandle-core/failures/debug_node_linear.py">
import torch
from safetensors.torch import load_file
import matplotlib.pyplot as plt
import numpy as np

def analyze():
    print(f" Analyzing Failure: {'node_linear'}")
    tensors = load_file("node_linear.safetensors")
    rust = tensors["rust_actual"]
    gold = tensors["py_golden"]

    diff = (rust - gold).abs()
    print(f"  Max Diff: {diff.max().item():.6f}")
    print(f"  MSE:      {(diff ** 2).mean().item():.8f}")

    # Plot
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title("Rust Tensor Histogram")
    plt.hist(rust.flatten().float().numpy(), bins=50, alpha=0.7, label='Rust')
    plt.hist(gold.flatten().float().numpy(), bins=50, alpha=0.7, label='Gold')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.title("Difference Heatmap (First Slice)")
    if diff.ndim > 1:
        plt.imshow(diff.flatten(0, -2)[0].float().numpy(), cmap='hot', aspect='auto')
    else:
        plt.plot(diff.float().numpy())
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    analyze()
</file>

<file path="crates/pycandle-core/src/gpt2.rs">
use candle_core::{IndexOp, Result, Tensor};
use candle_nn::{Embedding, LayerNorm, Linear, Module, VarBuilder};

#[derive(Debug, Clone, Copy, PartialEq)]
pub struct Config {
    pub vocab_size: usize,
    pub context_length: usize,
    pub emb_dim: usize,
    pub n_heads: usize,
    pub n_layers: usize,
    pub drop_rate: f32,
    pub qkv_bias: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            vocab_size: 50257,
            context_length: 1024,
            emb_dim: 768,
            n_heads: 12,
            n_layers: 12,
            drop_rate: 0.1,
            qkv_bias: true, // Standard GPT2 has bias
        }
    }
}

// ============================================================================
// KV Cache
// ============================================================================

#[derive(Debug, Clone)]
pub struct KVCache {
    pub k: Tensor, // (B, n_head, T, head_dim)
    pub v: Tensor, // (B, n_head, T, head_dim)
}

impl KVCache {
    pub fn new() -> Self {
        // Placeholder, usually initialized during first forward pass
        // or we use Option<KVCache>
        unimplemented!("Use Option<KVCache> for now")
    }
}

// ============================================================================
// Layers
// ============================================================================

// Conv1D in HuggingFace is actually a Linear layer with (nx, nf) weight shape
// so transposing is needed if loading from standard HF checkpoints.
// However, standard Candle `linear` expects (out, in).
// HF Conv1D weight is (in, out).
fn conv1d(in_f: usize, out_f: usize, vb: VarBuilder) -> Result<Linear> {
    let weight = vb.get((in_f, out_f), "weight")?.t()?;
    let bias = vb.get((out_f,), "bias")?;
    Ok(Linear::new(weight, Some(bias)))
}
pub struct MultiHeadAttention {
    c_attn: Linear,
    c_proj: Linear,
    n_head: usize,
    head_dim: usize,
    scale: f64,
}

impl MultiHeadAttention {
    pub fn new(
        n_embd: usize,
        n_head: usize,
        _context_length: usize,
        vb: VarBuilder,
    ) -> Result<Self> {
        let c_attn = conv1d(n_embd, 3 * n_embd, vb.pp("c_attn"))?;
        let c_proj = conv1d(n_embd, n_embd, vb.pp("c_proj"))?;
        let head_dim = n_embd / n_head;
        let scale = 1.0 / (head_dim as f64).sqrt();

        Ok(Self {
            c_attn,
            c_proj,
            n_head,
            head_dim,
            scale,
        })
    }

    pub fn forward(
        &self,
        x: &Tensor,
        mask: Option<&Tensor>,
        layer_cache: Option<&mut Option<KVCache>>,
    ) -> Result<Tensor> {
        let (b_sz, t, c) = x.dims3()?;
        let qkv = self.c_attn.forward(x)?;

        // (B, T, 3 * n_embd) -> (B, T, 3, n_head, head_dim)
        let qkv = qkv.reshape((b_sz, t, 3, self.n_head, self.head_dim))?;
        // (3, B, n_head, T, head_dim)
        let qkv = qkv.permute((2, 0, 3, 1, 4))?;

        let q = qkv.i(0)?;
        let k = qkv.i(1)?;
        let v = qkv.i(2)?;

        // KV Cache handling
        let (k, v) = if let Some(cache_opt) = layer_cache {
            if let Some(past_kv) = cache_opt.take() {
                let k = Tensor::cat(&[&past_kv.k, &k], 2)?;
                let v = Tensor::cat(&[&past_kv.v, &v], 2)?;
                *cache_opt = Some(KVCache {
                    k: k.clone(),
                    v: v.clone(),
                });
                (k, v)
            } else {
                *cache_opt = Some(KVCache {
                    k: k.clone(),
                    v: v.clone(),
                });
                (k, v)
            }
        } else {
            (k, v)
        };

        // Standard attention
        let t_total = k.dim(2)?;
        // q: (B, H, T_q, D) @ k.t: (B, H, D, T_k) -> (B, H, T_q, T_k)
        let att = (q.matmul(&k.t()?)? * self.scale)?;

        let att = if let Some(mask) = mask {
            let infinite =
                Tensor::new(f32::NEG_INFINITY, att.device())?.broadcast_as(att.shape())?;
            let mask = mask
                .narrow(2, 0, t)?
                .narrow(3, 0, t_total)?
                .eq(0.0)?
                .broadcast_as(att.shape())?;
            mask.where_cond(&infinite, &att)?
        } else {
            att // Attend to all past
        };

        let att = candle_nn::ops::softmax(&att, 3)?;

        // (B, H, T_q, T_k) @ (B, H, T_k, D) -> (B, H, T_q, D)
        let y = att.matmul(&v)?;
        // (B, T_q, H, D) -> (B, T_q, C)
        let y = y.permute((0, 2, 1, 3))?.reshape((b_sz, t, c))?;

        self.c_proj.forward(&y)
    }
}

pub struct FeedForward {
    c_fc: Linear,
    c_proj: Linear,
    act: candle_nn::Activation,
}

impl FeedForward {
    pub fn new(n_embd: usize, vb: VarBuilder) -> Result<Self> {
        let c_fc = conv1d(n_embd, 4 * n_embd, vb.pp("c_fc"))?;
        let c_proj = conv1d(4 * n_embd, n_embd, vb.pp("c_proj"))?;
        Ok(Self {
            c_fc,
            c_proj,
            act: candle_nn::Activation::Gelu,
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let x = self.c_fc.forward(x)?;
        let x = self.act.forward(&x)?;
        self.c_proj.forward(&x)
    }
}

pub struct TransformerBlock {
    ln_1: LayerNorm,
    attn: MultiHeadAttention,
    ln_2: LayerNorm,
    mlp: FeedForward,
}

impl TransformerBlock {
    pub fn new(
        n_embd: usize,
        n_head: usize,
        context_length: usize,
        vb: VarBuilder,
    ) -> Result<Self> {
        let ln_1 = candle_nn::layer_norm(n_embd, 1e-5, vb.pp("ln_1"))?;
        let attn = MultiHeadAttention::new(n_embd, n_head, context_length, vb.pp("attn"))?;
        let ln_2 = candle_nn::layer_norm(n_embd, 1e-5, vb.pp("ln_2"))?;
        let mlp = FeedForward::new(n_embd, vb.pp("mlp"))?;
        Ok(Self {
            ln_1,
            attn,
            ln_2,
            mlp,
        })
    }

    pub fn forward(
        &self,
        x: &Tensor,
        mask: Option<&Tensor>,
        layer_cache: Option<&mut Option<KVCache>>,
    ) -> Result<Tensor> {
        let residual = x;
        let x = self.ln_1.forward(x)?;
        let x = self.attn.forward(&x, mask, layer_cache)?;
        let x = (x + residual)?;

        let residual = &x;
        let x = self.ln_2.forward(&x)?;
        let x = self.mlp.forward(&x)?;
        let x = (x + residual)?;
        Ok(x)
    }
}
pub struct GPTModel {
    pub wte: Embedding,
    pub wpe: Embedding,
    pub h: Vec<TransformerBlock>,
    pub ln_f: LayerNorm,
    pub mask: Option<Tensor>,
}

impl GPTModel {
    pub fn new(cfg: Config, vb: VarBuilder) -> Result<Self> {
        let wte = candle_nn::embedding(cfg.vocab_size, cfg.emb_dim, vb.pp("wte"))?;
        let wpe = candle_nn::embedding(cfg.context_length, cfg.emb_dim, vb.pp("wpe"))?;

        let mut h = Vec::new();
        for i in 0..cfg.n_layers {
            h.push(TransformerBlock::new(
                cfg.emb_dim,
                cfg.n_heads,
                cfg.context_length,
                vb.pp(format!("h.{}", i)),
            )?);
        }

        let ln_f = candle_nn::layer_norm(cfg.emb_dim, 1e-5, vb.pp("ln_f"))?;

        // Causal mask buffer - compute once
        let mask: Vec<_> = (0..cfg.context_length)
            .flat_map(|i| {
                (0..cfg.context_length).map(move |j| if j <= i { 1.0f32 } else { 0.0f32 })
            })
            .collect();
        let mask = Tensor::from_vec(
            mask,
            (1, 1, cfg.context_length, cfg.context_length),
            vb.device(),
        )?;

        Ok(Self {
            wte,
            wpe,
            h,
            ln_f,
            mask: Some(mask),
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        self.forward_kv(x, None)
    }

    pub fn forward_kv(
        &self,
        x: &Tensor,
        mut kv_cache: Option<&mut Vec<Option<KVCache>>>,
    ) -> Result<Tensor> {
        let (_b, t) = x.dims2()?;

        let offset = if let Some(cache) = &kv_cache {
            if let Some(Some(prev)) = cache.first() {
                prev.k.dim(2)?
            } else {
                0
            }
        } else {
            0
        };

        let pos = Tensor::arange(offset as u32, (offset + t) as u32, x.device())?;

        let tok_emb = self.wte.forward(x)?;
        let pos_emb = self.wpe.forward(&pos)?;

        let mut x = (tok_emb + pos_emb)?;

        for (i, block) in self.h.iter().enumerate() {
            let layer_cache = if let Some(cache) = &mut kv_cache {
                if cache.len() <= i {
                    cache.resize_with(i + 1, || None);
                }
                cache.get_mut(i)
            } else {
                None
            };
            x = block.forward(&x, self.mask.as_ref(), layer_cache)?;
        }

        self.ln_f.forward(&x)
    }
}
</file>

<file path="crates/pycandle-core/src/samplers.rs">
use candle_core::{Result, Tensor};

pub trait LogitsProcessor {
    fn apply(&self, logits: &Tensor) -> Result<Tensor>;
}

/// Repetition Penalty
/// Reference: https://arxiv.org/pdf/1909.05858.pdf
pub struct RepetitionPenalty {
    pub penalty: f64,
    pub context: Vec<u32>,
}

impl RepetitionPenalty {
    pub fn new(penalty: f64, context: Vec<u32>) -> Self {
        Self { penalty, context }
    }
}

impl LogitsProcessor for RepetitionPenalty {
    fn apply(&self, logits: &Tensor) -> Result<Tensor> {
        if self.penalty <= 1.0 || self.context.is_empty() {
            return Ok(logits.clone());
        }

        let mut logits_vec = logits.squeeze(0)?.to_vec1::<f32>()?;

        for &token in &self.context {
            if (token as usize) < logits_vec.len() {
                let logit = logits_vec[token as usize];
                if logit < 0.0 {
                    logits_vec[token as usize] = logit * self.penalty as f32;
                } else {
                    logits_vec[token as usize] = logit / self.penalty as f32;
                }
            }
        }

        Tensor::from_vec(logits_vec, (1, logits.dim(1)?), logits.device())
    }
}

/// Temperature scaling
pub struct Temperature {
    pub temperature: f64,
}

impl LogitsProcessor for Temperature {
    fn apply(&self, logits: &Tensor) -> Result<Tensor> {
        if self.temperature <= 0.0 {
            // Greedy sampling handled by caller usually, but here we can just return
            return Ok(logits.clone());
        }
        logits / self.temperature
    }
}

/// Top-P (Nucleus) Sampling
pub struct TopP {
    pub p: f64,
}

impl LogitsProcessor for TopP {
    fn apply(&self, logits: &Tensor) -> Result<Tensor> {
        if self.p >= 1.0 {
            return Ok(logits.clone());
        }

        let probs = candle_nn::ops::softmax(logits, 1)?;
        let probs_vec = probs.squeeze(0)?.to_vec1::<f32>()?;

        // Sort descending, keep indices
        let mut indices: Vec<usize> = (0..probs_vec.len()).collect();
        indices.sort_by(|&a, &b| probs_vec[b].partial_cmp(&probs_vec[a]).unwrap());

        let mut cum_sum = 0.0;
        let mut cutoff_index = indices.len() - 1;

        for (i, &idx) in indices.iter().enumerate() {
            cum_sum += probs_vec[idx];
            if cum_sum > self.p as f32 {
                cutoff_index = i;
                break;
            }
        }

        // Everything after cutoff gets -inf
        let mut new_logits = logits.squeeze(0)?.to_vec1::<f32>()?;
        let neg_inf = f32::NEG_INFINITY;

        // Mask out the tail
        for &idx in &indices[cutoff_index + 1..] {
            new_logits[idx] = neg_inf;
        }

        Tensor::from_vec(new_logits, (1, logits.dim(1)?), logits.device())
    }
}

/// Min-P Sampling (Alternative to Top-P)
/// Reference: https://github.com/huggingface/transformers/issues/27670
pub struct MinP {
    pub p: f64,
}

impl LogitsProcessor for MinP {
    fn apply(&self, logits: &Tensor) -> Result<Tensor> {
        if self.p <= 0.0 {
            return Ok(logits.clone());
        }

        let probs = candle_nn::ops::softmax(logits, 1)?;
        let max_prob = probs.max_keepdim(1)?.squeeze(0)?.to_vec1::<f32>()?[0];
        let scaled_min = max_prob * self.p as f32;

        let probs_vec = probs.squeeze(0)?.to_vec1::<f32>()?;
        let mut new_logits = logits.squeeze(0)?.to_vec1::<f32>()?;
        let neg_inf = f32::NEG_INFINITY;

        for (i, &prob) in probs_vec.iter().enumerate() {
            if prob < scaled_min {
                new_logits[i] = neg_inf;
            }
        }

        Tensor::from_vec(new_logits, (1, logits.dim(1)?), logits.device())
    }
}
</file>

<file path="crates/pycandle-core/src/weights.rs">
use anyhow::{Context, Result};
use regex::Regex;
use std::collections::{HashMap, HashSet};

/// A renaming engine for tensor keys using Regex patterns.
pub struct WeightMapper {
    mappings: Vec<(Regex, String)>,
}

impl WeightMapper {
    /// Create a mapper from a JSON string containing pattern -> replacement mappings.
    pub fn from_json(json: &str) -> Result<Self> {
        let raw: HashMap<String, String> = serde_json::from_str(json)?;
        let mut mappings = Vec::new();
        // Sort keys to ensure deterministic order (important for overlapping regexes)
        let mut keys: Vec<_> = raw.keys().collect();
        keys.sort();

        for pattern in keys {
            let replacement = raw.get(pattern).unwrap();
            let re = Regex::new(pattern)
                .with_context(|| format!("Invalid regex pattern: {}", pattern))?;
            mappings.push((re, replacement.clone()));
        }
        Ok(Self { mappings })
    }

    /// Map a key using all registered patterns.
    pub fn map_key(&self, key: &str) -> String {
        let mut current = key.to_string();
        for (re, replacement) in &self.mappings {
            current = re.replace_all(&current, replacement.as_str()).to_string();
        }
        current
    }
}

/// Identifies which weights are actually used in a model based on its manifest.
pub struct WeightExtractor {
    active_params: HashSet<String>,
}

impl WeightExtractor {
    /// Create an extractor from a manifest JSON.
    pub fn from_manifest(manifest_json: &str) -> Result<Self> {
        let manifest: HashMap<String, serde_json::Value> = serde_json::from_str(manifest_json)?;
        let mut active_params = HashSet::new();

        for (module_name, meta) in manifest {
            if module_name.starts_with('_') {
                continue;
            }

            if let Some(params) = meta.get("parameters").and_then(|p| p.as_array()) {
                for p in params {
                    if let Some(p_name) = p.as_str() {
                        // PyTorch module parameters are accessed as module_name.weight, etc.
                        active_params.insert(format!("{}.{}", module_name, p_name));
                    }
                }
            }
        }

        Ok(Self { active_params })
    }

    /// Check if a given tensor key is used in the manifest.
    pub fn should_keep(&self, key: &str) -> bool {
        self.active_params.contains(key)
    }

    /// Return the set of all active parameter keys.
    pub fn active_keys(&self) -> &HashSet<String> {
        &self.active_params
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_mapper_basic() {
        let json = r#"{"encoder\\.layers\\.(\\d+)\\.": "h.$1."}"#;
        let mapper = WeightMapper::from_json(json).unwrap();
        assert_eq!(mapper.map_key("encoder.layers.0.weight"), "h.0.weight");
        assert_eq!(mapper.map_key("encoder.layers.15.bias"), "h.15.bias");
    }

    #[test]
    fn test_extractor_basic() {
        let manifest = r#"{
            "encoder.layers.0": {
                "parameters": ["weight", "bias"]
            },
            "decoder": {
                "parameters": ["weight"]
            },
            "_internal": { "parameters": ["unused"] }
        }"#;
        let extractor = WeightExtractor::from_manifest(manifest).unwrap();
        assert!(extractor.should_keep("encoder.layers.0.weight"));
        assert!(extractor.should_keep("encoder.layers.0.bias"));
        assert!(extractor.should_keep("decoder.weight"));
        assert!(!extractor.should_keep("encoder.layers.0.other"));
        assert!(!extractor.should_keep("_internal.unused"));
    }
}
</file>

<file path="crates/pycandle-core/tests/dummy_test.rs">
#[cfg(test)]
mod tests {
    use candle_core::{Device, Tensor};
    use pycandle_core::{ComparisonResult, PyChecker};

    // Mock PyChecker just to access log_result (which we can't easily do without full setup)
    // Actually, we can just use PyChecker if we mock the files, but easier to just implement a similar test
    // that writes to the same file to verify the dashboard picks it up.

    // Wait, let's try to use the actual PyChecker if possible.
    // We need a dummy manifest and safetensors.
    // Instead, I'll just write a test that prints the expected output format for the dashboard to parse.

    #[test]
    fn test_layer_1_pass() {
        println!("test_layer_1_pass ... ok");
    }

    #[test]
    fn test_layer_2_fail() {
        // Dashboard should pick this up as failure
        assert!(false, "Simulated failure");
    }

    #[test]
    fn test_layer_3_pass() {
        std::thread::sleep(std::time::Duration::from_millis(500));
        println!("test_layer_3_pass ... ok");
    }
}
</file>

<file path="crates/pycandle-core/tests/quantization_drift.rs">
use candle_core::{Device, Tensor};
use pycandle_core::{LayerMeta, PyChecker, VerificationMode};
use std::collections::HashMap;

#[test]
fn test_quantization_drift() -> anyhow::Result<()> {
    let device = Device::Cpu;

    // 1. Create a dummy manifest
    let manifest_json = r#"{
        "layer_perfect": {
            "name": "layer_perfect", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        },
        "layer_drift_small": {
            "name": "layer_drift_small", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        },
        "layer_drift_large": {
            "name": "layer_drift_large", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        }
    }"#;

    // Write dummy files for PyChecker::load
    // Use a unique subdir to avoid conflicts
    let trace_dir = "test_trace_drift_core";
    std::fs::create_dir_all(trace_dir)?;
    std::fs::write(
        format!("{}/drift_run_manifest.json", trace_dir),
        manifest_json,
    )?;

    // Create dummy golden tensors
    let t_perfect = Tensor::new(&[1.0f32, 2.0, 3.0], &device)?;
    let t_drift_small = Tensor::new(&[10.0f32, 20.0, 30.0], &device)?;
    let t_drift_large = Tensor::new(&[100.0f32, 200.0, 300.0], &device)?;

    let tensors_map: HashMap<String, Tensor> = HashMap::from([
        ("layer_perfect.out.0".to_string(), t_perfect.clone()),
        ("layer_drift_small.out.0".to_string(), t_drift_small.clone()),
        ("layer_drift_large.out.0".to_string(), t_drift_large.clone()),
    ]);
    candle_core::safetensors::save(
        &tensors_map,
        format!("{}/drift_run_trace.safetensors", trace_dir),
    )?;

    // 2. Load Checker in DriftTracking mode
    // Note: PyChecker::load takes project_name and base_path
    let checker = PyChecker::load("drift_run", trace_dir, &device)?
        .with_mode(VerificationMode::DriftTracking);

    println!("Checking in mode: {:?}", checker.mode);

    // 3. Verify Layers

    // A) Perfect Match
    let res1 = checker.verify("layer_perfect", &t_perfect)?;
    assert!(res1.mse < 1e-6);

    // B) Small Drift (MSE = 1e-6, barely passing strict if atol=1e-4, but let's make it small enough)
    // Let's add noise: 1e-3. 1e-3^2 = 1e-6.
    let noise_small = Tensor::new(&[0.001f32, 0.001, 0.001], &device)?;
    let t_small_noisy = (&t_drift_small + noise_small)?;
    let res2 = checker.verify("layer_drift_small", &t_small_noisy)?;
    println!("Layer Small Drift MSE: {}", res2.mse);

    // C) Large Drift (MSE ~ 0.01) - Should fail in Strict, but pass here
    // Noise 0.1. 0.1^2 = 0.01. > 1e-4.
    let noise_large = Tensor::new(&[0.1f32, 0.1, 0.1], &device)?;
    let t_large_noisy = (&t_drift_large + noise_large)?;

    // This should NOT panic or return Err, unlike Strict mode
    let res3 = checker.verify("layer_drift_large", &t_large_noisy)?;
    println!("Layer Large Drift MSE: {}", res3.mse);

    assert!(
        res3.mse > checker.atol,
        "Expected large drift to exceed atol"
    );

    // 4. Print Report (Manual verify on console output)
    checker.print_drift_report();

    // Cleanup
    std::fs::remove_dir_all(trace_dir)?;

    Ok(())
}
</file>

<file path="crates/pycandle-core/verification_results.jsonl">
{"name":"layer_perfect","mse":0.0,"max_diff":0.0,"cosine_sim":0.99999994,"passed":true,"heatmap":null}
{"name":"layer_drift_small","mse":9.995374e-7,"max_diff":0.0010004044,"cosine_sim":1.0,"passed":true,"heatmap":null}
{"name":"layer_drift_large","mse":0.010000712,"max_diff":0.1000061,"cosine_sim":1.0,"passed":false,"heatmap":null}
{"name":"layer_perfect","mse":0.0,"max_diff":0.0,"cosine_sim":0.99999994,"passed":true,"heatmap":null}
{"name":"layer_drift_small","mse":9.995374e-7,"max_diff":0.0010004044,"cosine_sim":1.0,"passed":true,"heatmap":null}
{"name":"layer_drift_large","mse":0.010000712,"max_diff":0.1000061,"cosine_sim":1.0,"passed":false,"heatmap":null}
{"name":"layer_perfect","mse":0.0,"max_diff":0.0,"cosine_sim":0.99999994,"passed":true,"heatmap":null}
{"name":"layer_drift_small","mse":9.995374e-7,"max_diff":0.0010004044,"cosine_sim":1.0,"passed":true,"heatmap":null}
{"name":"layer_drift_large","mse":0.010000712,"max_diff":0.1000061,"cosine_sim":1.0,"passed":false,"heatmap":null}
{"name":"node_linear","mse":0.44827208,"max_diff":1.1747879,"cosine_sim":0.0,"passed":false,"heatmap":null}
{"name":"node_linear","mse":0.44827208,"max_diff":1.1747879,"cosine_sim":0.0,"passed":false,"heatmap":null}
{"name":"node_linear","mse":0.0,"max_diff":0.0,"cosine_sim":0.99999994,"passed":true,"heatmap":null}
{"name":"node_relu","mse":0.0,"max_diff":0.0,"cosine_sim":1.0000001,"passed":true,"heatmap":null}
{"name":"node_relu","mse":0.0,"max_diff":0.0,"cosine_sim":1.0000001,"passed":true,"heatmap":null}
{"name":"node_linear","mse":0.0,"max_diff":0.0,"cosine_sim":0.99999994,"passed":true,"heatmap":null}
{"name":"node_relu","mse":0.0,"max_diff":0.0,"cosine_sim":1.0000001,"passed":true,"heatmap":null}
{"name":"node_relu","mse":0.0,"max_diff":0.0,"cosine_sim":1.0000001,"passed":true,"heatmap":null}
</file>

<file path="crates/pycandle/src/dashboard.rs">
use anyhow::Result;
use crossterm::{
    event::{self, Event, KeyCode, KeyEventKind},
    execute,
    terminal::{EnterAlternateScreen, LeaveAlternateScreen, disable_raw_mode, enable_raw_mode},
};
use pycandle_core::ComparisonResult;
use ratatui::{
    prelude::*,
    widgets::{
        Block, Borders, List, ListItem, Paragraph,
        canvas::{Canvas, Rectangle},
    },
};
use std::collections::HashMap;
use std::io::{BufRead, BufReader};
use std::process::{Command, Stdio};
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

pub enum DashboardEvent {
    Input(event::KeyEvent),
    TestLine(String),
    Tick,
}

struct App {
    test_results: Vec<TestResult>,
    parity_results: HashMap<String, ComparisonResult>,
    output_log: Vec<String>,
    running: bool,
    scroll: usize,
    passed: usize,
    failed: usize,
    total: usize,
}

struct TestResult {
    name: String,
    status: TestStatus,
    details: String,
}

enum TestStatus {
    Running,
    Passed,
    Failed,
}

impl App {
    fn new() -> Self {
        Self {
            test_results: Vec::new(),
            parity_results: HashMap::new(),
            output_log: Vec::new(),
            running: true,
            scroll: 0,
            passed: 0,
            failed: 0,
            total: 0,
        }
    }

    fn on_tick(&mut self) {
        // Periodically reload parity results
        self.load_parity_results();
    }

    fn load_parity_results(&mut self) {
        if let Ok(file) = std::fs::File::open("verification_results.jsonl") {
            let reader = BufReader::new(file);
            for line in reader.lines() {
                if let Ok(l) = line {
                    if let Ok(res) = serde_json::from_str::<ComparisonResult>(&l) {
                        // Normalize name to help matching?
                        // For now just store by layer name
                        self.parity_results.insert(res.name.clone(), res);
                    }
                }
            }
        }
    }

    fn on_log(&mut self, line: String) {
        // Parse cargo test output
        if line.contains("test result: ok") {
            // Summary line, maybe parse stats?
        } else if line.contains("test ") && line.contains(" ... ok") {
            let name = line.replace("test ", "").replace(" ... ok", "");
            self.test_results.push(TestResult {
                name,
                status: TestStatus::Passed,
                details: "".to_string(),
            });
            self.passed += 1;
            self.total += 1;
        } else if line.contains("test ") && line.contains(" ... FAILED") {
            let name = line.replace("test ", "").replace(" ... FAILED", "");
            self.test_results.push(TestResult {
                name,
                status: TestStatus::Failed,
                details: "".to_string(),
            });
            self.failed += 1;
            self.total += 1;
        }

        // Keep a rolling log
        self.output_log.push(line);
        if self.output_log.len() > 100 {
            self.output_log.remove(0);
        }
    }
}

pub fn run_dashboard(_args: &[String]) -> Result<()> {
    // Setup terminal
    enable_raw_mode()?;
    let mut stdout = std::io::stdout();
    execute!(stdout, EnterAlternateScreen)?;
    let backend = CrosstermBackend::new(stdout);
    let mut terminal = Terminal::new(backend)?;

    // Channels
    let (tx, rx) = mpsc::channel();
    let tick_rate = Duration::from_millis(100);

    // Spawn Input Thread
    let tx_input = tx.clone();
    thread::spawn(move || {
        loop {
            if event::poll(Duration::from_millis(50)).unwrap() {
                if let Event::Key(key) = event::read().unwrap() {
                    if key.kind == KeyEventKind::Press {
                        if tx_input.send(DashboardEvent::Input(key)).is_err() {
                            return;
                        }
                    }
                }
            }
        }
    });

    // Spawn Tick Thread
    let tx_tick = tx.clone();
    thread::spawn(move || {
        loop {
            thread::sleep(tick_rate);
            if tx_tick.send(DashboardEvent::Tick).is_err() {
                return;
            }
        }
    });

    // Spawn Test Runner Thread
    let tx_log = tx.clone();
    thread::spawn(move || {
        let mut cmd = Command::new("cargo")
            .arg("test")
            .arg("--")
            .arg("--nocapture") // Important to see output in real-time
            .stdout(Stdio::piped())
            .stderr(Stdio::piped()) // Capture stderr too
            .spawn()
            .expect("Failed to spawn cargo test");

        if let Some(stdout) = cmd.stdout.take() {
            let reader = BufReader::new(stdout);
            for line in reader.lines() {
                if let Ok(l) = line {
                    let _ = tx_log.send(DashboardEvent::TestLine(l));
                }
            }
        }
    });

    // App Loop
    let mut app = App::new();
    let mut should_quit = false;

    while !should_quit {
        terminal.draw(|f| ui(f, &mut app))?;

        match rx.recv()? {
            DashboardEvent::Input(key) => match key.code {
                KeyCode::Char('q') => should_quit = true,
                KeyCode::Down => {
                    if app.scroll < app.test_results.len().saturating_sub(1) {
                        app.scroll += 1;
                    }
                }
                KeyCode::Up => {
                    if app.scroll > 0 {
                        app.scroll -= 1;
                    }
                }
                _ => {}
            },
            DashboardEvent::TestLine(line) => app.on_log(line),
            DashboardEvent::Tick => app.on_tick(),
        }
    }

    // Restore terminal
    disable_raw_mode()?;
    execute!(terminal.backend_mut(), LeaveAlternateScreen)?;
    terminal.show_cursor()?;

    Ok(())
}

fn ui(f: &mut Frame, app: &mut App) {
    let chunks = Layout::default()
        .direction(Direction::Vertical)
        .constraints([
            Constraint::Length(3), // Header
            Constraint::Min(0),    // Main (List + Details)
            Constraint::Length(8), // Log
            Constraint::Length(1), // Footer
        ])
        .split(f.area());

    // Header
    let title = Paragraph::new(format!(
        "Parity Dashboard | Total: {} | Passed: {} | Failed: {}",
        app.total, app.passed, app.failed
    ))
    .block(
        Block::default()
            .borders(Borders::ALL)
            .title("PyCandle Status"),
    )
    .style(Style::default().fg(Color::Cyan));
    f.render_widget(title, chunks[0]);

    // Main Content Split
    let main_chunks = Layout::default()
        .direction(Direction::Horizontal)
        .constraints([Constraint::Percentage(40), Constraint::Percentage(60)])
        .split(chunks[1]);

    // --- List Widget (Left) ---
    let items: Vec<ListItem> = app
        .test_results
        .iter()
        .enumerate()
        .skip(app.scroll.saturating_sub(10)) // Simple pseudo-windowing
        .take(50)
        .map(|(i, res)| {
            let style = match res.status {
                TestStatus::Passed => Style::default().fg(Color::Green),
                TestStatus::Failed => Style::default().fg(Color::Red),
                TestStatus::Running => Style::default().fg(Color::Yellow),
            };
            let icon = match res.status {
                TestStatus::Passed => "",
                TestStatus::Failed => "",
                TestStatus::Running => "",
            };

            let prefix = if i == app.scroll { "> " } else { "  " };
            ListItem::new(format!("{}{}{}", prefix, icon, res.name)).style(if i == app.scroll {
                style.add_modifier(Modifier::BOLD | Modifier::REVERSED)
            } else {
                style
            })
        })
        .collect();

    let list_title = if app.test_results.is_empty() {
        "Running Tests..."
    } else {
        "Tests"
    };
    let list = List::new(items).block(Block::default().borders(Borders::ALL).title(list_title));
    f.render_widget(list, main_chunks[0]);

    // --- Details Widget (Right) ---
    // Try to find matching parity result for the selected test
    let selected_test = app.test_results.get(app.scroll);

    let details_block = Block::default().borders(Borders::ALL).title("Details");
    let inner = details_block.inner(main_chunks[1]);
    f.render_widget(details_block, main_chunks[1]);

    let details_layout = Layout::default()
        .direction(Direction::Vertical)
        .constraints([Constraint::Length(5), Constraint::Min(0)])
        .split(inner);

    if let Some(test) = selected_test {
        // Find result by fuzzy matching name
        let matched_result = app.parity_results.values().find(|r| {
            let parts: Vec<&str> = r.name.split('.').collect();
            if parts.len() >= 2 {
                test.name.contains(parts[parts.len() - 1])
                    && test.name.contains(parts[parts.len() - 2])
            } else {
                test.name.contains(&r.name)
            }
        });

        if let Some(res) = matched_result {
            // Stats
            let status_line = Line::from(vec![
                Span::raw(format!("Layer: {}\nStatus: ", res.name)),
                if res.passed {
                    Span::styled("PASS", Style::default().fg(Color::Green))
                } else {
                    Span::styled("FAIL", Style::default().fg(Color::Red))
                },
                Span::raw(format!(
                    "\nMSE: {:.2e}\nCosSim: {:.6}",
                    res.mse, res.cosine_sim
                )),
            ]);

            f.render_widget(Paragraph::new(status_line), details_layout[0]);

            // Heatmap
            if let Some(heatmap) = &res.heatmap {
                // Render 8x8 heatmap
                if heatmap.len() == 64 {
                    // Normalize for coloring
                    let max_val = heatmap.iter().cloned().fold(0.0, f32::max);

                    let canvas = Canvas::default()
                        .block(
                            Block::default()
                                .borders(Borders::ALL)
                                .title("Error Heatmap (8x8)"),
                        )
                        .x_bounds([0.0, 8.0])
                        .y_bounds([0.0, 8.0])
                        .paint(move |ctx| {
                            for r in 0..8 {
                                for c in 0..8 {
                                    let idx = r * 8 + c;
                                    let val = heatmap[idx];
                                    let intensity = if max_val > 0.0 { val / max_val } else { 0.0 };

                                    // Color ramp: Black -> Blue -> Red
                                    let color = if intensity < 0.2 {
                                        Color::DarkGray
                                    } else if intensity < 0.5 {
                                        Color::Blue
                                    } else if intensity < 0.8 {
                                        Color::Magenta
                                    } else {
                                        Color::Red
                                    };

                                    // Draw 1x1 rectangle
                                    // r=0 is first row (top), so map to y=7
                                    ctx.draw(&Rectangle {
                                        x: c as f64,
                                        y: 7.0 - r as f64,
                                        width: 1.0,
                                        height: 1.0,
                                        color,
                                    });
                                }
                            }
                        });
                    f.render_widget(canvas, details_layout[1]);
                }
            } else if !res.passed {
                f.render_widget(Paragraph::new("No heatmap available."), details_layout[1]);
            }
        } else {
            f.render_widget(
                Paragraph::new("No trace data found for this test."),
                details_layout[0],
            );
        }
    }

    // Footer
    let footer = Paragraph::new("Press 'q' to quit | '/' to scroll")
        .style(Style::default().fg(Color::Gray));
    f.render_widget(footer, chunks[3]);

    // Log output (Raw)
    let log_items: Vec<ListItem> = app
        .output_log
        .iter()
        .rev()
        .take(8)
        .rev()
        .map(|l| ListItem::new(l.clone()).style(Style::default().fg(Color::DarkGray)))
        .collect();

    let log_box =
        List::new(log_items).block(Block::default().borders(Borders::ALL).title("Raw Output"));
    f.render_widget(log_box, chunks[2]);
}
</file>

<file path="crates/pycandle/src/init.rs">
use anyhow::{Context, Result};
use colored::Colorize;
use std::fs;
use std::path::Path;

const RECORDER_TEMPLATE: &str = r#"import torch
import sys
import os

# Try to import pycandle spy. 
# in a real setup this would be installed, but for now we look in relative paths common in this workspace.
try:
    from pycandle.spy import GoldenRecorder
except ImportError:
    # Add potential fallback paths
    possible_paths = ["py", "../py", "../../py"]
    for p in possible_paths:
        if os.path.exists(os.path.join(p, "spy.py")):
            sys.path.append(p)
            break
    from spy import GoldenRecorder

# TODO: Import your model class
# from my_project.model import MyModel

def main():
    print(" Initializing model configuration...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   Device: {device}")

    # TODO: Instantiate your model
    # model = MyModel().to(device)
    # model.eval()

    # TODO: Create dummy input matching your model's requirement
    # dummy_input = torch.randn(1, 3, 224, 224).to(device)

    print(" Starting recording...")
    recorder = GoldenRecorder(output_dir="traces")
    
    # TODO: Run the forward pass with the recorder
    # recorder.record(model, dummy_input)
    
    # Save the trace
    name = "debug_run"
    recorder.save(name)
    print(f" Recording saved to traces/{name}")

if __name__ == "__main__":
    main()
"#;

const TEST_TEMPLATE: &str = r#"#[cfg(test)]
mod tests {
    use anyhow::Result;
    // use super::*; // Import your model

    #[test]
    fn test_parity() -> Result<()> {
        // TODO: Load the checker
        // let device = candle_core::Device::Cpu;
        // let checker = pycandle_core::PyChecker::load("debug_run", "traces/", &device)?;
        
        // TODO: Load your model and run forward pass
        // let model = MyModel::load(..., Some(checker))?;
        // let output = model.forward(&input)?;

        Ok(())
    }
}
"#;

pub fn run_init(name: Option<String>) -> Result<()> {
    println!("{}", " PyCandle Project Initialization".bold().green());

    // 1. Create recorder.py
    let recorder_path = Path::new("recorder.py");
    if recorder_path.exists() {
        println!("   {} recorder.py already exists, skipping.", "".yellow());
    } else {
        fs::write(recorder_path, RECORDER_TEMPLATE).context("Failed to write recorder.py")?;
        println!("   {} Created recorder.py", "".green());
    }

    // 2. Create tests directory and parity test if requested
    let tests_dir = Path::new("tests");
    if !tests_dir.exists() {
        fs::create_dir(tests_dir).ok(); // failure ok, maybe we are not in root
    }

    let test_path = tests_dir.join("parity.rs");
    if tests_dir.exists() && !test_path.exists() {
        fs::write(&test_path, TEST_TEMPLATE).context("Failed to write tests/parity.rs")?;
        println!("   {} Created tests/parity.rs", "".green());
    } else {
        println!(
            "   {} tests/parity.rs already exists (or tests/ missing), skipping.",
            "".yellow()
        );
    }

    println!("\nNext steps:");
    println!("1. Edit {} to import your model.", "recorder.py".bold());
    println!(
        "2. Run {} to capture traces.",
        "pycandle record --script recorder.py --name debug_run".bold()
    );
    println!(
        "3. Run {} to generate Rust code.",
        "pycandle codegen ...".bold()
    );

    Ok(())
}
</file>

<file path="crates/pycandle/src/todos.rs">
// TODO extraction and management for generated code
use regex::Regex;
use serde::Serialize;
use std::collections::HashMap;

#[derive(Serialize, Debug)]
pub struct TodoItem {
    pub line: usize,
    pub module_type: String,
    pub field_name: String,
    pub context: String,
    pub suggestion: String,
}

#[derive(Serialize, Debug)]
pub struct TodoReport {
    pub file: String,
    pub total: usize,
    pub by_type: HashMap<String, usize>,
    pub todos: Vec<TodoItem>,
}

/// Extract TODO markers from generated Rust code
pub fn extract_todos(content: &str) -> Vec<TodoItem> {
    let mut todos = Vec::new();

    // Match: let field_name = todo!("Implement initialization for ModuleType");
    let re = Regex::new(r#"let\s+(\w+)\s*=\s*todo!\("Implement initialization for (\w+)"\)"#)
        .expect("Invalid regex");

    for (line_num, line) in content.lines().enumerate() {
        if let Some(caps) = re.captures(line) {
            let field_name = caps.get(1).unwrap().as_str().to_string();
            let module_type = caps.get(2).unwrap().as_str().to_string();

            todos.push(TodoItem {
                line: line_num + 1,
                field_name,
                module_type: module_type.clone(),
                context: line.trim().to_string(),
                suggestion: get_implementation_hint(&module_type),
            });
        }
    }

    todos
}

/// Get implementation hint for a module type
pub fn get_implementation_hint(module_type: &str) -> String {
    match module_type {
        "LSTM" => r#"LSTM::load(vb.pp("field"), input_size, hidden_size, num_layers)?"#.to_string(),
        "BatchNorm1d" => r#"BatchNorm1d::load(vb.pp("field"), num_features)?"#.to_string(),
        "BatchNorm2d" => r#"BatchNorm2d::load(vb.pp("field"), num_features)?"#.to_string(),
        "Snake" => r#"Snake::load(vb.pp("field"), in_features)?"#.to_string(),
        "ReLU" => "ReLU".to_string(),
        "Sigmoid" => "Sigmoid".to_string(),
        "ELU" => "ELU::new(1.0)".to_string(),
        "Dropout" => "// Dropout is a no-op at inference time".to_string(),
        "Conv1D" => r#"// HuggingFace Conv1D: implement as Linear with transpose"#.to_string(),
        "NewGELUActivation" => "GELU // or x.gelu_erf()".to_string(),
        _ => format!("// Manual implementation needed for {}", module_type),
    }
}

/// Generate a report from extracted TODOs
pub fn generate_report(file_path: &str, todos: Vec<TodoItem>) -> TodoReport {
    let mut by_type: HashMap<String, usize> = HashMap::new();
    for todo in &todos {
        *by_type.entry(todo.module_type.clone()).or_default() += 1;
    }

    TodoReport {
        file: file_path.to_string(),
        total: todos.len(),
        by_type,
        todos,
    }
}
</file>

<file path="docs/meta_trace_guide.md">
# PyCandle Meta-Trace Strategy

The **Meta-Trace Strategy** is the recommended SOP for porting large deep learning models (e.g., Transformers, LLMs) to Candle, especially on machines with limited RAM (e.g., 16GB RAM / 4GB available).

## The Problem: Paging File Errors
Loading weight files directly into PyTorch (e.g., 1.8GB + intermediate allocations) often exhausts system memory, leading to `OSError: The paging file is too small`.

## The Solution: Record Architecture on `meta`
Instead of loading weights into memory, we initialize the model on the PyTorch `meta` device. This records the **shapes**, **parameters**, and **computation graph** without allocating any actual weight buffers.

### Step 1: Initialize on Meta Device
Update your recording script to use the `meta` device.

```python
import torch
from py.spy import GoldenRecorder
from my_model import MyLargeModel

device = "meta"
with torch.device(device):
    model = MyLargeModel()
model.eval()

# Dummy inputs must also be on meta
dummy_input = torch.randn(1, 128, model.dim, device=device)

recorder = GoldenRecorder(output_dir="pycandle_trace")
recorder.record(model, dummy_input)
recorder.save("my_large_model_meta")
```

### Step 2: Generate Rust Code
Run the `pycandle codegen` as usual. The manifest contains everything needed to define the Rust structs.

```bash
cargo run -- codegen --manifest pycandle_trace/my_large_model_meta_manifest.json --out generated_model.rs
```

### Step 3: Stream-Extract Weights
Since you didn't record weights, your `trace.safetensors` will be empty or missing tensors. Use a specialized extraction script to map weights from the original checkpoint directly to the manifest-compatible keys.

```python
from safetensors.torch import load_file, save_file
# Load only what manifests says we need
# Rename keys to match manifest
# Save to a new, minimal weights file
```

## Benefits
- **Zero Memory Consumption**: Tracing happens in milliseconds with no RAM pressure.
- **Permanent Solution**: Works for models of any size (7B, 70B+) as long as the architecture fits in memory.
- **Power User DX**: Separates architecture capture from weight management.
</file>

<file path="docs/PORTING_SOP.md">
# PyCandle Porting SOP

This document outlines the Standard Operating Procedure (SOP) for porting PyTorch models to Rust/Candle using the PyCandle framework.

## 1. Project Setup
Initialize a new porting project. This generates the necessary boilerplate for recording and parity testing.

```bash
# In your workspace root
pycandle init --name <RunName>
```

**What this does:**
- Creates `recorder.py`: A standard PyTorch recording script tailored for your model.
- Creates `tests/main.rs`: A standard integration test harness for parity verification.

## 2. Model Wrapping (Python)
Edit the generated `recorder.py` to import and instantiate your specific PyTorch model.

```python
# recorder.py
from my_model_source import MyModel  # <--- Import your model

model = MyModel(...)
input_tensor = torch.randn(...)
```

## 3. Recording Traces
Run the recorder to capture the Golden Trace (activations, weights, and config).

```bash
# Uses uv under the hood to manage dependencies
pycandle record --script recorder.py --name <RunName>
```

*Output:* `traces/<RunName>/` containing `.safetensors` and `_manifest.json`.

## 4. Codegen & Analysis
Analyze the trace to see what layers are supported and generate the Rust code.

```bash
# Analyze first
pycandle codegen --manifest traces/<RunName>/_manifest.json --analyze-only

# Generate Rust code
pycandle codegen --manifest traces/<RunName>/_manifest.json --out crates/my-model/src/model.rs --model MyModel
```

## 5. Parity Verification
Run the generated test harness to verify that your Rust implementation matches the PyTorch golden record bit-for-bit.

```bash
cargo test
```

## 6. Iterative Refinement
If `cargo test` fails or parity is low:
1.  Use `pycandle dashboard` to visualize the error.
2.  Fix the Rust implementation.
3.  Re-run `cargo test`.
</file>

<file path="dummy_manifest.json">
{
    "layer1": {
        "name": "layer1",
        "module_type": "Linear",
        "input_shapes": [
            [
                1,
                10
            ]
        ],
        "output_shapes": [
            [
                1,
                20
            ]
        ],
        "parameters": [],
        "is_leaf": true,
        "config": {}
    },
    "layer2": {
        "name": "layer2",
        "module_type": "ReLU",
        "input_shapes": [
            [
                1,
                20
            ]
        ],
        "output_shapes": [
            [
                1,
                20
            ]
        ],
        "parameters": [],
        "is_leaf": true,
        "config": {}
    },
    "layer3": {
        "name": "layer3",
        "module_type": "Linear",
        "input_shapes": [
            [
                1,
                20
            ]
        ],
        "output_shapes": [
            [
                1,
                30
            ]
        ],
        "parameters": [],
        "is_leaf": true,
        "config": {}
    },
    "layer4": {
        "name": "layer4",
        "module_type": "Sigmoid",
        "input_shapes": [
            [
                1,
                30
            ]
        ],
        "output_shapes": [
            [
                1,
                30
            ]
        ],
        "parameters": [],
        "is_leaf": true,
        "config": {}
    }
}
</file>

<file path="gen_dummy_results.rs">
use serde::Serialize;
use std::fs::OpenOptions;
use std::io::Write;

#[derive(Serialize)]
struct Result {
    name: String,
    mse: f32,
    max_diff: f32,
    cosine_sim: f32,
    passed: bool,
}

fn main() {
    let results = vec![
        Result {
            name: "layer1.out.0".to_string(),
            mse: 1e-10,
            max_diff: 1e-5,
            cosine_sim: 1.0,
            passed: true,
        },
        Result {
            name: "layer2.out.0".to_string(),
            mse: 1e-8,
            max_diff: 1e-4,
            cosine_sim: 0.9999,
            passed: true,
        },
        Result {
            name: "layer3.out.0".to_string(),
            mse: 0.05,
            max_diff: 0.1,
            cosine_sim: 0.95,
            passed: false,
        }, // Drift!
        Result {
            name: "layer4.out.0".to_string(),
            mse: 0.2,
            max_diff: 0.5,
            cosine_sim: 0.8,
            passed: false,
        },
    ];

    let mut file = OpenOptions::new()
        .create(true)
        .write(true)
        .truncate(true)
        .open("verification_results.jsonl")
        .unwrap();

    for r in results {
        writeln!(file, "{}", serde_json::to_string(&r).unwrap()).unwrap();
    }

    println!("Generated verification_results.jsonl");
}
</file>

<file path="generated_hints.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct Config {
    pub hidden_dim: usize, // 64
    pub vocab_size: usize, // 64
}

pub struct MyModel {
    pub embedding: Embedding,
    pub linear: Linear,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(cfg: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let embedding = candle_nn::embedding(cfg.vocab_size, cfg.hidden_dim, vb.pp("embedding"))?;
        let linear = { let w = vb.pp("linear").get((cfg.hidden_dim, cfg.hidden_dim), "weight")?.t()?; let b = Some(vb.pp("linear").get(cfg.hidden_dim, "bias")?); Linear::new(w, b) };

        Ok(Self {
            embedding,
            linear,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: embedding
        x = self.embedding.forward(&x)?;
        py_check!(self.checker, "embedding", &x);

        // Layer: linear
        x = self.linear.forward(&x)?;
        py_check!(self.checker, "linear", &x);

        Ok(x)
    }
}
</file>

<file path="generated_symbolic.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct Config {
    pub hidden_dim: usize, // 768
    pub vocab_size: usize, // 50257
}

pub struct MyTestModel {
    pub embedding: Embedding,
    pub linear1: Linear,
    pub linear2: Linear,
    pub ln: LayerNorm,
    pub checker: Option<PyChecker>,
}

impl MyTestModel {
    pub fn load(cfg: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let embedding = candle_nn::embedding(cfg.vocab_size, cfg.hidden_dim, vb.pp("embedding"))?;
        let linear1 = candle_nn::linear(cfg.hidden_dim, 2048, vb.pp("linear1"))?;
        let linear2 = candle_nn::linear(2048, cfg.hidden_dim, vb.pp("linear2"))?;
        let ln = candle_nn::layer_norm(768, candle_nn::LayerNormConfig { eps: 1.0e-5, ..Default::default() }, vb.pp("ln"))?;

        Ok(Self {
            embedding,
            linear1,
            linear2,
            ln,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();

        // Layer: embedding
        x = self.embedding.forward(&x)?;
        py_check!(self.checker, "embedding", &x);

        // Layer: linear1
        x = self.linear1.forward(&x)?;
        py_check!(self.checker, "linear1", &x);

        // Layer: linear2
        x = self.linear2.forward(&x)?;
        py_check!(self.checker, "linear2", &x);

        // Layer: ln
        x = self.ln.forward(&x)?;
        py_check!(self.checker, "ln", &x);

        Ok(x)
    }
}
</file>

<file path="py/.python-version">
3.11
</file>

<file path="py/dag_model.py">
import torch
import torch.nn as nn
from spy import GoldenRecorder

class ComplexModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv1d(16, 32, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.fc = nn.Linear(32 * 10, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        # x is (B, 32, 10)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

if __name__ == "__main__":
    model = ComplexModel()
    recorder = GoldenRecorder()
    
    # Dummy input (B, C, T)
    x = torch.randn(1, 16, 10)
    
    recorder.record(model, x)
    recorder.trace_fx(model, x)
    recorder.save("complex_model", use_fx=True)
</file>

<file path="py/generated_residual.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct ResidualModel {
    pub bn1: BatchNorm1d,
    pub bn2: BatchNorm1d,
    pub conv1: Conv1d,
    pub conv2: Conv1d,
    pub relu: ReLU,
    pub relu_1: ReLU,
    pub checker: Option<PyChecker>,
}

impl ResidualModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let bn1 = BatchNorm1d::load(vb.pp("bn1"), 16)?;
        let bn2 = BatchNorm1d::load(vb.pp("bn2"), 16)?;
        let conv1 = candle_nn::conv1d(16, 16, 3, candle_nn::Conv1dConfig { stride: 1, padding: 1, ..Default::default() }, vb.pp("conv1"))?;
        let conv2 = candle_nn::conv1d(16, 16, 3, candle_nn::Conv1dConfig { stride: 1, padding: 1, ..Default::default() }, vb.pp("conv2"))?;
        let relu = ReLU;
        let relu_1 = ReLU;

        Ok(Self {
            bn1,
            bn2,
            conv1,
            conv2,
            relu,
            relu_1,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let x_conv1 = self.conv1.forward(&xs)?;
        py_check!(self.checker, "conv1", &x_conv1);
        let x_bn1 = self.bn1.forward(&x_conv1)?;
        py_check!(self.checker, "bn1", &x_bn1);
        let x_relu = self.relu.forward(&x_bn1)?;
        py_check!(self.checker, "relu", &x_relu);
        let x_conv2 = self.conv2.forward(&x_relu)?;
        py_check!(self.checker, "conv2", &x_conv2);
        let x_bn2 = self.bn2.forward(&x_conv2)?;
        py_check!(self.checker, "bn2", &x_bn2);
        let x_add = (&x_bn2 + &xs)?;
        let x_relu_1 = self.relu.forward(&x_add)?;
        py_check!(self.checker, "relu", &x_relu_1);
        Ok(x_relu_1)
    }
}
</file>

<file path="py/hello.py">
def main():
    print("Hello from pycandle-spy!")


if __name__ == "__main__":
    main()
</file>

<file path="py/onnx_to_fx.py">
# ONNX to FX Converter
import os
import sys
import argparse
import torch
import onnx
from onnx2torch import convert
from spy import GoldenRecorder

def main():
    parser = argparse.ArgumentParser(description="Convert ONNX model to PyCandle manifest via torch.fx")
    parser.add_argument("--onnx", type=str, required=True, help="Path to ONNX model")
    parser.add_argument("--name", type=str, required=True, help="Project name")
    parser.add_argument("--out", type=str, default="pycandle_trace", help="Output directory")
    
    args = parser.parse_args()
    
    print(f" Loading ONNX model from {args.onnx}...")
    onnx_model = onnx.load(args.onnx)
    
    print(" Converting ONNX to PyTorch...")
    torch_model = convert(onnx_model)
    torch_model.eval()
    
    # Try to infer input shape from ONNX model
    input_shape = [1, 3, 224, 224] # Default fallback
    if len(onnx_model.graph.input) > 0:
        dims = onnx_model.graph.input[0].type.tensor_type.shape.dim
        input_shape = [d.dim_value if d.dim_value > 0 else 1 for d in dims]
    
    print(f" Using input shape: {input_shape}")
    dummy_input = torch.randn(*input_shape)
    
    recorder = GoldenRecorder(output_dir=args.out)
    
    print(" Recording trace and FX graph...")
    # Record will also perform FX tracing if requested
    recorder.record(torch_model, dummy_input, trace_fx=True)
    
    print(f" Saving manifest and weights to {args.out}...")
    recorder.save(args.name, use_fx=True)
    
    # Save weights
    from safetensors.torch import save_file
    weight_path = os.path.join(args.out, f"{args.name}_weights.safetensors")
    # convert state_dict to use keys matching the manifest (which uses node names)
    # Actually, recorder.manifest has the mapping.
    # But for a simple ONNX converted model, state_dict keys often match node names if convert is clean.
    # Let's just save the state_dict for now.
    save_file(torch_model.state_dict(), weight_path)
    
    print(f" Conversion complete! You can now run:")
    print(f"   pycandle codegen --manifest {args.out}/{args.name}_manifest.json --out generated_{args.name}.rs")

if __name__ == "__main__":
    main()
</file>

<file path="py/test_hints.py">
import torch
import torch.nn as nn
from spy import GoldenRecorder

class HintsModel(nn.Module):
    def __init__(self):
        super().__init__()
        # Ambiguous: Both 64
        self.embedding = nn.Embedding(64, 64)
        self.linear = nn.Linear(64, 64)

    def forward(self, x):
        x = self.embedding(x)
        x = self.linear(x)
        return x

model = HintsModel()
recorder = GoldenRecorder(output_dir="test_trace_hints")
x = torch.randint(0, 64, (1, 10))
recorder.record(model, x)

# Provide hints to resolve ambiguity
hints = {
    "vocab_size": 64,
    "hidden_dim": 64
}

recorder.save("hints_test", hints=hints)
</file>

<file path="py/test_model.py">
import torch
import torch.nn as nn
from spy import GoldenRecorder

class SmallModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.fc = nn.Linear(16 * 10, 2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

if __name__ == "__main__":
    model = SmallModel()
    recorder = GoldenRecorder()
    
    # Dummy input (B, C, T)
    x = torch.randn(1, 1, 10)
    
    recorder.record(model, x)
    recorder.save("small_model")
</file>

<file path="py/weight_extractor.py">
import os
import sys
import json
import torch
from safetensors.torch import save_file
from typing import Dict, Any, Set

def extract_weights(checkpoint_path: str, manifest_path: str, output_path: str, mapper_path: str = None):
    """
    Extracts only the weights specified in the manifest from a PyTorch checkpoint.
    Supports .bin/.pt (Pickle) and .safetensors.
    """
    if not os.path.exists(manifest_path):
        print(f" Manifest not found: {manifest_path}")
        sys.exit(1)
        
    with open(manifest_path, 'r') as f:
        manifest = json.load(f)
    
    # Identify active parameters
    active_params: Set[str] = set()
    for name, meta in manifest.items():
        if name.startswith('_'): 
            continue
        if 'parameters' in meta:
            for p in meta['parameters']:
                active_params.add(f"{name}.{p}")
    
    print(f" Manifest contains {len(active_params)} active parameters.")
    
    # Load weights selectively
    weights: Dict[str, torch.Tensor] = {}
    
    if checkpoint_path.endswith('.safetensors'):
        from safetensors import safe_open
        with safe_open(checkpoint_path, framework="pt", device="cpu") as f:
            for key in f.keys():
                if key in active_params:
                    weights[key] = f.get_tensor(key)
    else:
        # Pickle-based (.bin, .pt, .pth)
        # We use weights_only=True for security and map_location='cpu' for memory
        try:
            state_dict = torch.load(checkpoint_path, map_location='cpu', weights_only=True)
            for k, v in state_dict.items():
                if k in active_params:
                    weights[k] = v
        except Exception as e:
            print(f" Failed to load checkpoint: {e}")
            # Fallback for older torch versions or complex pickles
            state_dict = torch.load(checkpoint_path, map_location='cpu')
            for k, v in state_dict.items():
                if k in active_params:
                    weights[k] = v

    if not weights:
        print(" No matching weights found in checkpoint!")
        # Print a few examples from the checkpoint if possible
        return

    # Optional renaming
    if mapper_path and os.path.exists(mapper_path):
        import re
        with open(mapper_path, 'r') as f:
            mappings = json.load(f)
        
        print(f" Applying {len(mappings)} renaming patterns...")
        renamed_weights = {}
        # Sort mappings by length of pattern (desc) or just alphabetical for consistency?
        # Typically we want deterministic order.
        sorted_patterns = sorted(mappings.items())
        
        for k, v in weights.items():
            new_k = k
            for pattern, replacement in sorted_patterns:
                new_k = re.sub(pattern, replacement, new_k)
            renamed_weights[new_k] = v
        weights = renamed_weights

    # Ensure directory exists
    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
    
    save_file(weights, output_path)
    print(f" Surgically extracted {len(weights)} weights to {output_path}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Surgically extract model weights.")
    parser.add_argument("--checkpoint", required=True, help="Path to PyTorch checkpoint (.bin, .pt, .safetensors)")
    parser.add_argument("--manifest", required=True, help="Path to manifest.json")
    parser.add_argument("--out", required=True, help="Output .safetensors path")
    parser.add_argument("--map", help="Optional JSON mapping file for renaming")
    args = parser.parse_args()
    
    extract_weights(args.checkpoint, args.manifest, args.out, args.map)
</file>

<file path="recorder.py">
import torch
import sys
import os

# Try to import pycandle spy. 
# in a real setup this would be installed, but for now we look in relative paths common in this workspace.
try:
    from pycandle.spy import GoldenRecorder
except ImportError:
    # Add potential fallback paths
    possible_paths = ["py", "../py", "../../py"]
    for p in possible_paths:
        if os.path.exists(os.path.join(p, "spy.py")):
            sys.path.append(p)
            break
    from spy import GoldenRecorder

# TODO: Import your model class
# from my_project.model import MyModel

def main():
    print(" Initializing model configuration...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   Device: {device}")

    # TODO: Instantiate your model
    # model = MyModel().to(device)
    # model.eval()

    # TODO: Create dummy input matching your model's requirement
    # dummy_input = torch.randn(1, 3, 224, 224).to(device)

    print(" Starting recording...")
    recorder = GoldenRecorder(output_dir="traces")
    
    # TODO: Run the forward pass with the recorder
    # recorder.record(model, dummy_input)
    
    # Save the trace
    name = "debug_run"
    recorder.save(name)
    print(f" Recording saved to traces/{name}")

if __name__ == "__main__":
    main()
</file>

<file path="specs/melspectrogram_parity.md">
# Walkthrough - MelSpectrogram Implementation

I have implemented and verified the `MelSpectrogram` operation in `pycandle-audio` with full parity against `torchaudio`.

## Changes

### `crates/pycandle-audio`

#### [lib.rs](file:///d:/pycandle/crates/pycandle-audio/src/lib.rs)
-   Implemented `MelSpectrogramConfig` with support for `HTK` and `Slaney` mel scales.
-   Implemented `MelNorm::Slaney` for area normalization.
-   Implemented `hz_to_mel` and `mel_to_hz` for both scales.
-   Implemented `get_mel_banks` to generate the Mel filterbank matrix.
-   Implemented `mel_spectrogram` (STFT + Power + Mel Filterbank).

## Verification Results

Verified against `torchaudio` using a Python script.

### Mel Filterbank Parity
-   **Max Diff:** `6.89e-08`
-   **Status:**  EXACT MATCH
-   this confirms the implementation of Slaney scale and area normalization is correct.

### End-to-End MelSpectrogram
-   **Max Diff:** `0.018` (approx `1e-5` relative error)
-   **Status:**  PASS (High Precision)
-   Differences are due to floating point variations between Rust's `realfft` and PyTorch's FFT backend (MKL/FFTW). The core logic is verified correct.

### STFT & Power
-   **STFT Max Diff:** `0.010`
-   **Power Max Diff:** `1.0` (approx `4e-6` relative error)
</file>

<file path="test_symbolic.py">
import torch
import torch.nn as nn
from spy import GoldenRecorder

class SmallModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.embedding = nn.Embedding(50257, 768)
        self.linear1 = nn.Linear(768, 2048)
        self.linear2 = nn.Linear(2048, 768)
        self.ln = nn.LayerNorm(768)

    def forward(self, x):
        x = self.embedding(x)
        x = self.linear1(x)
        x = torch.relu(x)
        x = self.linear2(x)
        x = self.ln(x)
        return x

model = SmallModel()
recorder = GoldenRecorder(output_dir="test_trace")
# Embedding input: (batch, seq)
x = torch.randint(0, 50257, (1, 10))
recorder.record(model, x)
recorder.save("symbolic_test")
</file>

<file path="test_trace_hints/hints_test_manifest.json">
{
    "embedding": {
        "name": "embedding",
        "module_type": "Embedding",
        "input_shapes": [
            [
                1,
                10
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                64
            ]
        ],
        "parameters": [
            "weight"
        ],
        "is_leaf": true,
        "config": {
            "num_embeddings": 64,
            "embedding_dim": 64
        }
    },
    "linear": {
        "name": "linear",
        "module_type": "Linear",
        "input_shapes": [
            [
                1,
                10,
                64
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                64
            ]
        ],
        "parameters": [
            "weight",
            "bias"
        ],
        "is_leaf": true,
        "config": {
            "in_features": 64,
            "out_features": 64,
            "bias": true,
            "weight_shape": [
                64,
                64
            ]
        }
    },
    "_symbolic_hints": {
        "vocab_size": 64,
        "hidden_dim": 64
    }
}
</file>

<file path="test_trace/symbolic_test_manifest.json">
{
    "embedding": {
        "name": "embedding",
        "module_type": "Embedding",
        "input_shapes": [
            [
                1,
                10
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                768
            ]
        ],
        "parameters": [
            "weight"
        ],
        "is_leaf": true,
        "config": {
            "num_embeddings": 50257,
            "embedding_dim": 768
        }
    },
    "linear1": {
        "name": "linear1",
        "module_type": "Linear",
        "input_shapes": [
            [
                1,
                10,
                768
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                2048
            ]
        ],
        "parameters": [
            "weight",
            "bias"
        ],
        "is_leaf": true,
        "config": {
            "in_features": 768,
            "out_features": 2048,
            "bias": true,
            "weight_shape": [
                2048,
                768
            ]
        }
    },
    "linear2": {
        "name": "linear2",
        "module_type": "Linear",
        "input_shapes": [
            [
                1,
                10,
                2048
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                768
            ]
        ],
        "parameters": [
            "weight",
            "bias"
        ],
        "is_leaf": true,
        "config": {
            "in_features": 2048,
            "out_features": 768,
            "bias": true,
            "weight_shape": [
                768,
                2048
            ]
        }
    },
    "ln": {
        "name": "ln",
        "module_type": "LayerNorm",
        "input_shapes": [
            [
                1,
                10,
                768
            ]
        ],
        "output_shapes": [
            [
                1,
                10,
                768
            ]
        ],
        "parameters": [
            "weight",
            "bias"
        ],
        "is_leaf": true,
        "config": {
            "normalized_shape": [
                768
            ],
            "eps": 1e-05
        }
    }
}
</file>

<file path="tests/quantization_drift.rs">
use candle_core::{Device, Tensor};
use pycandle_core::checker::LayerMeta; // Needed for mock manifest
use pycandle_core::{PyChecker, VerificationMode};
use std::collections::HashMap;

#[test]
fn test_quantization_drift() -> anyhow::Result<()> {
    let device = Device::Cpu;

    // 1. Create a dummy manifest
    let manifest_json = r#"{
        "layer_perfect": {
            "name": "layer_perfect", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        },
        "layer_drift_small": {
            "name": "layer_drift_small", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        },
        "layer_drift_large": {
            "name": "layer_drift_large", "module_type": "Linear", 
            "input_shapes": [], "output_shapes": [], "parameters": [], "is_leaf": true, "config": {} 
        }
    }"#;

    // Write dummy files for PyChecker::load
    std::fs::create_dir_all("test_trace_drift")?;
    std::fs::write("test_trace_drift/drift_run_manifest.json", manifest_json)?;

    // Create dummy golden tensors
    let t_perfect = Tensor::new(&[1.0f32, 2.0, 3.0], &device)?;
    let t_drift_small = Tensor::new(&[10.0f32, 20.0, 30.0], &device)?;
    let t_drift_large = Tensor::new(&[100.0f32, 200.0, 300.0], &device)?;

    let tensors_map: HashMap<String, Tensor> = HashMap::from([
        ("layer_perfect.out.0".to_string(), t_perfect.clone()),
        ("layer_drift_small.out.0".to_string(), t_drift_small.clone()),
        ("layer_drift_large.out.0".to_string(), t_drift_large.clone()),
    ]);
    candle_core::safetensors::save(&tensors_map, "test_trace_drift/drift_run_trace.safetensors")?;

    // 2. Load Checker in DriftTracking mode
    let checker = PyChecker::load("drift_run", "test_trace_drift", &device)?
        .with_mode(VerificationMode::DriftTracking);

    println!("Checking in mode: {:?}", checker.mode);

    // 3. Verify Layers

    // A) Perfect Match
    let res1 = checker.verify("layer_perfect", &t_perfect)?;
    assert!(res1.mse < 1e-6);

    // B) Small Drift (MSE = 1e-6, barely passing strict if atol=1e-4, but let's make it small enough)
    // Let's add noise: 1e-3. 1e-3^2 = 1e-6.
    let noise_small = Tensor::new(&[0.001f32, 0.001, 0.001], &device)?;
    let t_small_noisy = (&t_drift_small + noise_small)?;
    let res2 = checker.verify("layer_drift_small", &t_small_noisy)?;
    println!("Layer Small Drift MSE: {}", res2.mse);

    // C) Large Drift (MSE ~ 0.01) - Should fail in Strict, but pass here
    // Noise 0.1. 0.1^2 = 0.01. > 1e-4.
    let noise_large = Tensor::new(&[0.1f32, 0.1, 0.1], &device)?;
    let t_large_noisy = (&t_drift_large + noise_large)?;

    // This should NOT panic or return Err, unlike Strict mode
    let res3 = checker.verify("layer_drift_large", &t_large_noisy)?;
    println!("Layer Large Drift MSE: {}", res3.mse);

    assert!(
        res3.mse > checker.atol,
        "Expected large drift to exceed atol"
    );

    // 4. Print Report (Manual verify on console output)
    checker.print_drift_report();

    // Cleanup
    std::fs::remove_dir_all("test_trace_drift")?;

    Ok(())
}
</file>

<file path="tests/simple_onnx_parity.rs">
#[cfg(test)]
mod tests {
    use super::*;
    use candle_core::{Device, Tensor};
    use pycandle_core::{PyChecker, VerificationMode};
    use my_project::SimpleOnnxModel;
    use anyhow::Result;

    #[test]
    fn test_parity() -> Result<()> {
        // 1. Setup Device
        let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
        println!("Running on device: {:?}", device);

        // 2. Load Checker and Golden Trace
        // Assumes the trace directory is in the current project root
        let checker = PyChecker::load("simple_onnx", "pycandle_trace", &device)?
            .with_mode(VerificationMode::Strict);
        println!("Loaded checker with trace: {}", checker.name);

        // 3. Load Model
        // We use zeros VB as a placeholder; in a real parity test, 
        // you might want to load weights using pycandle weight tools.
        let vb = candle_nn::VarBuilder::zeros(candle_core::DType::F32, &device);
        let model = SimpleOnnxModel::load(vb, Some(checker.clone()))?;

        // 4. Load Inputs from Trace
        let trace_path = format!("pycandle_trace/simple_onnx_trace.safetensors", "simple_onnx");
        let tensors = candle_core::safetensors::load(&trace_path, &device)?;
        
        let x0 = tensors.get("model_input.0").context("Missing model_input.0")?.clone();


        // 5. Run Forward Pass & Verify
        let output = model.forward(&x0)?;
        checker.verify("node_relu", &output)?;
        println!(" Parity test passed for SimpleOnnxModel!");

        Ok(())
    }
}
</file>

<file path="tts_turbo_temp.py">
import os
import math
from dataclasses import dataclass
from pathlib import Path

import librosa
import torch
import perth
import pyloudnorm as ln

from safetensors.torch import load_file
from huggingface_hub import snapshot_download
from transformers import AutoTokenizer

from .models.t3 import T3
from .models.s3tokenizer import S3_SR
from .models.s3gen import S3GEN_SR, S3Gen
from .models.tokenizers import EnTokenizer
from .models.voice_encoder import VoiceEncoder
from .models.t3.modules.cond_enc import T3Cond
from .models.t3.modules.t3_config import T3Config
from .models.s3gen.const import S3GEN_SIL
import logging
logger = logging.getLogger(__name__)

REPO_ID = "ResembleAI/chatterbox-turbo"


def punc_norm(text: str) -> str:
    """
        Quick cleanup func for punctuation from LLMs or
        containing chars not seen often in the dataset
    """
    if len(text) == 0:
        return "You need to add some text for me to talk."

    # Capitalise first letter
    if text[0].islower():
        text = text[0].upper() + text[1:]

    # Remove multiple space chars
    text = " ".join(text.split())

    # Replace uncommon/llm punc
    punc_to_replace = [
        ("", ", "),
        (":", ","),
        ("", "-"),
        ("", "-"),
        (" ,", ","),
        ("", "\""),
        ("", "\""),
        ("", "'"),
        ("", "'"),
    ]
    for old_char_sequence, new_char in punc_to_replace:
        text = text.replace(old_char_sequence, new_char)

    # Add full stop if no ending punc
    text = text.rstrip(" ")
    sentence_enders = {".", "!", "?", "-", ","}
    if not any(text.endswith(p) for p in sentence_enders):
        text += "."

    return text


@dataclass
class Conditionals:
    """
    Conditionals for T3 and S3Gen
    - T3 conditionals:
        - speaker_emb
        - clap_emb
        - cond_prompt_speech_tokens
        - cond_prompt_speech_emb
        - emotion_adv
    - S3Gen conditionals:
        - prompt_token
        - prompt_token_len
        - prompt_feat
        - prompt_feat_len
        - embedding
    """
    t3: T3Cond
    gen: dict

    def to(self, device):
        self.t3 = self.t3.to(device=device)
        for k, v in self.gen.items():
            if torch.is_tensor(v):
                self.gen[k] = v.to(device=device)
        return self

    def save(self, fpath: Path):
        arg_dict = dict(
            t3=self.t3.__dict__,
            gen=self.gen
        )
        torch.save(arg_dict, fpath)

    @classmethod
    def load(cls, fpath, map_location="cpu"):
        if isinstance(map_location, str):
            map_location = torch.device(map_location)
        kwargs = torch.load(fpath, map_location=map_location, weights_only=True)
        return cls(T3Cond(**kwargs['t3']), kwargs['gen'])


class ChatterboxTurboTTS:
    ENC_COND_LEN = 15 * S3_SR
    DEC_COND_LEN = 10 * S3GEN_SR

    def __init__(
        self,
        t3: T3,
        s3gen: S3Gen,
        ve: VoiceEncoder,
        tokenizer: EnTokenizer,
        device: str,
        conds: Conditionals = None,
    ):
        self.sr = S3GEN_SR  # sample rate of synthesized audio
        self.t3 = t3
        self.s3gen = s3gen
        self.ve = ve
        self.tokenizer = tokenizer
        self.device = device
        self.conds = conds
        self.watermarker = perth.PerthImplicitWatermarker()

    @classmethod
    def from_local(cls, ckpt_dir, device) -> 'ChatterboxTurboTTS':
        ckpt_dir = Path(ckpt_dir)

        # Always load to CPU first for non-CUDA devices to handle CUDA-saved models
        if device in ["cpu", "mps"]:
            map_location = torch.device('cpu')
        else:
            map_location = None

        ve = VoiceEncoder()
        ve.load_state_dict(
            load_file(ckpt_dir / "ve.safetensors")
        )
        ve.to(device).eval()

        # Turbo specific hp
        hp = T3Config(text_tokens_dict_size=50276)
        hp.llama_config_name = "GPT2_medium"
        hp.speech_tokens_dict_size = 6563
        hp.input_pos_emb = None
        hp.speech_cond_prompt_len = 375
        hp.use_perceiver_resampler = False
        hp.emotion_adv = False

        t3 = T3(hp)
        t3_state = load_file(ckpt_dir / "t3_turbo_v1.safetensors")
        if "model" in t3_state.keys():
            t3_state = t3_state["model"][0]
        t3.load_state_dict(t3_state)
        del t3.tfmr.wte
        t3.to(device).eval()

        s3gen = S3Gen(meanflow=True)
        weights = load_file(ckpt_dir / "s3gen_meanflow.safetensors")
        s3gen.load_state_dict(
            weights, strict=True
        )
        s3gen.to(device).eval()

        tokenizer = AutoTokenizer.from_pretrained(ckpt_dir)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        if len(tokenizer) != 50276:
            print(f"WARNING: Tokenizer len {len(tokenizer)} != 50276")

        conds = None
        builtin_voice = ckpt_dir / "conds.pt"
        if builtin_voice.exists():
            conds = Conditionals.load(builtin_voice, map_location=map_location).to(device)

        return cls(t3, s3gen, ve, tokenizer, device, conds=conds)

    @classmethod
    def from_pretrained(cls, device) -> 'ChatterboxTurboTTS':
        # Check if MPS is available on macOS
        if device == "mps" and not torch.backends.mps.is_available():
            if not torch.backends.mps.is_built():
                print("MPS not available because the current PyTorch install was not built with MPS enabled.")
            else:
                print("MPS not available because the current MacOS version is not 12.3+ and/or you do not have an MPS-enabled device on this machine.")
            device = "cpu"

        local_path = snapshot_download(
            repo_id=REPO_ID,
            token=os.getenv("HF_TOKEN") or True,
            # Optional: Filter to download only what you need
            allow_patterns=["*.safetensors", "*.json", "*.txt", "*.pt", "*.model"]
        )

        return cls.from_local(local_path, device)

    def norm_loudness(self, wav, sr, target_lufs=-27):
        try:
            meter = ln.Meter(sr)
            loudness = meter.integrated_loudness(wav)
            gain_db = target_lufs - loudness
            gain_linear = 10.0 ** (gain_db / 20.0)
            if math.isfinite(gain_linear) and gain_linear > 0.0:
                wav = wav * gain_linear
        except Exception as e:
            print(f"Warning: Error in norm_loudness, skipping: {e}")

        return wav

    def prepare_conditionals(self, wav_fpath, exaggeration=0.5, norm_loudness=True):
        ## Load and norm reference wav
        s3gen_ref_wav, _sr = librosa.load(wav_fpath, sr=S3GEN_SR)

        assert len(s3gen_ref_wav) / _sr > 5.0, "Audio prompt must be longer than 5 seconds!"

        if norm_loudness:
            s3gen_ref_wav = self.norm_loudness(s3gen_ref_wav, _sr)

        ref_16k_wav = librosa.resample(s3gen_ref_wav, orig_sr=S3GEN_SR, target_sr=S3_SR)

        s3gen_ref_wav = s3gen_ref_wav[:self.DEC_COND_LEN]
        s3gen_ref_dict = self.s3gen.embed_ref(s3gen_ref_wav, S3GEN_SR, device=self.device)

        # Speech cond prompt tokens
        if plen := self.t3.hp.speech_cond_prompt_len:
            s3_tokzr = self.s3gen.tokenizer
            t3_cond_prompt_tokens, _ = s3_tokzr.forward([ref_16k_wav[:self.ENC_COND_LEN]], max_len=plen)
            t3_cond_prompt_tokens = torch.atleast_2d(t3_cond_prompt_tokens).to(self.device)

        # Voice-encoder speaker embedding
        ve_embed = torch.from_numpy(self.ve.embeds_from_wavs([ref_16k_wav], sample_rate=S3_SR))
        ve_embed = ve_embed.mean(axis=0, keepdim=True).to(self.device)

        t3_cond = T3Cond(
            speaker_emb=ve_embed,
            cond_prompt_speech_tokens=t3_cond_prompt_tokens,
            emotion_adv=exaggeration * torch.ones(1, 1, 1),
        ).to(device=self.device)
        self.conds = Conditionals(t3_cond, s3gen_ref_dict)

    def generate(
        self,
        text,
        repetition_penalty=1.2,
        min_p=0.00,
        top_p=0.95,
        audio_prompt_path=None,
        exaggeration=0.0,
        cfg_weight=0.0,
        temperature=0.8,
        top_k=1000,
        norm_loudness=True,
    ):
        if audio_prompt_path:
            self.prepare_conditionals(audio_prompt_path, exaggeration=exaggeration, norm_loudness=norm_loudness)
        else:
            assert self.conds is not None, "Please `prepare_conditionals` first or specify `audio_prompt_path`"

        if cfg_weight > 0.0 or exaggeration > 0.0 or min_p > 0.0:
            logger.warning("CFG, min_p and exaggeration are not supported by Turbo version and will be ignored.")

        # Norm and tokenize text
        text = punc_norm(text)
        text_tokens = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        text_tokens = text_tokens.input_ids.to(self.device)

        speech_tokens = self.t3.inference_turbo(
            t3_cond=self.conds.t3,
            text_tokens=text_tokens,
            temperature=temperature,
            top_k=top_k,
            top_p=top_p,
            repetition_penalty=repetition_penalty,
        )

        # Remove OOV tokens and add silence to end
        speech_tokens = speech_tokens[speech_tokens < 6561]
        speech_tokens = speech_tokens.to(self.device)
        silence = torch.tensor([S3GEN_SIL, S3GEN_SIL, S3GEN_SIL]).long().to(self.device)
        speech_tokens = torch.cat([speech_tokens, silence])

        wav, _ = self.s3gen.inference(
            speech_tokens=speech_tokens,
            ref_dict=self.conds.gen,
            n_cfm_timesteps=2,
        )
        wav = wav.squeeze(0).detach().cpu().numpy()
        watermarked_wav = self.watermarker.apply_watermark(wav, sample_rate=self.sr)
        return torch.from_numpy(watermarked_wav).unsqueeze(0)
</file>

<file path="verification_results.jsonl">
{"name":"layer1.out.0", "mse":1e-10, "max_diff":1e-5, "cosine_sim":1.0, "passed":true}
{"name":"layer2.out.0", "mse":1e-8, "max_diff":1e-4, "cosine_sim":0.9999, "passed":true}
{"name":"layer3.out.0", "mse":0.05, "max_diff":0.1, "cosine_sim":0.95, "passed":false}
{"name":"layer4.out.0", "mse":0.2, "max_diff":0.5, "cosine_sim":0.8, "passed":false}
</file>

<file path="crates/pycandle-audio/Cargo.toml">
[package]
name = "pycandle-audio"
description = "Audio ops for PyCandle: STFT, iSTFT, and padding with PyTorch parity"
version.workspace = true
edition.workspace = true
license.workspace = true

[dependencies]
candle-core.workspace = true
candle-nn.workspace = true
thiserror.workspace = true
realfft.workspace = true
num-complex.workspace = true
</file>

<file path="crates/pycandle-core/Cargo.toml">
[package]
name = "pycandle-core"
description = "Core library for PyCandle: PyChecker, layers, and codegen"
version.workspace = true
edition.workspace = true
license.workspace = true

[dependencies]
candle-core.workspace = true
candle-nn.workspace = true
safetensors.workspace = true
regex.workspace = true
serde.workspace = true
anyhow.workspace = true
serde_json.workspace = true
colored.workspace = true
thiserror.workspace = true
</file>

<file path="crates/pycandle-core/src/codegen/gpt2.rs">
//! GPT2 code generation helpers
//!
//! This module provides codegen utilities for HuggingFace GPT2 models.

use crate::LayerMeta;

/// Configuration extracted from GPT2 manifest
#[derive(Debug, Clone)]
pub struct GptConfig {
    pub vocab_size: usize,
    pub context_length: usize,
    pub emb_dim: usize,
    pub n_heads: usize,
    pub n_layers: usize,
    pub drop_rate: f32,
}

impl Default for GptConfig {
    fn default() -> Self {
        Self {
            vocab_size: 50257,
            context_length: 1024,
            emb_dim: 768,
            n_heads: 12,
            n_layers: 12,
            drop_rate: 0.1,
        }
    }
}

/// Check if module type is a GPT2 variant
pub fn is_gpt2_type(module_type: &str) -> bool {
    matches!(
        module_type,
        "GPT2Model" | "GPT2LMHeadModel" | "GPT2Block" | "GPT2Attention" | "GPT2MLP"
    )
}

/// Map GPT2 Python type to Candle type
pub fn map_type(py_type: &str) -> Option<String> {
    match py_type {
        "GPT2Model" | "GPT2LMHeadModel" => Some("gpt2::GPTModel".to_string()),
        "GPT2Block" => Some("gpt2::TransformerBlock".to_string()),
        "GPT2Attention" => Some("gpt2::MultiHeadAttention".to_string()),
        "GPT2MLP" => Some("gpt2::FeedForward".to_string()),
        _ => None,
    }
}

/// Extract GPT config from layer metadata
pub fn extract_config(meta: &LayerMeta) -> GptConfig {
    GptConfig {
        vocab_size: meta
            .config
            .get("vocab_size")
            .and_then(|v| v.as_u64())
            .unwrap_or(50257) as usize,
        context_length: meta
            .config
            .get("n_positions")
            .and_then(|v| v.as_u64())
            .unwrap_or(1024) as usize,
        emb_dim: meta
            .config
            .get("n_embd")
            .and_then(|v| v.as_u64())
            .unwrap_or(768) as usize,
        n_heads: meta
            .config
            .get("n_head")
            .and_then(|v| v.as_u64())
            .unwrap_or(12) as usize,
        n_layers: meta
            .config
            .get("n_layer")
            .and_then(|v| v.as_u64())
            .unwrap_or(12) as usize,
        drop_rate: meta
            .config
            .get("resid_pdrop")
            .and_then(|v| v.as_f64())
            .unwrap_or(0.1) as f32,
    }
}

/// Generate initialization code for GPT2 layer types
pub fn generate_init(
    layer_name: &str,
    meta: &LayerMeta,
    symbolic_dims: &std::collections::HashMap<String, usize>,
) -> Option<String> {
    let render_dim = |val: usize, preferred: &str| -> String {
        if !preferred.is_empty() {
            if let Some(&v) = symbolic_dims.get(preferred) {
                if v == val {
                    return format!("config.{}", preferred);
                }
            }
        }
        for (name, &v) in symbolic_dims {
            if v == val {
                return format!("config.{}", name);
            }
        }
        val.to_string()
    };

    match meta.module_type.as_str() {
        "GPT2Model" | "GPT2LMHeadModel" => {
            let config_val = extract_config(meta);
            let vocab_size = render_dim(config_val.vocab_size, "vocab_size");
            let context_length = render_dim(config_val.context_length, "context_length");
            let emb_dim = render_dim(config_val.emb_dim, "hidden_dim");
            let n_heads = render_dim(config_val.n_heads, "n_head");
            let n_layers = render_dim(config_val.n_layers, "n_layers");

            Some(format!(
                r#"{{
                let gpt_cfg = pycandle_core::gpt2::Config {{
                    vocab_size: {},
                    context_length: {},
                    emb_dim: {},
                    n_heads: {},
                    n_layers: {},
                    drop_rate: {:.1},
                    qkv_bias: false,
                }};
                pycandle_core::gpt2::GPTModel::new(gpt_cfg, &vb.pp("{}"))?
            }}"#,
                vocab_size,
                context_length,
                emb_dim,
                n_heads,
                n_layers,
                config_val.drop_rate,
                layer_name
            ))
        }
        "GPT2Block" => Some(format!(
            "pycandle_core::gpt2::TransformerBlock::new(gpt2_cfg, &vb.pp(\"{}\"))?",
            layer_name
        )),
        "GPT2Attention" => {
            let dim_val = meta
                .config
                .get("n_embd")
                .and_then(|v| v.as_u64())
                .unwrap_or(768) as usize;
            let heads_val = meta
                .config
                .get("n_head")
                .and_then(|v| v.as_u64())
                .unwrap_or(12) as usize;
            let dim = render_dim(dim_val, "hidden_dim");
            let heads = render_dim(heads_val, "n_head");

            Some(format!(
                "pycandle_core::gpt2::MultiHeadAttention::new({}, {}, 0.1, {}, false, &vb.pp(\"{}\"))?",
                dim, dim, heads, layer_name
            ))
        }
        "GPT2MLP" => Some(format!(
            "pycandle_core::gpt2::FeedForward::new(gpt2_cfg, &vb.pp(\"{}\"))?",
            layer_name
        )),
        _ => None,
    }
}
</file>

<file path="crates/pycandle-core/src/layers.rs">
//! Neural network layer implementations for Candle
//!
//! These provide PyTorch-compatible implementations that Candle doesn't have built-in.

use candle_nn::Module;

use candle_core::{IndexOp, Result, Tensor};

// ============================================================================
// Activation Functions
// ============================================================================

/// ReLU activation: max(0, x)
pub struct ReLU;
impl ReLU {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x.relu()
    }
}

/// GELU activation (Gaussian Error Linear Unit)
pub struct GELU;
impl GELU {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x.gelu_erf()
    }
}

/// Sigmoid activation: 1 / (1 + exp(-x))
pub struct Sigmoid;
impl Sigmoid {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        candle_nn::ops::sigmoid(x)
    }
}

/// Tanh activation
pub struct Tanh;
impl Tanh {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x.tanh()
    }
}

/// ELU activation: x if x > 0, else alpha * (exp(x) - 1)
pub struct ELU {
    pub alpha: f64,
}
impl ELU {
    pub fn new(alpha: f64) -> Self {
        Self { alpha }
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x.elu(self.alpha)
    }
}

/// LeakyReLU activation: x if x > 0, else negative_slope * x
pub struct LeakyReLU {
    pub negative_slope: f64,
}
impl LeakyReLU {
    pub fn new(negative_slope: f64) -> Self {
        Self { negative_slope }
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        // leaky_relu: max(0, x) + negative_slope * min(0, x)
        let zeros = x.zeros_like()?;
        let pos = x.maximum(&zeros)?;
        let neg = x.minimum(&zeros)?;
        pos + (neg * self.negative_slope)?
    }
}

/// Snake activation: x + sin(x)/
/// Used in neural vocoders like BigVGAN
pub struct Snake {
    pub alpha: Tensor,
}
impl Snake {
    pub fn load(vb: candle_nn::VarBuilder, in_features: usize) -> Result<Self> {
        let alpha = vb
            .get((in_features,), "alpha")
            .or_else(|_| vb.get((1, in_features, 1), "alpha"))?;
        let alpha = alpha.reshape((1, in_features, 1))?;
        Ok(Self { alpha })
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        // x: (B, C, T), alpha: (1, C, 1)
        let ax = x.broadcast_mul(&self.alpha)?;
        let sin_ax = ax.sin()?;
        let sin_sq = sin_ax.sqr()?;
        x + sin_sq.broadcast_div(&self.alpha)?
    }
}

/// Mish activation: x * tanh(softplus(x))
pub struct Mish;
impl Mish {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        // Mish(x) = x * tanh(softplus(x))
        // softplus(x) = ln(1 + exp(x))
        let sp = (x.exp()? + 1.0)?.log()?;
        x.broadcast_mul(&sp.tanh()?)
    }
}

/// SiLU / Swish activation: x * sigmoid(x)
pub struct SiLU;
impl SiLU {
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x * candle_nn::ops::sigmoid(x)?
    }
}

// ============================================================================
// Normalization Layers
// ============================================================================

/// BatchNorm1d for inference (uses running statistics)
/// Input: (B, C, T) or (B, C)
pub struct BatchNorm1d {
    pub weight: Tensor, // gamma
    pub bias: Tensor,   // beta
    pub running_mean: Tensor,
    pub running_var: Tensor,
    pub eps: f64,
}

impl BatchNorm1d {
    pub fn load(vb: candle_nn::VarBuilder, num_features: usize) -> Result<Self> {
        let weight = vb.get((num_features,), "weight")?;
        let bias = vb.get((num_features,), "bias")?;
        let running_mean = vb.get((num_features,), "running_mean")?;
        let running_var = vb.get((num_features,), "running_var")?;
        Ok(Self {
            weight,
            bias,
            running_mean,
            running_var,
            eps: 1e-5,
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        // x: (B, C, T) for 1d or (B, C)
        // Normalize: (x - mean) / sqrt(var + eps) * weight + bias
        let ndim = x.dims().len();
        let (mean, var, weight, bias) = if ndim == 3 {
            // (B, C, T) - unsqueeze to (1, C, 1)
            (
                self.running_mean.unsqueeze(0)?.unsqueeze(2)?,
                self.running_var.unsqueeze(0)?.unsqueeze(2)?,
                self.weight.unsqueeze(0)?.unsqueeze(2)?,
                self.bias.unsqueeze(0)?.unsqueeze(2)?,
            )
        } else {
            // (B, C) - unsqueeze to (1, C)
            (
                self.running_mean.unsqueeze(0)?,
                self.running_var.unsqueeze(0)?,
                self.weight.unsqueeze(0)?,
                self.bias.unsqueeze(0)?,
            )
        };

        let normalized = x
            .broadcast_sub(&mean)?
            .broadcast_div(&(var + self.eps)?.sqrt()?)?;
        normalized.broadcast_mul(&weight)?.broadcast_add(&bias)
    }
}

/// BatchNorm2d for inference (uses running statistics)
/// Input: (B, C, H, W)
pub struct BatchNorm2d {
    pub weight: Tensor,
    pub bias: Tensor,
    pub running_mean: Tensor,
    pub running_var: Tensor,
    pub eps: f64,
}

impl BatchNorm2d {
    pub fn load(vb: candle_nn::VarBuilder, num_features: usize) -> Result<Self> {
        let weight = vb.get((num_features,), "weight")?;
        let bias = vb.get((num_features,), "bias")?;
        let running_mean = vb.get((num_features,), "running_mean")?;
        let running_var = vb.get((num_features,), "running_var")?;
        Ok(Self {
            weight,
            bias,
            running_mean,
            running_var,
            eps: 1e-5,
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        // x: (B, C, H, W)
        // Reshape stats to (1, C, 1, 1) for broadcasting
        let mean = self.running_mean.unsqueeze(0)?.unsqueeze(2)?.unsqueeze(3)?;
        let var = self.running_var.unsqueeze(0)?.unsqueeze(2)?.unsqueeze(3)?;
        let weight = self.weight.unsqueeze(0)?.unsqueeze(2)?.unsqueeze(3)?;
        let bias = self.bias.unsqueeze(0)?.unsqueeze(2)?.unsqueeze(3)?;

        let normalized = x
            .broadcast_sub(&mean)?
            .broadcast_div(&(var + self.eps)?.sqrt()?)?;
        normalized.broadcast_mul(&weight)?.broadcast_add(&bias)
    }
}

// ============================================================================
// Recurrent Layers
// ============================================================================

/// LSTM layer (multi-layer, unidirectional)
/// Input: (B, T, input_size) if batch_first=true
/// Output: (output, (h_n, c_n))
pub struct LSTM {
    pub weight_ih: Vec<Tensor>, // One per layer: (4*hidden, input_size or hidden_size)
    pub weight_hh: Vec<Tensor>, // One per layer: (4*hidden, hidden_size)
    pub bias_ih: Vec<Tensor>,   // One per layer: (4*hidden,)
    pub bias_hh: Vec<Tensor>,   // One per layer: (4*hidden,)
    pub num_layers: usize,
    pub hidden_size: usize,
}

impl LSTM {
    pub fn load(
        vb: candle_nn::VarBuilder,
        input_size: usize,
        hidden_size: usize,
        num_layers: usize,
    ) -> Result<Self> {
        let mut weight_ih = Vec::new();
        let mut weight_hh = Vec::new();
        let mut bias_ih = Vec::new();
        let mut bias_hh = Vec::new();

        for layer in 0..num_layers {
            let in_size = if layer == 0 { input_size } else { hidden_size };
            weight_ih.push(vb.get((4 * hidden_size, in_size), &format!("weight_ih_l{}", layer))?);
            weight_hh.push(vb.get(
                (4 * hidden_size, hidden_size),
                &format!("weight_hh_l{}", layer),
            )?);
            bias_ih.push(vb.get((4 * hidden_size,), &format!("bias_ih_l{}", layer))?);
            bias_hh.push(vb.get((4 * hidden_size,), &format!("bias_hh_l{}", layer))?);
        }

        Ok(Self {
            weight_ih,
            weight_hh,
            bias_ih,
            bias_hh,
            num_layers,
            hidden_size,
        })
    }

    pub fn forward(&self, x: &Tensor) -> Result<(Tensor, (Tensor, Tensor))> {
        // x: (B, T, input_size) assuming batch_first
        let (batch, seq_len, _) = x.dims3()?;
        let device = x.device();
        let dtype = x.dtype();

        let h = Tensor::zeros((self.num_layers, batch, self.hidden_size), dtype, device)?;
        let c = Tensor::zeros((self.num_layers, batch, self.hidden_size), dtype, device)?;
        let mut output = x.clone();

        for layer in 0..self.num_layers {
            let mut h_t = h.i(layer)?;
            let mut c_t = c.i(layer)?;
            let mut outputs = Vec::new();

            for t in 0..seq_len {
                let x_t = output.i((.., t, ..))?;

                // gates = x @ W_ih.T + h @ W_hh.T + b_ih + b_hh
                let gates = x_t
                    .matmul(&self.weight_ih[layer].t()?)?
                    .broadcast_add(&h_t.matmul(&self.weight_hh[layer].t()?)?)?
                    .broadcast_add(&self.bias_ih[layer])?
                    .broadcast_add(&self.bias_hh[layer])?;

                // Split into i, f, g, o (each of size hidden_size)
                let chunks = gates.chunk(4, 1)?;
                let i_gate = candle_nn::ops::sigmoid(&chunks[0])?;
                let f_gate = candle_nn::ops::sigmoid(&chunks[1])?;
                let g_gate = chunks[2].tanh()?;
                let o_gate = candle_nn::ops::sigmoid(&chunks[3])?;

                c_t = f_gate
                    .broadcast_mul(&c_t)?
                    .broadcast_add(&i_gate.broadcast_mul(&g_gate)?)?;
                h_t = o_gate.broadcast_mul(&c_t.tanh()?)?;

                outputs.push(h_t.unsqueeze(1)?);
            }

            output = Tensor::cat(&outputs, 1)?;
        }

        Ok((output, (h, c)))
    }
}

// ============================================================================
// Specialized Layers
// ============================================================================

/// CausalConv1d: A 1D convolution with causal padding
/// Ensures that output at time t only depends on inputs at time <= t
pub struct CausalConv1d {
    pub conv: candle_nn::Conv1d,
    pub padding: usize,
}

impl CausalConv1d {
    pub fn load(
        vb: candle_nn::VarBuilder,
        in_channels: usize,
        out_channels: usize,
        kernel_size: usize,
        stride: usize,
        bias: bool,
    ) -> Result<Self> {
        let padding = kernel_size - 1;
        let config = candle_nn::Conv1dConfig {
            stride,
            padding,
            ..Default::default()
        };
        let conv = if bias {
            candle_nn::conv1d(in_channels, out_channels, kernel_size, config, vb)?
        } else {
            candle_nn::conv1d_no_bias(in_channels, out_channels, kernel_size, config, vb)?
        };
        Ok(Self { conv, padding })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let x = self.conv.forward(x)?;
        // Causal slice: remove the 'future' padding at the end
        if self.padding > 0 {
            let dim = x.dims().len() - 1;
            let seq_len = x.dim(dim)?;
            x.narrow(dim, 0, seq_len - self.padding)
        } else {
            Ok(x)
        }
    }
}

/// Dropout layer (inference no-op)
pub struct Dropout {
    pub p: f32,
}
impl Dropout {
    pub fn new() -> Self {
        Self { p: 0.5 }
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        Ok(x.clone())
    }
}

/// Transpose layer (swaps two dimensions)
pub struct Transpose {
    pub dim0: usize,
    pub dim1: usize,
}
impl Transpose {
    pub fn new(dim0: usize, dim1: usize) -> Self {
        Self { dim0, dim1 }
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        x.transpose(self.dim0, self.dim1)
    }
}

/// ConvTranspose1d implementation
pub struct ConvTranspose1d {
    inner: candle_nn::ConvTranspose1d,
}

impl ConvTranspose1d {
    pub fn load(
        vb: candle_nn::VarBuilder,
        in_c: usize,
        out_c: usize,
        kernel_size: usize,
        stride: usize,
        padding: usize,
    ) -> Result<Self> {
        let weight = vb.get((in_c, out_c, kernel_size), "weight").or_else(|_| {
            vb.pp("parametrizations.weight")
                .get((in_c, out_c, kernel_size), "original1")
        })?;
        let bias = vb.get((out_c,), "bias").ok();

        let config = candle_nn::ConvTranspose1dConfig {
            stride,
            padding,
            ..Default::default()
        };
        let inner = candle_nn::ConvTranspose1d::new(weight, bias, config);
        Ok(Self { inner })
    }

    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        self.inner.forward(x)
    }
}

/// Sinusoidal Positional Embedding
pub struct SinusoidalPosEmb {
    pub dim: usize,
}
impl SinusoidalPosEmb {
    pub fn new(dim: usize) -> Self {
        Self { dim }
    }
    pub fn forward(&self, x: &Tensor) -> Result<Tensor> {
        let half_dim = self.dim / 2;
        let device = x.device();
        let dtype = x.dtype();
        let inv_freq: Vec<_> = (0..half_dim)
            .map(|i| 1.0f32 / (10000.0f32.powf(i as f32 / (half_dim as f32 - 1.0f32))))
            .collect();
        let inv_freq = Tensor::from_vec(inv_freq, half_dim, device)?.to_dtype(dtype)?;
        let emb = x.unsqueeze(1)?.broadcast_mul(&inv_freq.unsqueeze(0)?)?;
        Tensor::cat(&[emb.sin()?, emb.cos()?], 1)
    }
}
</file>

<file path="crates/pycandle/src/report.rs">
// Report generation for PyCandle coverage analysis
use pycandle_core::LayerMeta;
use std::collections::HashMap;

/// Data structure holding analysis results
pub struct ReportData {
    pub supported: usize,
    pub unsupported: usize,
    pub gaps: HashMap<String, usize>,
    pub layers: HashMap<String, LayerMeta>,
}

/// Generates HTML coverage reports from manifest data
pub struct ReportGenerator {
    manifest: HashMap<String, LayerMeta>,
}

impl ReportGenerator {
    pub fn new(manifest: HashMap<String, LayerMeta>) -> Self {
        Self { manifest }
    }

    /// Analyze the manifest and categorize layers
    pub fn analyze(&self) -> ReportData {
        let mut supported = 0;
        let mut unsupported = 0;
        let mut gaps: HashMap<String, usize> = HashMap::new();

        for (_name, meta) in &self.manifest {
            if !meta.is_leaf {
                continue;
            }
            if self.is_supported(&meta.module_type) {
                supported += 1;
            } else {
                unsupported += 1;
                *gaps.entry(meta.module_type.clone()).or_default() += 1;
            }
        }

        ReportData {
            supported,
            unsupported,
            gaps,
            layers: self.manifest.clone(),
        }
    }

    /// Check if a module type is supported by PyCandle codegen
    fn is_supported(&self, module_type: &str) -> bool {
        matches!(
            module_type,
            "Linear"
                | "Conv1d"
                | "Conv2d"
                | "Embedding"
                | "LayerNorm"
                | "ReLU"
                | "GELU"
                | "Sigmoid"
                | "Tanh"
                | "ELU"
                | "LeakyReLU"
                | "Snake"
                | "BatchNorm1d"
                | "BatchNorm2d"
                | "LSTM"
        )
    }

    /// Generate a standalone HTML coverage report
    pub fn generate_html(&self, data: &ReportData) -> String {
        format!(
            r#"<!DOCTYPE html>
<html>
<head>
    <title>PyCandle Coverage Report</title>
    <style>
        :root {{
            --bg: #0f172a;
            --card-bg: #1e293b;
            --text: #e2e8f0;
            --text-muted: #94a3b8;
            --green: #22c55e;
            --red: #ef4444;
            --blue: #3b82f6;
            --border: #334155;
        }}
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        body {{
            font-family: 'Inter', system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            min-height: 100vh;
            padding: 40px 20px;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}
        h1 {{
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 8px;
            background: linear-gradient(135deg, var(--blue), var(--green));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .subtitle {{
            color: var(--text-muted);
            margin-bottom: 32px;
        }}
        .dashboard {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        .card {{
            background: var(--card-bg);
            padding: 24px;
            border-radius: 12px;
            border: 1px solid var(--border);
            transition: transform 0.2s, box-shadow 0.2s;
        }}
        .card:hover {{
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(0,0,0,0.3);
        }}
        .card h3 {{
            font-size: 0.875rem;
            font-weight: 500;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 8px;
        }}
        .card .value {{
            font-size: 3rem;
            font-weight: 700;
        }}
        .card.supported .value {{ color: var(--green); }}
        .card.unsupported .value {{ color: var(--red); }}
        .card.total .value {{ color: var(--blue); }}
        .progress-bar {{
            height: 8px;
            background: var(--border);
            border-radius: 4px;
            overflow: hidden;
            margin-top: 8px;
        }}
        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, var(--green), var(--blue));
            border-radius: 4px;
            transition: width 0.5s ease;
        }}
        h2 {{
            font-size: 1.5rem;
            font-weight: 600;
            margin: 32px 0 16px 0;
            color: var(--text);
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            background: var(--card-bg);
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 32px;
        }}
        th {{
            text-align: left;
            padding: 16px;
            background: rgba(0,0,0,0.2);
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            font-size: 0.75rem;
            letter-spacing: 0.05em;
        }}
        td {{
            padding: 12px 16px;
            border-bottom: 1px solid var(--border);
        }}
        tr:last-child td {{
            border-bottom: none;
        }}
        tr:hover {{
            background: rgba(255,255,255,0.02);
        }}
        .status {{
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 4px 12px;
            border-radius: 9999px;
            font-size: 0.875rem;
            font-weight: 500;
        }}
        .status.supported {{
            background: rgba(34, 197, 94, 0.15);
            color: var(--green);
        }}
        .status.unsupported {{
            background: rgba(239, 68, 68, 0.15);
            color: var(--red);
        }}
        .status::before {{
            content: '';
            width: 6px;
            height: 6px;
            border-radius: 50%;
            background: currentColor;
        }}
        .mono {{
            font-family: 'JetBrains Mono', 'Fira Code', monospace;
            font-size: 0.875rem;
        }}
        .shape {{
            color: var(--text-muted);
            font-size: 0.8rem;
        }}
        .count-badge {{
            display: inline-block;
            background: var(--border);
            padding: 2px 10px;
            border-radius: 9999px;
            font-size: 0.875rem;
            font-weight: 600;
        }}
        
        /* Component grouping styles */
        .component-section {{
            background: var(--card-bg);
            border-radius: 12px;
            border: 1px solid var(--border);
            margin-bottom: 16px;
            overflow: hidden;
        }}
        .component-header {{
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 16px 20px;
            background: rgba(0,0,0,0.2);
            cursor: pointer;
            user-select: none;
            transition: background 0.2s;
        }}
        .component-header:hover {{
            background: rgba(0,0,0,0.3);
        }}
        .component-header h3 {{
            font-size: 1rem;
            font-weight: 600;
            color: var(--text);
            display: flex;
            align-items: center;
            gap: 12px;
        }}
        .component-header .chevron {{
            transition: transform 0.2s;
            color: var(--text-muted);
        }}
        .component-header.collapsed .chevron {{
            transform: rotate(-90deg);
        }}
        .component-stats {{
            display: flex;
            gap: 16px;
            font-size: 0.875rem;
        }}
        .component-stats .stat {{
            display: flex;
            align-items: center;
            gap: 6px;
        }}
        .component-stats .stat.ok {{ color: var(--green); }}
        .component-stats .stat.err {{ color: var(--red); }}
        .component-content {{
            max-height: 2000px;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }}
        .component-content.collapsed {{
            max-height: 0;
        }}
        .component-content table {{
            margin-bottom: 0;
            border-radius: 0;
        }}
        .layer-name {{
            padding-left: 24px;
            position: relative;
        }}
        .layer-name::before {{
            content: '';
            position: absolute;
            left: 8px;
            color: var(--border);
        }}
        
        /* Filters */
        .filters {{
            display: flex;
            gap: 12px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }}
        .filter-btn {{
            padding: 8px 16px;
            border: 1px solid var(--border);
            background: transparent;
            color: var(--text);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s;
            font-size: 0.875rem;
        }}
        .filter-btn:hover {{
            background: var(--card-bg);
        }}
        .filter-btn.active {{
            background: var(--blue);
            border-color: var(--blue);
        }}
        .search-box {{
            flex: 1;
            min-width: 200px;
            padding: 8px 16px;
            border: 1px solid var(--border);
            background: var(--card-bg);
            color: var(--text);
            border-radius: 8px;
            font-size: 0.875rem;
        }}
        .search-box:focus {{
            outline: none;
            border-color: var(--blue);
        }}
        .hidden {{ display: none !important; }}
        
        /* Drift Analysis Chart Styles */
        .drift-section {{
            background: var(--card-bg);
            border-radius: 12px;
            border: 1px solid var(--border);
            padding: 24px;
            margin-bottom: 32px;
        }}
        .drift-section h2 {{
            margin-top: 0;
            margin-bottom: 16px;
        }}
        .drift-chart {{
            width: 100%;
            height: 300px;
            position: relative;
        }}
        .drift-chart svg {{
            width: 100%;
            height: 100%;
        }}
        .drift-legend {{
            display: flex;
            gap: 24px;
            margin-top: 16px;
            font-size: 0.875rem;
            color: var(--text-muted);
        }}
        .drift-legend-item {{
            display: flex;
            align-items: center;
            gap: 8px;
        }}
        .drift-legend-color {{
            width: 16px;
            height: 16px;
            border-radius: 4px;
        }}
        .divergence-alert {{
            background: rgba(239, 68, 68, 0.15);
            border: 1px solid var(--red);
            border-radius: 8px;
            padding: 16px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 12px;
        }}
        .divergence-alert .icon {{
            font-size: 1.5rem;
        }}
        .divergence-alert .message {{
            flex: 1;
        }}
        .divergence-alert .layer-name {{
            font-family: 'JetBrains Mono', monospace;
            color: var(--red);
            font-weight: 600;
        }}
        .drift-placeholder {{
            text-align: center;
            padding: 40px;
            color: var(--text-muted);
        }}
        .drift-placeholder .icon {{
            font-size: 3rem;
            margin-bottom: 16px;
            opacity: 0.5;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1> PyCandle Coverage Report</h1>
        <p class="subtitle">Module coverage analysis for Candle code generation</p>
        
        <div class="dashboard">
            <div class="card total">
                <h3>Total Layers</h3>
                <div class="value">{total}</div>
            </div>
            <div class="card supported">
                <h3>Supported</h3>
                <div class="value">{supported}</div>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {coverage:.1}%"></div>
                </div>
            </div>
            <div class="card unsupported">
                <h3>Needs Implementation</h3>
                <div class="value">{unsupported}</div>
            </div>
        </div>
        
        <!-- Drift Analysis Section -->
        <div class="drift-section">
            <h2> Numerical Drift Analysis</h2>
            <div id="divergenceAlert" class="divergence-alert" style="display: none;">
                <span class="icon"></span>
                <div class="message">
                    <strong>Divergence Detected!</strong> Cosine similarity dropped below 0.99 at layer 
                    <span class="layer-name" id="divergenceLayer">-</span>
                </div>
            </div>
            <div class="drift-chart" id="driftChart">
                <div class="drift-placeholder">
                    <div class="icon"></div>
                    <p>Run parity verification to see drift analysis</p>
                    <p style="font-size: 0.8rem; margin-top: 8px;">
                        Use <code>PyChecker::verify()</code> and pass results to generate this chart
                    </p>
                </div>
            </div>
            <div class="drift-legend">
                <div class="drift-legend-item">
                    <div class="drift-legend-color" style="background: #3b82f6;"></div>
                    <span>MSE (log scale)</span>
                </div>
                <div class="drift-legend-item">
                    <div class="drift-legend-color" style="background: #22c55e;"></div>
                    <span>Cosine Similarity</span>
                </div>
                <div class="drift-legend-item">
                    <div class="drift-legend-color" style="background: #ef4444;"></div>
                    <span>Divergence Threshold (0.99)</span>
                </div>
            </div>
        </div>
        
        <script src="https://d3js.org/d3.v7.min.js"></script>
        <script>
            // Drift data will be injected here when parity checks are run
            const driftData = {drift_data_json};
            
            if (driftData && driftData.length > 0) {{
                renderDriftChart(driftData);
            }}
            
            function renderDriftChart(data) {{
                const container = document.getElementById('driftChart');
                container.innerHTML = '';
                
                const margin = {{top: 20, right: 60, bottom: 60, left: 60}};
                const width = container.clientWidth - margin.left - margin.right;
                const height = 260 - margin.top - margin.bottom;
                
                const svg = d3.select('#driftChart')
                    .append('svg')
                    .attr('width', width + margin.left + margin.right)
                    .attr('height', height + margin.top + margin.bottom)
                    .append('g')
                    .attr('transform', `translate(${{margin.left}},${{margin.top}})`);
                
                // Scales
                const x = d3.scaleBand()
                    .domain(data.map((d, i) => i))
                    .range([0, width])
                    .padding(0.1);
                
                const yMSE = d3.scaleLog()
                    .domain([1e-10, d3.max(data, d => d.mse) * 10])
                    .range([height, 0]);
                
                const yCosSim = d3.scaleLinear()
                    .domain([0.9, 1])
                    .range([height, 0]);
                
                // MSE bars
                svg.selectAll('.bar-mse')
                    .data(data)
                    .enter()
                    .append('rect')
                    .attr('class', 'bar-mse')
                    .attr('x', (d, i) => x(i))
                    .attr('y', d => yMSE(Math.max(d.mse, 1e-10)))
                    .attr('width', x.bandwidth())
                    .attr('height', d => height - yMSE(Math.max(d.mse, 1e-10)))
                    .attr('fill', '#3b82f6')
                    .attr('opacity', 0.7);
                
                // Cosine similarity line
                const line = d3.line()
                    .x((d, i) => x(i) + x.bandwidth() / 2)
                    .y(d => yCosSim(d.cosine_sim))
                    .curve(d3.curveMonotoneX);
                
                svg.append('path')
                    .datum(data)
                    .attr('fill', 'none')
                    .attr('stroke', '#22c55e')
                    .attr('stroke-width', 2)
                    .attr('d', line);
                
                // Threshold line at 0.99
                svg.append('line')
                    .attr('x1', 0)
                    .attr('x2', width)
                    .attr('y1', yCosSim(0.99))
                    .attr('y2', yCosSim(0.99))
                    .attr('stroke', '#ef4444')
                    .attr('stroke-width', 1)
                    .attr('stroke-dasharray', '4,4');
                
                // Find divergence point
                const divergencePoint = data.findIndex(d => d.cosine_sim < 0.99);
                if (divergencePoint >= 0) {{
                    document.getElementById('divergenceAlert').style.display = 'flex';
                    document.getElementById('divergenceLayer').textContent = data[divergencePoint].name;
                    
                    // Highlight divergence point
                    svg.append('circle')
                        .attr('cx', x(divergencePoint) + x.bandwidth() / 2)
                        .attr('cy', yCosSim(data[divergencePoint].cosine_sim))
                        .attr('r', 6)
                        .attr('fill', '#ef4444')
                        .attr('stroke', '#fff')
                        .attr('stroke-width', 2);
                }}
                
                // Axes
                svg.append('g')
                    .attr('transform', `translate(0,${{height}})`)
                    .call(d3.axisBottom(x).tickFormat(i => data[i]?.name?.split('.').pop() || i))
                    .selectAll('text')
                    .attr('transform', 'rotate(-45)')
                    .style('text-anchor', 'end')
                    .style('fill', '#94a3b8')
                    .style('font-size', '10px');
                
                svg.append('g')
                    .call(d3.axisLeft(yMSE).ticks(5, '.0e'))
                    .selectAll('text')
                    .style('fill', '#3b82f6');
                
                svg.append('g')
                    .attr('transform', `translate(${{width}},0)`)
                    .call(d3.axisRight(yCosSim).ticks(5))
                    .selectAll('text')
                    .style('fill', '#22c55e');
            }}
        </script>
        
        <h2>Gap Analysis</h2>
        <table>
            <thead>
                <tr>
                    <th>Module Type</th>
                    <th>Count</th>
                    <th>Status</th>
                </tr>
            </thead>
            <tbody>
                {gaps_table}
            </tbody>
        </table>
        
        <h2>Layers by Component</h2>
        <div class="filters">
            <input type="text" class="search-box" placeholder="Search layers..." id="searchBox">
            <button class="filter-btn active" data-filter="all">All</button>
            <button class="filter-btn" data-filter="supported">Supported Only</button>
            <button class="filter-btn" data-filter="unsupported">Unsupported Only</button>
            <button class="filter-btn" data-filter="expand">Expand All</button>
            <button class="filter-btn" data-filter="collapse">Collapse All</button>
        </div>
        
        {components_html}
    </div>
</body>
</html>"#,
            total = data.supported + data.unsupported,
            supported = data.supported,
            unsupported = data.unsupported,
            coverage = if data.supported + data.unsupported > 0 {
                (data.supported as f64 / (data.supported + data.unsupported) as f64) * 100.0
            } else {
                100.0
            },
            gaps_table = self.render_gaps_table(&data.gaps),
            components_html = self.render_components(&data.layers),
            // Drift data - read from jsonl if exists
            drift_data_json = self.read_drift_data(),
        )
    }

    fn read_drift_data(&self) -> String {
        let path = std::path::Path::new("verification_results.jsonl");
        if !path.exists() {
            return "[]".to_string();
        }

        if let Ok(content) = std::fs::read_to_string(path) {
            let lines: Vec<String> = content
                .lines()
                .filter(|l| !l.trim().is_empty())
                .map(|l| l.to_string())
                .collect();

            format!("[{}]", lines.join(","))
        } else {
            "[]".to_string()
        }
    }

    fn render_gaps_table(&self, gaps: &HashMap<String, usize>) -> String {
        if gaps.is_empty() {
            return "<tr><td colspan=\"3\" style=\"text-align: center; color: var(--green);\"> All module types are supported!</td></tr>".to_string();
        }

        let mut sorted: Vec<_> = gaps.iter().collect();
        sorted.sort_by(|a, b| b.1.cmp(a.1));

        sorted
            .iter()
            .map(|(module_type, count)| {
                format!(
                    r#"<tr>
                        <td class="mono">{}</td>
                        <td><span class="count-badge">{}</span></td>
                        <td><span class="status unsupported">Needs Implementation</span></td>
                    </tr>"#,
                    module_type, count
                )
            })
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// Group layers by their top-level component and render as collapsible sections
    fn render_components(&self, layers: &HashMap<String, LayerMeta>) -> String {
        // Group layers by their first path component
        let mut groups: HashMap<String, Vec<(&String, &LayerMeta)>> = HashMap::new();

        for (name, meta) in layers.iter().filter(|(_, m)| m.is_leaf) {
            let component = name.split('.').next().unwrap_or(name).to_string();
            groups.entry(component).or_default().push((name, meta));
        }

        // Sort groups by name
        let mut sorted_groups: Vec<_> = groups.into_iter().collect();
        sorted_groups.sort_by(|a, b| a.0.cmp(&b.0));

        let components_html = sorted_groups
            .iter()
            .map(|(component, layers)| {
                // Sort layers within component
                let mut sorted_layers = layers.clone();
                sorted_layers.sort_by(|a, b| a.0.cmp(b.0));

                // Count supported/unsupported
                let supported_count = sorted_layers
                    .iter()
                    .filter(|(_, m)| self.is_supported(&m.module_type))
                    .count();
                let unsupported_count = sorted_layers.len() - supported_count;

                let rows: String = sorted_layers
                    .iter()
                    .map(|(name, meta)| {
                        let supported = self.is_supported(&meta.module_type);
                        let status_class = if supported {
                            "supported"
                        } else {
                            "unsupported"
                        };
                        let status_text = if supported {
                            "Supported"
                        } else {
                            "Needs Implementation"
                        };

                        // Get the short name (everything after the first dot)
                        let short_name = name.split('.').skip(1).collect::<Vec<_>>().join(".");
                        let display_name = if short_name.is_empty() {
                            name.to_string()
                        } else {
                            short_name
                        };

                        let input_shapes = meta
                            .input_shapes
                            .iter()
                            .map(|s| format!("{:?}", s))
                            .collect::<Vec<_>>()
                            .join(", ");
                        let output_shapes = meta
                            .output_shapes
                            .iter()
                            .map(|s| format!("{:?}", s))
                            .collect::<Vec<_>>()
                            .join(", ");

                        format!(
                            r#"<tr class="layer-row" data-supported="{}">
                            <td class="mono layer-name">{}</td>
                            <td class="mono">{}</td>
                            <td class="shape">{}</td>
                            <td class="shape">{}</td>
                            <td><span class="status {}">{}</span></td>
                        </tr>"#,
                            supported,
                            display_name,
                            meta.module_type,
                            input_shapes,
                            output_shapes,
                            status_class,
                            status_text
                        )
                    })
                    .collect();

                format!(
                    r#"<div class="component-section" data-has-unsupported="{}">
                        <div class="component-header">
                            <h3>
                                <span class="chevron"></span>
                                {}
                            </h3>
                            <div class="component-stats">
                                <span class="stat">{} layers</span>
                                <span class="stat ok"> {}</span>
                                {}
                            </div>
                        </div>
                        <div class="component-content">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Layer</th>
                                        <th>Type</th>
                                        <th>Input Shape</th>
                                        <th>Output Shape</th>
                                        <th>Status</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {}
                                </tbody>
                            </table>
                        </div>
                    </div>"#,
                    unsupported_count > 0,
                    component,
                    sorted_layers.len(),
                    supported_count,
                    if unsupported_count > 0 {
                        format!("<span class=\"stat err\"> {}</span>", unsupported_count)
                    } else {
                        String::new()
                    },
                    rows
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        format!(
            r#"
        <div id="componentList">
            {}
        </div>
        
        <script>
            // State
            let currentFilter = 'all';
            let searchQuery = '';

            // Toggle component sections
            function setupCollapsibles() {{
                document.querySelectorAll('.component-header').forEach(header => {{
                    // Remove old listener if any
                    const newHeader = header.cloneNode(true);
                    header.parentNode.replaceChild(newHeader, header);
                    
                    newHeader.addEventListener('click', () => {{
                        newHeader.classList.toggle('collapsed');
                        newHeader.nextElementSibling.classList.toggle('collapsed');
                    }});
                }});
            }}
            setupCollapsibles();
            
            function updateVisibility() {{
                document.querySelectorAll('.component-section').forEach(section => {{
                    const rows = section.querySelectorAll('.layer-row');
                    let visibleRowsInSection = 0;
                    
                    rows.forEach(row => {{
                        const isSupported = row.dataset.supported === 'true';
                        let matchesFilter = true;
                        
                        if (currentFilter === 'supported') matchesFilter = isSupported;
                        else if (currentFilter === 'unsupported') matchesFilter = !isSupported;
                        
                        const matchesSearch = !searchQuery || row.textContent.toLowerCase().includes(searchQuery) || 
                                           section.querySelector('h3').textContent.toLowerCase().includes(searchQuery);
                        
                        const isVisible = matchesFilter && matchesSearch;
                        row.classList.toggle('hidden', !isVisible);
                        if (isVisible) visibleRowsInSection++;
                    }});
                    
                    section.classList.toggle('hidden', visibleRowsInSection === 0);
                    
                    // Auto-expand if we are filtering for unsupported and there are some
                    if (currentFilter === 'unsupported' && visibleRowsInSection > 0) {{
                        section.querySelector('.component-header').classList.remove('collapsed');
                        section.querySelector('.component-content').classList.remove('collapsed');
                    }}
                }});
            }}

            // Filter buttons
            document.querySelectorAll('.filter-btn').forEach(btn => {{
                btn.addEventListener('click', () => {{
                    const filter = btn.dataset.filter;
                    
                    if (filter === 'expand') {{
                        document.querySelectorAll('.component-header').forEach(h => h.classList.remove('collapsed'));
                        document.querySelectorAll('.component-content').forEach(c => c.classList.remove('collapsed'));
                        return;
                    }}
                    if (filter === 'collapse') {{
                        document.querySelectorAll('.component-header').forEach(h => h.classList.add('collapsed'));
                        document.querySelectorAll('.component-content').forEach(c => c.classList.add('collapsed'));
                        return;
                    }}
                    
                    document.querySelectorAll('.filter-btn').forEach(b => {{
                        if (['all', 'supported', 'unsupported'].includes(b.dataset.filter)) {{
                            b.classList.remove('active');
                        }}
                    }});
                    btn.classList.add('active');
                    
                    currentFilter = filter;
                    updateVisibility();
                }});
            }});
            
            // Search
            document.getElementById('searchBox').addEventListener('input', (e) => {{
                searchQuery = e.target.value.toLowerCase();
                updateVisibility();
            }});
        </script>
        "#,
            components_html
        )
    }
}
</file>

<file path="crates/pycandle/src/test_gen.rs">
use anyhow::{Context, Result};
use pycandle_core::LayerMeta;
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;

pub struct TestGenerator {
    model_name: String,
    crate_name: String,
    manifest: HashMap<String, LayerMeta>,
    project_name: String,
}

impl TestGenerator {
    pub fn new(model_name: String, manifest_path: PathBuf) -> Result<Self> {
        let manifest_content = fs::read_to_string(&manifest_path)
            .with_context(|| format!("Failed to read manifest at {:?}", manifest_path))?;

        let full_manifest: HashMap<String, serde_json::Value> =
            serde_json::from_str(&manifest_content).context("Failed to parse manifest JSON")?;

        let manifest: HashMap<String, LayerMeta> = full_manifest
            .into_iter()
            .filter(|(k, _)| !k.starts_with('_'))
            .map(|(k, v)| {
                let meta: LayerMeta = serde_json::from_value(v)
                    .with_context(|| format!("Failed to parse LayerMeta for {}", k))?;
                Ok((k, meta))
            })
            .collect::<Result<_>>()?;

        let stem = manifest_path.file_stem().unwrap().to_str().unwrap();
        let project_name = stem.replace("_manifest", "");

        Ok(Self {
            model_name,
            crate_name: Self::detect_crate_name().unwrap_or_else(|_| "my_project".to_string()),
            manifest,
            project_name,
        })
    }

    fn detect_crate_name() -> Result<String> {
        let content = fs::read_to_string("Cargo.toml").context("Failed to read Cargo.toml")?;
        let toml: toml::Value = toml::from_str(&content).context("Failed to parse Cargo.toml")?;

        if let Some(package) = toml.get("package") {
            if let Some(name) = package.get("name") {
                return Ok(name.as_str().unwrap_or("my_project").replace("-", "_"));
            }
        }

        Ok("my_project".to_string())
    }

    pub fn generate_test_file(&self) -> String {
        let input_count = self.count_model_inputs();
        let inputs_code = self.generate_inputs_loading_code(input_count);
        let forward_call = self.generate_forward_call(input_count);

        format!(
            r#"#[cfg(test)]
mod tests {{
    use super::*;
    use candle_core::{{Device, Tensor}};
    use pycandle_core::{{PyChecker, VerificationMode}};
    use {}::{};
    use anyhow::Result;

    #[test]
    fn test_parity() -> Result<()> {{
        // 1. Setup Device
        let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
        println!("Running on device: {{:?}}", device);

        // 2. Load Checker and Golden Trace
        // Assumes the trace directory is in the current project root
        let checker = PyChecker::load("{}", "pycandle_trace", &device)?
            .with_mode(VerificationMode::Strict);
        println!("Loaded checker with trace: {{}}", checker.name);

        // 3. Load Model
        // We use zeros VB as a placeholder; in a real parity test, 
        // you might want to load weights using pycandle weight tools.
        let vb = candle_nn::VarBuilder::zeros(candle_core::DType::F32, &device);
        let model = {}::load(vb, Some(checker.clone()))?;

        // 4. Load Inputs from Trace
        let trace_path = format!("pycandle_trace/{}_trace.safetensors", "{}");
        let tensors = candle_core::safetensors::load(&trace_path, &device)?;
        
{}

        // 5. Run Forward Pass & Verify
{}
        println!(" Parity test passed for {}!");

        Ok(())
    }}
}}
"#,
            self.crate_name,
            self.model_name,
            self.project_name,
            self.model_name,
            self.project_name,
            self.project_name,
            inputs_code,
            forward_call,
            self.model_name
        )
    }

    fn count_model_inputs(&self) -> usize {
        // Simple heuristic: check manifest for model_input.N keys or count input shapes of top level
        // Actually, we can just look at what's in the trace if we had it,
        // but from manifest we rely on the fact that GoldenRecorder saves 'model_input.0'
        // For now, let's assume we can find up to 10.
        // A better way: the GoldenRecorder knows.
        // Let's just check for the existence of "model_input.0" in manifest if it was recorded there?
        // Actually GoldenRecorder saves them to records, but not necessarily manifest unless they are layers.
        // But we know 'model_input.0' is the standard naming.
        // Let's just default to 1 for now if we can't find more, or maybe look at the first layer's input count.
        1
    }

    fn generate_inputs_loading_code(&self, count: usize) -> String {
        let mut code = String::new();
        for i in 0..count {
            code.push_str(&format!(
                "        let x{} = tensors.get(\"model_input.{}\").context(\"Missing model_input.{}\")?.clone();\n",
                i, i, i
            ));
        }
        code
    }

    fn generate_forward_call(&self, count: usize) -> String {
        let args = (0..count)
            .map(|i| format!("&x{}", i))
            .collect::<Vec<_>>()
            .join(", ");

        // We need to know if the model returns a single tensor or multiple
        // For now, assume single.
        let output_layer = self.detect_output_layer();
        format!(
            r#"        let output = model.forward({})?;
        checker.verify("{}", &output)?;"#,
            args, output_layer
        )
    }

    fn detect_output_layer(&self) -> String {
        // Heuristic: The layer that isn't used as an input to any other layer,
        // or the last one alphabetically if it looks like a sequence.
        // If we have FX graph, it's the last node.
        // For now, return a placeholder or try to find the "last" one.
        if let Some(last) = self.manifest.keys().max() {
            last.clone()
        } else {
            "TODO_output_layer".to_string()
        }
    }
}
</file>

<file path="py/generated_complex.rs">
use candle_core::{Tensor, Result, Device, Shape};
use candle_nn::{Linear, Conv1d, LayerNorm, Embedding, VarBuilder, Module};
use pycandle_core::{PyChecker, py_check, Dropout, Transpose, Mish, CausalConv1d, SiLU, ReLU, GELU, Sigmoid, Tanh, ELU, LeakyReLU, Snake, BatchNorm1d, BatchNorm2d, LSTM};

pub struct ComplexModel {
    pub conv1: Conv1d,
    pub fc: Linear,
    pub relu: ReLU,
    pub checker: Option<PyChecker>,
}

impl ComplexModel {
    pub fn load(vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let conv1 = candle_nn::conv1d(16, 32, 3, candle_nn::Conv1dConfig { stride: 1, padding: 1, ..Default::default() }, vb.pp("conv1"))?;
        let fc = candle_nn::linear(320, 10, vb.pp("fc"))?;
        let relu = ReLU;

        Ok(Self {
            conv1,
            fc,
            relu,
            checker,
        })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let x_conv1 = self.conv1.forward(&xs)?;
        py_check!(self.checker, "conv1", &x_conv1);
        let x_relu = self.relu.forward(&x_conv1)?;
        py_check!(self.checker, "relu", &x_relu);
        let x_size = x_relu.dim(0)?;
        let x_view = x_relu.reshape(vec![x_size, -1])?;
        let x_fc = self.fc.forward(&x_view)?;
        py_check!(self.checker, "fc", &x_fc);
        Ok(x_fc)
    }
}
</file>

<file path="py/pyproject.toml">
[project]
name = "pycandle-spy"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "numpy",
    "packaging",
    "safetensors",
    "torch>=2.0.0",
    "onnx",
    "onnx2torch",
    "onnxscript",
]
</file>

<file path="tests/parity.rs">
#[cfg(test)]
mod tests {
    use super::*;
    use candle_core::{Device, Tensor};
    use pycandle_core::PyChecker;
    use my_project::MyModel;
    use anyhow::Result;

    #[test]
    fn test_parity() -> Result<()> {
        // 1. Setup Device
        let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
        println!("Running on device: {:?}", device);

        // 2. Load Checker and Golden Trace
        // Assumes "pycandle_trace" directory exists with trace files
        let checker = PyChecker::load("debug_run", "pycandle_trace", &device)?;
        println!("Loaded checker with trace: {}", checker.name);

        // 3. Load Model
        // We use the same variable builder as normally, but verify loaded weights match if needed
        // For parity test, we rely on the implementation's load to initialize weights correctly 
        // (often random or specific config). 
        // Ideally, we should load exact weights from the trace if available, but for now 
        // we assume the user might have a load_from_weights or similar if critical.
        // However, for pure activation parity on specific inputs, we usually need the weights to match.
        // TODO: In a real scenario, we might need to load weights from the trace too.
        // For now, we assume the user constructs the model. 
        // NOTE: If the model uses random initialization, this test WILL FAIL unless 
        // we load weights from the python trace.
        // 
        // As a workaround for this generic generator, we assume the user has a `load` function
        // that takes the checker.
        let vb = candle_nn::VarBuilder::zeros(candle_core::DType::F32, &device);
        let model = MyModel::load(vb, Some(checker.clone()))?;

        // 4. Load Inputs from Trace
        // The trace should contain 'model_input.0', 'model_input.1', etc.
        // We'll try to load at least the first input.
        // Note: PyChecker holds "golden_tensors", which contains the inputs too if we saved them!
        
        // We access the inputs directly from the golden tensors loaded in checker
        // (This requires PyChecker to expose golden_tensors or a getter, or we access directly if pub)
        // Since `golden_tensors` is private in PyChecker but we need it, ensure PyChecker exposes a way.
        // Assuming PyChecker has a `get_tensor` method or we can clone from the file.
        // Let's use `candle_core::safetensors::load` again here for simplicity to get inputs.
        
        let tensors = candle_core::safetensors::load("pycandle_trace/debug_run_trace.safetensors", &device)?;
        
        // 5. Run Forward Pass
        if let Some(input) = tensors.get("model_input.0") {
            let _output = model.forward(input)?;
            println!("Forward pass completed successfully!");
        } else {
            eprintln!(" No 'model_input.0' found in trace. Skipping forward pass execution.");
            println!("Available keys: {:?}", tensors.keys().take(5));
        }

        Ok(())
    }
}
</file>

<file path="crates/pycandle-audio/src/lib.rs">
//! PyCandle Audio - Audio operations with PyTorch parity
//!
//! This crate provides STFT, iSTFT, and padding operations that match
//! PyTorch's behavior for audio model porting.

use candle_core::{Result, Tensor};

/// Padding modes for audio operations
#[derive(Debug, Clone, Copy)]
pub enum PadMode {
    /// Reflect padding: [1,2,3] -> [3,2,1,2,3,2,1]
    Reflect,
    /// Replicate edge values
    Replicate,
    /// Pad with constant value
    Constant(f64),
}

/// Mel scale types
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum MelScale {
    /// HTK scale: 2595 * log10(1 + f / 700)
    Htk,
    /// Slaney scale: linear below 1kHz, log above
    Slaney,
}

/// Normalization modes for Mel banks
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum MelNorm {
    /// No normalization
    None,
    /// Slaney-style area normalization
    Slaney,
}

/// MelSpectrogram configuration matching torchaudio.transforms.MelSpectrogram
#[derive(Debug, Clone)]
pub struct MelSpectrogramConfig {
    pub stft_config: StftConfig,
    pub sample_rate: usize,
    pub n_mels: usize,
    pub f_min: f64,
    pub f_max: Option<f64>,
    pub mel_scale: MelScale,
    pub norm: MelNorm,
}

impl Default for MelSpectrogramConfig {
    fn default() -> Self {
        Self {
            stft_config: StftConfig::default(),
            sample_rate: 16000,
            n_mels: 128,
            f_min: 0.0,
            f_max: None,
            mel_scale: MelScale::Htk,
            norm: MelNorm::None,
        }
    }
}

/// STFT configuration matching PyTorch's torch.stft
#[derive(Debug, Clone)]
pub struct StftConfig {
    pub n_fft: usize,
    pub hop_length: Option<usize>,
    pub win_length: Option<usize>,
    pub center: bool,
    pub pad_mode: PadMode,
    pub normalized: bool,
    pub onesided: bool,
    pub return_complex: bool,
}

impl Default for StftConfig {
    fn default() -> Self {
        Self {
            n_fft: 400,
            hop_length: None,
            win_length: None,
            center: true,
            pad_mode: PadMode::Reflect,
            normalized: false,
            onesided: true,
            return_complex: true,
        }
    }
}

/// Apply 1D padding to a tensor
///
/// # Arguments
/// * `input` - Tensor of shape (B, T) or (B, C, T)
/// * `pad_left` - Amount of padding on the left
/// * `pad_right` - Amount of padding on the right
/// * `mode` - Padding mode
pub fn pad_1d(input: &Tensor, pad_left: usize, pad_right: usize, mode: PadMode) -> Result<Tensor> {
    let ndim = input.dims().len();
    let time_dim = ndim - 1;
    let time_len = input.dim(time_dim)?;

    match mode {
        PadMode::Reflect => {
            // Reflect padding - build indices and use index_select
            if pad_left > time_len - 1 || pad_right > time_len - 1 {
                return Err(candle_core::Error::Msg(
                    "Reflect padding size exceeds input size".to_string(),
                ));
            }

            // Build reflection indices
            let mut indices = Vec::with_capacity(pad_left + time_len + pad_right);

            // Left reflection: [pad_left, pad_left-1, ..., 1]
            for i in (1..=pad_left).rev() {
                indices.push(i as u32);
            }

            // Original: [0, 1, ..., time_len-1]
            for i in 0..time_len {
                indices.push(i as u32);
            }

            // Right reflection: [time_len-2, time_len-3, ..., time_len-1-pad_right]
            for i in 0..pad_right {
                indices.push((time_len - 2 - i) as u32);
            }

            let idx_tensor =
                Tensor::from_vec(indices, (pad_left + time_len + pad_right,), input.device())?;
            input.index_select(&idx_tensor, time_dim)
        }
        PadMode::Replicate => {
            // Edge/replicate padding using constant padding with edge values
            // For simplicity, use constant padding with zero and then copy edge values
            let total_len = pad_left + time_len + pad_right;
            let mut indices = Vec::with_capacity(total_len);

            for _ in 0..pad_left {
                indices.push(0u32);
            }
            for i in 0..time_len {
                indices.push(i as u32);
            }
            for _ in 0..pad_right {
                indices.push((time_len - 1) as u32);
            }

            let idx_tensor = Tensor::from_vec(indices, (total_len,), input.device())?;
            input.index_select(&idx_tensor, time_dim)
        }
        PadMode::Constant(val) => {
            let mut left_shape: Vec<usize> = input.dims().to_vec();
            left_shape[time_dim] = pad_left;
            let mut right_shape: Vec<usize> = input.dims().to_vec();
            right_shape[time_dim] = pad_right;

            let left =
                Tensor::full(val as f32, left_shape, input.device())?.to_dtype(input.dtype())?;
            let right =
                Tensor::full(val as f32, right_shape, input.device())?.to_dtype(input.dtype())?;
            Tensor::cat(&[&left, input, &right], time_dim)
        }
    }
}

/// Create a Hann window
pub fn hann_window(length: usize, device: &candle_core::Device) -> Result<Tensor> {
    let mut values = vec![0f32; length];
    for i in 0..length {
        values[i] = 0.5 * (1.0 - (2.0 * std::f32::consts::PI * i as f32 / length as f32).cos());
    }
    Tensor::from_vec(values, (length,), device)
}

/// Convert Hz to Mel frequency
pub fn hz_to_mel(freq: f64, scale: MelScale) -> f64 {
    match scale {
        MelScale::Htk => 2595.0 * (1.0 + freq / 700.0).log10(),
        MelScale::Slaney => {
            let min_log_hz = 1000.0;
            let min_log_mel = 15.0;
            let log_step = (6.4f64).ln() / 27.0;
            if freq >= min_log_hz {
                min_log_mel + (freq / min_log_hz).ln() / log_step
            } else {
                3.0 * freq / 200.0
            }
        }
    }
}

/// Convert Mel frequency to Hz
pub fn mel_to_hz(mel: f64, scale: MelScale) -> f64 {
    match scale {
        MelScale::Htk => 700.0 * (10f64.powf(mel / 2595.0) - 1.0),
        MelScale::Slaney => {
            let min_log_hz = 1000.0;
            let min_log_mel = 15.0;
            let log_step = (6.4f64).ln() / 27.0;
            if mel >= min_log_mel {
                min_log_hz * (log_step * (mel - min_log_mel)).exp()
            } else {
                200.0 * mel / 3.0
            }
        }
    }
}

/// Create a Mel filterbank matrix of shape (n_mels, n_fft / 2 + 1)
pub fn get_mel_banks(
    n_mels: usize,
    n_fft: usize,
    sample_rate: usize,
    f_min: f64,
    f_max: f64,
    scale: MelScale,
    norm: MelNorm,
) -> Result<Tensor> {
    let n_bins = n_fft / 2 + 1;
    let mel_min = hz_to_mel(f_min, scale);
    let mel_max = hz_to_mel(f_max, scale);

    let mut mel_points = vec![0.0f64; n_mels + 2];
    for i in 0..n_mels + 2 {
        mel_points[i] = mel_min + i as f64 * (mel_max - mel_min) / (n_mels + 1) as f64;
    }

    let mut hz_points = vec![0.0f64; n_mels + 2];
    for i in 0..n_mels + 2 {
        hz_points[i] = mel_to_hz(mel_points[i], scale);
    }

    let mut fft_freqs = vec![0.0f64; n_bins];
    for i in 0..n_bins {
        fft_freqs[i] = i as f64 * sample_rate as f64 / n_fft as f64;
    }

    let mut filterbank = vec![0.0f32; n_mels * n_bins];

    for i in 0..n_mels {
        let left = hz_points[i];
        let center = hz_points[i + 1];
        let right = hz_points[i + 2];

        for j in 0..n_bins {
            let f = fft_freqs[j];
            if f > left && f < right {
                let val = if f <= center {
                    (f - left) / (center - left)
                } else {
                    (right - f) / (right - center)
                };

                // Area normalization (Slaney)
                let val = if norm == MelNorm::Slaney {
                    val * 2.0 / (right - left)
                } else {
                    val
                };

                filterbank[i * n_bins + j] = val as f32;
            }
        }
    }

    Tensor::from_vec(filterbank, (n_mels, n_bins), &candle_core::Device::Cpu)
}

/// MelSpectrogram transformation
pub fn mel_spectrogram(
    input: &Tensor,
    config: &MelSpectrogramConfig,
    window: Option<&Tensor>,
) -> Result<Tensor> {
    let n_fft = config.stft_config.n_fft;
    let f_max = config.f_max.unwrap_or(config.sample_rate as f64 / 2.0);

    // 1. STFT
    let spec = stft(input, &config.stft_config, window)?;

    // spec is (B, n_bins, n_frames, 2) or (n_bins, n_frames, 2)
    // 2. Power Spectrogram (magnitude squared)
    let power = spec
        .narrow(spec.dims().len() - 1, 0, 1)?
        .sqr()?
        .add(&spec.narrow(spec.dims().len() - 1, 1, 1)?.sqr()?)?;
    let power = power.squeeze(spec.dims().len() - 1)?;

    // 3. Mel Filterbank
    let mel_banks = get_mel_banks(
        config.n_mels,
        n_fft,
        config.sample_rate,
        config.f_min,
        f_max,
        config.mel_scale,
        config.norm,
    )?
    .to_device(input.device())?
    .to_dtype(input.dtype())?;

    // Apply filterbank: (n_mels, n_bins) * (..., n_bins, n_frames)
    // We need to reorder power to (..., n_frames, n_bins) to use matmul or just use a custom dot product
    // Or just use matmul if we transpose.
    // power is (B, n_bins, n_frames)
    let power = power.transpose(power.dims().len() - 2, power.dims().len() - 1)?;
    // power is (B, n_frames, n_bins)

    let mel_spec = power.broadcast_matmul(&mel_banks.transpose(0, 1)?)?;
    // mel_spec is (B, n_frames, n_mels)

    mel_spec.transpose(mel_spec.dims().len() - 2, mel_spec.dims().len() - 1)
}

/// Short-time Fourier Transform (STFT)
pub fn stft(input: &Tensor, config: &StftConfig, window: Option<&Tensor>) -> Result<Tensor> {
    let device = input.device();
    let dtype = input.dtype();

    // 1. Padding
    let n_fft = config.n_fft;
    let hop_length = config.hop_length.unwrap_or(n_fft / 4);
    let win_length = config.win_length.unwrap_or(n_fft);

    let mut x = input.clone();
    if config.center {
        let pad = n_fft / 2;
        x = pad_1d(&x, pad, pad, config.pad_mode)?;
    }

    // 2. Framing & Windowing
    // x is (B, T) or (T,)
    let dims = x.dims();
    let (batch_size, time_len) = if dims.len() == 1 {
        (1, dims[0])
    } else if dims.len() == 2 {
        (dims[0], dims[1])
    } else {
        return Err(candle_core::Error::Msg(format!(
            "STFT input must be (B, T) or (T,), got {:?}",
            dims
        )));
    };

    let n_frames = (time_len - win_length) / hop_length + 1;

    // Move to CPU for FFT if on GPU
    let x_cpu = x.to_device(&candle_core::Device::Cpu)?;
    let x_vec = x_cpu.flatten_all()?.to_vec1::<f32>()?;

    let window_vec = if let Some(w) = window {
        w.to_device(&candle_core::Device::Cpu)?.to_vec1::<f32>()?
    } else {
        vec![1.0; win_length]
    };

    // 3. FFT Setup
    let mut planner = realfft::RealFftPlanner::<f32>::new();
    let r2c = planner.plan_fft_forward(n_fft);

    let n_bins = n_fft / 2 + 1;
    let mut output_vec = vec![0.0f32; batch_size * n_frames * n_bins * 2];

    for b in 0..batch_size {
        let batch_offset = b * time_len;
        let out_batch_offset = b * n_bins * n_frames * 2;
        for f in 0..n_frames {
            let start = batch_offset + f * hop_length;
            let mut frame = vec![0.0f32; n_fft];

            // Apply window and copy into frame (handling win_length < n_fft with zero padding)
            for i in 0..win_length {
                frame[i] = x_vec[start + i] * window_vec[i];
            }

            let mut spectrum = r2c.make_output_vec();
            r2c.process(&mut frame, &mut spectrum)
                .map_err(|e| candle_core::Error::Msg(format!("FFT error: {:?}", e)))?;

            for (i, c) in spectrum.iter().enumerate() {
                let out_idx = out_batch_offset + (i * n_frames + f) * 2;
                output_vec[out_idx] = c.re;
                output_vec[out_idx + 1] = c.im;
            }
        }
    }

    // 4. Result Formatting
    let shape = if batch_size == 1 && dims.len() == 1 {
        candle_core::Shape::from((n_bins, n_frames, 2usize))
    } else {
        candle_core::Shape::from((batch_size, n_bins, n_frames, 2usize))
    };

    let result = Tensor::from_vec(output_vec, shape, &candle_core::Device::Cpu)?;

    // Move back to original device and dtype
    result.to_device(device)?.to_dtype(dtype)
}

/// Inverse Short-time Fourier Transform (iSTFT)
pub fn istft(input: &Tensor, config: &StftConfig, window: Option<&Tensor>) -> Result<Tensor> {
    let device = input.device();
    let dtype = input.dtype();

    let n_fft = config.n_fft;
    let hop_length = config.hop_length.unwrap_or(n_fft / 4);
    let win_length = config.win_length.unwrap_or(n_fft);

    // input is (B, n_bins, n_frames, 2) or (n_bins, n_frames, 2)
    let dims = input.dims();
    let (batch_size, n_bins, n_frames) = if dims.len() == 3 {
        (1, dims[0], dims[1])
    } else if dims.len() == 4 {
        (dims[0], dims[1], dims[2])
    } else {
        return Err(candle_core::Error::Msg(format!(
            "iSTFT input must be (B, n_bins, n_frames, 2) or (n_bins, n_frames, 2), got {:?}",
            dims
        )));
    };

    if n_bins != n_fft / 2 + 1 {
        return Err(candle_core::Error::Msg(format!(
            "Expected {} bins for n_fft={}, got {}",
            n_fft / 2 + 1,
            n_fft,
            n_bins
        )));
    }

    // Move to CPU
    let input_cpu = input.to_device(&candle_core::Device::Cpu)?;
    let input_vec = input_cpu.flatten_all()?.to_vec1::<f32>()?;

    let window_vec = if let Some(w) = window {
        w.to_device(&candle_core::Device::Cpu)?.to_vec1::<f32>()?
    } else {
        vec![1.0; win_length]
    };

    // 2. Inverse FFT Setup
    let mut planner = realfft::RealFftPlanner::<f32>::new();
    let c2r = planner.plan_fft_inverse(n_fft);

    let mut output_audio = Vec::with_capacity(batch_size * (n_frames * hop_length + n_fft));

    for b in 0..batch_size {
        let batch_offset = b * n_bins * n_frames * 2;
        let expected_len = n_frames * hop_length + n_fft;
        let mut reconstructed = vec![0.0f32; expected_len];
        let mut window_sum = vec![0.0f32; expected_len];

        for f in 0..n_frames {
            let start = f * hop_length;
            let mut spectrum = Vec::with_capacity(n_bins);
            for i in 0..n_bins {
                let idx = batch_offset + (i * n_frames + f) * 2;
                spectrum.push(num_complex::Complex::new(
                    input_vec[idx],
                    input_vec[idx + 1],
                ));
            }

            let mut frame = c2r.make_output_vec();
            c2r.process(&mut spectrum, &mut frame)
                .map_err(|e| candle_core::Error::Msg(format!("iFFT error: {:?}", e)))?;

            // Normalize iFFT (realfft doesn't normalize by default)
            let norm = 1.0 / n_fft as f32;
            for i in 0..win_length {
                reconstructed[start + i] += frame[i] * norm * window_vec[i];
                window_sum[start + i] += window_vec[i] * window_vec[i];
            }
        }

        // Apply OLA normalization (Over-Lap Add)
        for i in 0..reconstructed.len() {
            if window_sum[i] > 1e-10 {
                reconstructed[i] /= window_sum[i];
            }
        }

        output_audio.extend_from_slice(&reconstructed);
    }

    // 3. Finalize and Crop
    let mut result = Tensor::from_vec(
        output_audio,
        (batch_size, n_frames * hop_length + n_fft),
        &candle_core::Device::Cpu,
    )?;

    if config.center {
        let pad = n_fft / 2;
        let total_len = result.dim(1)?;
        result = result.narrow(1, pad, total_len - 2 * pad)?;
    }

    if batch_size == 1 && dims.len() == 3 {
        result = result.squeeze(0)?;
    }

    result.to_device(device)?.to_dtype(dtype)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hann_window() {
        let device = candle_core::Device::Cpu;
        let window = hann_window(4, &device).unwrap();
        let data: Vec<f32> = window.to_vec1().unwrap();
        // Hann window for n=4: [0, 0.5, 1, 0.5]
        assert!((data[0] - 0.0).abs() < 1e-5);
        assert!((data[1] - 0.5).abs() < 1e-5);
        assert!((data[2] - 1.0).abs() < 1e-5);
        assert!((data[3] - 0.5).abs() < 1e-5);
    }

    #[test]
    fn test_stft_istft_roundtrip() {
        let device = candle_core::Device::Cpu;
        let config = StftConfig {
            n_fft: 16,
            hop_length: Some(4),
            win_length: Some(16),
            center: true,
            pad_mode: PadMode::Reflect,
            ..Default::default()
        };

        // Create a simple signal: sum of sines
        let mut signal = vec![0.0f32; 64];
        for i in 0..64 {
            signal[i] = (2.0 * std::f32::consts::PI * 440.0 * i as f32 / 16000.0).sin();
        }
        let x = Tensor::from_vec(signal, (64,), &device).unwrap();
        let window = hann_window(config.win_length.unwrap(), &device).unwrap();

        let spec = stft(&x, &config, Some(&window)).unwrap();
        let x_hat = istft(&spec, &config, Some(&window)).unwrap();

        let x_vec = x.to_vec1::<f32>().unwrap();
        let x_hat_vec = x_hat.to_vec1::<f32>().unwrap();

        // Roundtrip should be reasonably close
        // Note: OLA with Hann window and hop=4 (n_fft/4) meets COLA
        for i in 4..60 {
            // Avoid edges due to OLA ramp-up/down if not perfectly handled by padding
            assert!(
                (x_vec[i] - x_hat_vec[i]).abs() < 1e-3,
                "At index {}: {} != {}",
                i,
                x_vec[i],
                x_hat_vec[i]
            );
        }
    }

    #[test]
    fn test_mel_scales() {
        // HTK parity
        let hz = 1000.0;
        let mel = hz_to_mel(hz, MelScale::Htk);
        assert!((mel - 1000.0).abs() < 0.1);
        let hz_back = mel_to_hz(mel, MelScale::Htk);
        assert!((hz_back - hz).abs() < 1e-5);

        // Slaney parity
        let hz_s = 2000.0;
        let mel_s = hz_to_mel(hz_s, MelScale::Slaney);
        // Slaney: 15 + log(2000/1000) / log_step
        assert!((mel_s - 25.0).abs() < 0.1);
        let hz_back_s = mel_to_hz(mel_s, MelScale::Slaney);
        assert!((hz_back_s - hz_s).abs() < 1e-5);
    }

    #[test]
    fn test_get_mel_banks() {
        let n_mels = 40;
        let n_fft = 1024;
        let sample_rate = 16000;
        let f_min = 0.0;
        let f_max = 8000.0;

        let banks = get_mel_banks(
            n_mels,
            n_fft,
            sample_rate,
            f_min,
            f_max,
            MelScale::Htk,
            MelNorm::None,
        )
        .unwrap();

        assert_eq!(banks.dims(), &[40, 513]);
    }
}
</file>

<file path="crates/pycandle-core/src/checker.rs">
//! PyChecker - Golden tensor comparison for parity verification

use candle_core::{Device, Error, Result, Shape, Tensor};
use colored::*;
use serde::{Deserialize, Serialize};
use std::cell::RefCell;
use std::collections::HashMap;
use std::fs::OpenOptions;
use std::io::Write;
use std::path::Path;

/// Mode for verification: Strict (panic on failure) or DriftTracking (record and continue)
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum VerificationMode {
    Strict,
    DriftTracking,
}

/// Metadata for a recorded layer
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct LayerMeta {
    pub name: String,
    pub module_type: String,
    pub input_shapes: Vec<Vec<usize>>,
    pub output_shapes: Vec<Vec<usize>>,
    pub parameters: Vec<String>,
    pub is_leaf: bool,
    pub config: serde_json::Value,
}

/// Result of comparing two tensors
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ComparisonResult {
    pub name: String,
    pub mse: f32,
    pub max_diff: f32,
    pub cosine_sim: f32,
    pub passed: bool,
    pub heatmap: Option<Vec<f32>>,
}

/// PyChecker loads golden tensors and verifies Rust outputs against them
#[derive(Clone)]
pub struct PyChecker {
    pub name: String,
    golden_tensors: HashMap<String, Tensor>,
    pub manifest: HashMap<String, LayerMeta>,
    pub atol: f32,
    pub rtol: f32,
    pub device: Device,
    pub mode: VerificationMode,
    history: RefCell<Vec<ComparisonResult>>,
}

impl PyChecker {
    /// Load golden records from safetensors and manifest JSON
    pub fn load<P: AsRef<Path>>(project_name: &str, base_path: P, device: &Device) -> Result<Self> {
        let base = base_path.as_ref();
        let tensor_path = base.join(format!("{}_trace.safetensors", project_name));
        let manifest_path = base.join(format!("{}_manifest.json", project_name));

        let golden_tensors = candle_core::safetensors::load(&tensor_path, device)?;

        let manifest_file = std::fs::read_to_string(&manifest_path)
            .map_err(|e| Error::Msg(format!("Failed to read manifest: {}", e)))?;
        let full_manifest: HashMap<String, serde_json::Value> = serde_json::from_str(&manifest_file)
            .map_err(|e| Error::Msg(format!("Failed to parse manifest: {}", e)))?;

        let manifest: HashMap<String, LayerMeta> = full_manifest
            .into_iter()
            .filter(|(k, _)| !k.starts_with('_'))
            .map(|(k, v)| {
                let meta: LayerMeta = serde_json::from_value(v).map_err(|e| {
                    Error::Msg(format!("Failed to parse LayerMeta for {}: {}", k, e))
                })?;
                Ok((k, meta))
            })
            .collect::<Result<HashMap<String, LayerMeta>>>()?;

        Ok(Self {
            name: project_name.to_string(),
            golden_tensors,
            manifest,
            atol: 1e-4,
            rtol: 1e-4,
            device: device.clone(),
            mode: VerificationMode::Strict,
            history: RefCell::new(Vec::new()),
        })
    }

    /// Set verification mode
    pub fn with_mode(mut self, mode: VerificationMode) -> Self {
        self.mode = mode;
        self
    }

    /// Verify a tensor against the golden record for a layer
    pub fn verify(&self, layer_name: &str, actual: &Tensor) -> Result<ComparisonResult> {
        let key = format!("{}.out.0", layer_name);
        let expected = self.golden_tensors.get(&key).ok_or_else(|| {
            Error::Msg(format!(
                "Layer '{}' not found in trace. Available: {:?}",
                layer_name,
                self.golden_tensors.keys().take(5).collect::<Vec<_>>()
            ))
        })?;

        if actual.shape() != expected.shape() {
            self.diagnose_shape_mismatch(layer_name, actual.shape(), expected.shape());
            return Err(Error::Msg(format!(
                "Shape mismatch for {}: actual {:?}, expected {:?}",
                layer_name,
                actual.shape(),
                expected.shape()
            )));
        }

        let mut result = self.compare_tensors(actual, expected)?;
        result.name = layer_name.to_string();

        if result.mse > self.atol {
            // Compute heatmap for dashboard
            result.heatmap = self.compute_heatmap(actual, expected);

            // In Strict mode, we fail immediately
            if self.mode == VerificationMode::Strict {
                self.report_failure(layer_name, &result, actual, expected);
                self.log_result(&result);
                return Err(Error::Msg(format!(
                    "Numerical parity failed for {}",
                    layer_name
                )));
            } else {
                // In DriftTracking mode, we warn but continue
                println!(
                    "{} Layer '{}' drifted. (MSE: {:.2e})",
                    "".yellow(),
                    layer_name.yellow(),
                    result.mse
                );
            }
        } else {
            println!(
                "{} Layer '{}' passed. (MSE: {:.2e}, CosSim: {:.4})",
                "".green(),
                layer_name.yellow(),
                result.mse,
                result.cosine_sim
            );
        }

        self.log_result(&result);
        self.history.borrow_mut().push(result.clone());
        Ok(result)
    }

    /// Print a report of the most sensitive layers (highest drift)
    pub fn print_drift_report(&self) {
        let history = self.history.borrow();
        if history.is_empty() {
            return;
        }

        println!("\n{}", " QUANTIZATION DRIFT REPORT".blue().bold());
        println!("{:<40} | {:<12} | {:<12}", "Layer", "MSE", "Status");
        println!("{}", "-".repeat(70));

        let mut sorted_history = history.clone();
        sorted_history.sort_by(|a, b| b.mse.partial_cmp(&a.mse).unwrap());

        for res in sorted_history.iter().take(20) {
            let status = if res.mse > self.atol {
                "DRIFT".red()
            } else {
                "OK".green()
            };
            println!("{:<40} | {:.2e}   | {}", res.name, res.mse, status);
        }
        println!("\n");
    }

    fn log_result(&self, result: &ComparisonResult) {
        if let Ok(json) = serde_json::to_string(result) {
            if let Ok(mut file) = OpenOptions::new()
                .create(true)
                .append(true)
                .open("verification_results.jsonl")
            {
                let _ = writeln!(file, "{}", json);
            }
        }
    }

    fn compare_tensors(&self, a: &Tensor, b: &Tensor) -> Result<ComparisonResult> {
        let diff = (a - b)?;
        let mse = diff.sqr()?.mean_all()?.to_scalar::<f32>()?;
        let max_diff = diff.abs()?.max_all()?.to_scalar::<f32>()?;

        let a_flat = a.flatten_all()?;
        let b_flat = b.flatten_all()?;
        let dot = (&a_flat * &b_flat)?.sum_all()?.to_scalar::<f32>()?;
        let norm_a = a_flat.sqr()?.sum_all()?.sqrt()?.to_scalar::<f32>()?;
        let norm_b = b_flat.sqr()?.sum_all()?.sqrt()?.to_scalar::<f32>()?;
        let cosine_sim = dot / (norm_a * norm_b + 1e-8);

        Ok(ComparisonResult {
            name: "unknown".to_string(), // Will be overwritten by caller
            mse,
            max_diff,
            cosine_sim,
            passed: mse <= self.atol,
            heatmap: None,
        })
    }

    fn diagnose_shape_mismatch(&self, name: &str, actual: &Shape, expected: &Shape) {
        println!("\n{}", " SHAPE MISMATCH DETECTED".red().bold());
        println!("Layer: {}", name.yellow());
        println!("  Rust:   {:?}", actual.dims());
        println!("  Python: {:?}", expected.dims());

        let a_dims = actual.dims();
        let e_dims = expected.dims();

        if a_dims.len() == 3 && e_dims.len() == 3 {
            if a_dims[1] == e_dims[2] && a_dims[2] == e_dims[1] {
                println!(
                    "{}",
                    " DIAGNOSIS: Dimension Swap. (B, C, T) vs (B, T, C). Try .transpose(1, 2)?"
                        .cyan()
                );
            }
        }
        println!("{}\n", "---------------------------".red());
    }

    fn report_failure(
        &self,
        name: &str,
        res: &ComparisonResult,
        actual: &Tensor,
        expected: &Tensor,
    ) {
        println!("\n{}", " NUMERICAL PARITY FAILED".red().bold());
        println!("Layer: {}", name.yellow());
        println!("  MSE:      {:.8}", res.mse);
        println!("  Cos Sim:  {:.8}", res.cosine_sim);

        let a_mean = actual.mean_all().unwrap().to_scalar::<f32>().unwrap_or(0.0);
        let e_mean = expected
            .mean_all()
            .unwrap()
            .to_scalar::<f32>()
            .unwrap_or(0.0);
        println!("  Means:    Rust={:.6}, Py={:.6}", a_mean, e_mean);

        // --- Active Debugging Artifacts ---
        let failures_dir = Path::new("failures");
        if !failures_dir.exists() {
            let _ = std::fs::create_dir(failures_dir);
        }

        // 1. Save Tensor Snippet (.safetensors)
        let snippet_path = failures_dir.join(format!("{}.safetensors", name));
        let tensors_to_save = HashMap::from([
            ("rust_actual".to_string(), actual.clone()),
            ("py_golden".to_string(), expected.clone()),
        ]);
        if let Err(e) = candle_core::safetensors::save(&tensors_to_save, &snippet_path) {
            println!("  Failed to save snippet: {}", e);
        } else {
            println!(
                "   Snippet saved: {}",
                snippet_path.display().to_string().cyan()
            );
        }

        // 2. Generate Python Analysis Script
        let script_path = failures_dir.join(format!("debug_{}.py", name));
        let script_content = format!(
            r#"
import torch
from safetensors.torch import load_file
import matplotlib.pyplot as plt
import numpy as np

def analyze():
    print(f" Analyzing Failure: {{'{name}'}}")
    tensors = load_file("{filename}")
    rust = tensors["rust_actual"]
    gold = tensors["py_golden"]

    diff = (rust - gold).abs()
    print(f"  Max Diff: {{diff.max().item():.6f}}")
    print(f"  MSE:      {{(diff ** 2).mean().item():.8f}}")

    # Plot
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title("Rust Tensor Histogram")
    plt.hist(rust.flatten().float().numpy(), bins=50, alpha=0.7, label='Rust')
    plt.hist(gold.flatten().float().numpy(), bins=50, alpha=0.7, label='Gold')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.title("Difference Heatmap (First Slice)")
    if diff.ndim > 1:
        plt.imshow(diff.flatten(0, -2)[0].float().numpy(), cmap='hot', aspect='auto')
    else:
        plt.plot(diff.float().numpy())
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    analyze()
"#,
            name = name,
            filename = format!("{}.safetensors", name)
        );

        if let Ok(mut file) = std::fs::File::create(&script_path) {
            let _ = file.write_all(script_content.as_bytes());
            println!(
                "   Script generated: {}",
                script_path.display().to_string().cyan()
            );
        }

        println!("{}\n", "---------------------------".red());
    }

    pub fn compute_heatmap(&self, a: &Tensor, b: &Tensor) -> Option<Vec<f32>> {
        // Compute absolute difference
        let diff = (a - b).ok()?.abs().ok()?;

        // 1. Flatten to 1D
        let flat = diff.flatten_all().ok()?;
        let numel = flat.elem_count();

        // 2. We want an 8x8 grid = 64 buckets
        let grid_size = 64;
        if numel < grid_size {
            return None; // Too small to pool usefuly
        }

        let chunk_size = numel / grid_size;

        // 3. Simple max pooling into buckets
        // Walking through the tensor on CPU is slow for huge tensors, but this is a failure case anyway.
        // A faster way is to reshape (64, chunk_size) and max(dim=1).

        let reshaped = flat
            .narrow(0, 0, grid_size * chunk_size)
            .ok()?
            .reshape((grid_size, chunk_size))
            .ok()?;

        let pooled = reshaped.max(1).ok()?;

        // Convert to Vec<f32>
        pooled.to_vec1::<f32>().ok()
    }
}
</file>

<file path=".gitignore">
/target
Cargo.lock
# chatterbox-repo/*/
*.safetensors
*.pyc
__pycache__/
.venv/
pycandle_trace/
py_trace/
*.html
py/__pycache__/*/
</file>

<file path="Cargo.toml">
[workspace]
members = ["crates/pycandle", "crates/pycandle-core", "crates/pycandle-audio", "dx_simulation"]
resolver = "2"

[workspace.package]
version = "0.1.0"
edition = "2024"
license = "MIT"

[workspace.dependencies]
# Candle ML framework
candle-core = "0.9.1"
candle-nn = "0.9.1"
candle-transformers = "0.9.1"

# Serialization
safetensors = "0.5.2"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# CLI & utilities
clap = { version = "4.4", features = ["derive"] }
colored = "2.0"
thiserror = "1.0"
anyhow = "1.0"
walkdir = "2.4"
regex = "1.10"
realfft = "3.3"
num-complex = "0.4"
hf-hub = "0.4.0"
tokenizers = "0.20"
hound = "3.5"

# Internal crates
pycandle-core = { path = "crates/pycandle-core" }
pycandle-audio = { path = "crates/pycandle-audio" }
</file>

<file path="crates/pycandle-core/src/lib.rs">
//! PyCandle Core Library
//!
//! Core functionality for PyTorch  Candle porting with parity verification.
//!
//! # Features
//! - `PyChecker` for layer-wise verification against golden tensors
//! - `py_check!` macro for embedded verification in generated code
//! - Layer implementations: BatchNorm, LSTM, activations
//! - Code generation from manifests

mod checker;
pub mod codegen;
pub mod gpt2;
pub mod layers;
pub mod samplers;
pub mod weights;

pub use checker::{ComparisonResult, LayerMeta, PyChecker, VerificationMode};
pub use layers::*;
pub use samplers::*;
pub use weights::{WeightExtractor, WeightMapper};

/// Verify tensor against golden record, panics on mismatch
#[macro_export]
macro_rules! py_check {
    ($checker:expr, $name:expr, $tensor:expr) => {
        if let Some(ref c) = $checker {
            c.verify($name, $tensor).expect("Parity Check Failed");
        }
    };
}
</file>

<file path="crates/pycandle/Cargo.toml">
[package]
name = "pycandle"
description = "CLI for PyTorch  Candle porting with layer-wise parity verification"
version.workspace = true
edition.workspace = true
license.workspace = true

[[bin]]
name = "pycandle"
path = "src/main.rs"

[dependencies]
pycandle-core.workspace = true
candle-core.workspace = true
clap.workspace = true
colored.workspace = true
anyhow.workspace = true
serde.workspace = true
serde_json.workspace = true
walkdir.workspace = true
regex.workspace = true
ratatui = "0.29.0"
crossterm = "0.28.1"
toml = "0.8"
</file>

<file path="crates/pycandle-core/src/codegen/mod.rs">
//! Code generation from PyTorch manifests to Candle Rust code
//!
//! This module generates idiomatic Rust code from recorded PyTorch model manifests.

pub mod gpt2;

use crate::LayerMeta;
use serde::Serialize;
use std::collections::HashMap;

// ============================================================================
// Internal Types for Codegen
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ReturnType {
    Tensor,
    Tuple,
    Vec,
}

// ============================================================================
// JSON Output Structs for Analysis
// ============================================================================

#[derive(Serialize, Debug)]
pub struct AnalysisResult {
    pub supported: usize,
    pub unsupported: usize,
    pub total: usize,
    pub coverage_percent: f32,
    pub gaps: Vec<GapInfo>,
    pub layers: Vec<LayerInfo>,
}

#[derive(Serialize, Debug)]
pub struct GapInfo {
    pub module_type: String,
    pub count: usize,
    pub suggestion: String,
}

#[derive(Serialize, serde::Deserialize, Debug, Clone)]
pub struct LayerInfo {
    pub name: String,
    pub module_type: String,
    pub supported: bool,
    pub input_shapes: Vec<Vec<usize>>,
    pub output_shapes: Vec<Vec<usize>>,
}

#[derive(serde::Deserialize, Debug, Clone)]
pub struct GraphNode {
    pub name: String,
    pub op: String,
    pub target: String,
    pub args: Vec<serde_json::Value>,
    pub module_type: Option<String>,
}

#[derive(Serialize, serde::Deserialize, Debug, Clone, Default)]
pub struct SymbolicConfig {
    pub dims: HashMap<String, usize>,
}

/// Code generator that converts manifests to Rust code
pub struct Codegen {
    pub manifest: HashMap<String, LayerMeta>,
    pub hints: Option<HashMap<String, usize>>,
    pub graph_nodes: Vec<GraphNode>,
    pub stateful: bool,
    config: SymbolicConfig,
}

impl Codegen {
    pub fn new(
        manifest: HashMap<String, LayerMeta>,
        hints: Option<HashMap<String, usize>>,
    ) -> Self {
        let mut slf = Self {
            manifest,
            hints: hints.clone(),
            graph_nodes: Vec::new(),
            stateful: false,
            config: SymbolicConfig::default(),
        };
        slf.config = slf.extract_symbolic_config();
        slf
    }

    pub fn with_graph(mut self, graph_nodes: Vec<GraphNode>) -> Self {
        self.graph_nodes = graph_nodes;
        self
    }

    pub fn with_stateful(mut self, stateful: bool) -> Self {
        self.stateful = stateful;
        self
    }

    pub fn extract_symbolic_config(&self) -> SymbolicConfig {
        let mut dims = self.hints.clone().unwrap_or_default();

        for meta in self.manifest.values() {
            // GPT2 specific extraction
            if let Some(v) = meta.config.get("vocab_size").and_then(|v| v.as_u64()) {
                dims.entry("vocab_size".to_string()).or_insert(v as usize);
            }
            if let Some(v) = meta.config.get("n_embd").and_then(|v| v.as_u64()) {
                dims.entry("hidden_dim".to_string()).or_insert(v as usize);
            }
            if let Some(v) = meta.config.get("n_head").and_then(|v| v.as_u64()) {
                dims.entry("n_head".to_string()).or_insert(v as usize);
            }
            if let Some(v) = meta.config.get("n_layer").and_then(|v| v.as_u64()) {
                dims.entry("n_layers".to_string()).or_insert(v as usize);
            }
            if let Some(v) = meta.config.get("n_positions").and_then(|v| v.as_u64()) {
                dims.entry("context_length".to_string())
                    .or_insert(v as usize);
            }

            // Generic extraction
            match meta.module_type.as_str() {
                "Embedding" => {
                    if let Some(n) = meta.config.get("num_embeddings").and_then(|v| v.as_u64()) {
                        dims.entry("vocab_size".to_string()).or_insert(n as usize);
                    }
                    if let Some(d) = meta.config.get("embedding_dim").and_then(|v| v.as_u64()) {
                        dims.entry("hidden_dim".to_string()).or_insert(d as usize);
                    }
                }
                "Linear" | "LoRACompatibleLinear" => {
                    // If out_features is high (like 30000+), it's likely a vocab_size (lm_head)
                    if let Some(out_f) = meta.config.get("out_features").and_then(|v| v.as_u64()) {
                        if out_f > 30000 {
                            dims.entry("vocab_size".to_string())
                                .or_insert(out_f as usize);
                        }
                    }
                }
                _ => {}
            }
        }

        SymbolicConfig { dims }
    }

    fn render_dim(&self, value: usize, preferred_name: &str) -> String {
        // Try preferred name first
        if !preferred_name.is_empty() {
            if let Some(&v) = self.config.dims.get(preferred_name) {
                if v == value {
                    return format!("config.{}", preferred_name);
                }
            }
        }

        // Try exact value match in any dim
        for (name, &v) in &self.config.dims {
            if v == value {
                return format!("config.{}", name);
            }
        }

        value.to_string()
    }

    fn sanitize_name(&self, name: &str) -> String {
        // Handle ONNX paths like /layers/0/Gather_1_output -> gather_1
        if name.contains('/') {
            let clean = name.trim_start_matches('/');
            let parts: Vec<&str> = clean.split('/').collect();
            let last = parts.last().unwrap_or(&name);
            let mut sanitized = last.to_lowercase().replace("_output", "");

            if sanitized.starts_with("node_") {
                sanitized = sanitized.replace("node_", "x_");
            }

            // Ensure valid identifier
            if sanitized
                .chars()
                .next()
                .map(|c| !c.is_alphabetic())
                .unwrap_or(true)
            {
                return format!("x_{}", sanitized);
            }
            return sanitized;
        }

        // Standard PyTorch names: encoder.layers.0 -> encoder_layers_0
        let mut sanitized = name.replace(".", "_").replace("-", "_");
        if sanitized.starts_with("node_") {
            sanitized = sanitized.replace("node_", "x_");
        }

        // Ensure valid identifier
        if sanitized
            .chars()
            .next()
            .map(|c| !c.is_alphabetic() && c != '_')
            .unwrap_or(true)
        {
            return format!("x_{}", sanitized);
        }

        sanitized
    }

    /// Analyze the manifest and return a structured result for JSON output
    pub fn analyze(&self) -> AnalysisResult {
        let mut supported = 0;
        let mut unsupported = 0;
        let mut gap_counts: HashMap<String, usize> = HashMap::new();
        let mut layers = Vec::new();

        for (name, meta) in &self.manifest {
            if !meta.is_leaf {
                continue;
            }

            let is_supported = self.is_supported(&meta.module_type);
            if is_supported {
                supported += 1;
            } else {
                unsupported += 1;
                *gap_counts.entry(meta.module_type.clone()).or_default() += 1;
            }

            layers.push(LayerInfo {
                name: name.clone(),
                module_type: meta.module_type.clone(),
                supported: is_supported,
                input_shapes: meta.input_shapes.clone(),
                output_shapes: meta.output_shapes.clone(),
            });
        }

        // Sort layers by name for consistent output
        layers.sort_by(|a, b| a.name.cmp(&b.name));

        let gaps: Vec<GapInfo> = gap_counts
            .into_iter()
            .map(|(t, c)| GapInfo {
                suggestion: self.get_suggestion(&t),
                module_type: t,
                count: c,
            })
            .collect();

        let total = supported + unsupported;
        let coverage_percent = if total > 0 {
            (supported as f32 / total as f32) * 100.0
        } else {
            100.0
        };

        AnalysisResult {
            supported,
            unsupported,
            total,
            coverage_percent,
            gaps,
            layers,
        }
    }

    /// Check if a module type is supported by the codegen
    pub fn is_supported(&self, module_type: &str) -> bool {
        // Check GPT2 helper first
        if gpt2::map_type(module_type).is_some() {
            return true;
        }

        matches!(
            module_type,
            "Linear"
                | "Conv1d"
                | "LayerNorm"
                | "Embedding"
                | "ReLU"
                | "GELU"
                | "Sigmoid"
                | "Tanh"
                | "ELU"
                | "LeakyReLU"
                | "Snake"
                | "BatchNorm1d"
                | "BatchNorm2d"
                | "LSTM"
                | "Mish"
                | "SiLU"
                | "CausalConv1d"
                | "Transpose"
                | "Conv1D"
                | "Dropout"
                | "NewGELUActivation"
                | "LoRACompatibleLinear"
                | "SinusoidalPosEmb"
        )
    }

    /// Get implementation suggestion for an unsupported module type
    pub fn get_suggestion(&self, module_type: &str) -> String {
        match module_type {
            "LSTM" => "Use /add-lstm workflow".to_string(),
            "BatchNorm1d" | "BatchNorm2d" => "Use /add-batchnorm workflow".to_string(),
            "Snake" | "ELU" => "Use /add-activations workflow".to_string(),
            _ => format!("Implement {} manually", module_type),
        }
    }

    pub fn generate_model_rs(&self, model_name: &str) -> String {
        let mut code = String::new();
        code.push_str("use candle_core::{Result, Tensor, IndexOp, Shape};\n");
        code.push_str("use candle_nn::{Module, VarBuilder};\n");
        code.push_str("use pycandle_core::{PyChecker, py_check, VerificationMode, layers::*};\n\n");

        if self.stateful {
            code.push_str(
                r#"#[derive(Debug, Clone)]
pub struct KVCache {
    pub k: Tensor,
    pub v: Tensor,
}

"#,
            );
        }

        code.push_str(&self.generate_config_struct());
        code.push_str("\n");
        code.push_str(&self.generate_struct(model_name));
        code.push_str("\n");
        code.push_str(&self.generate_impl(model_name));

        code
    }

    fn generate_config_struct(&self) -> String {
        let mut lines = vec!["pub struct Config {".to_string()];
        let mut dims: Vec<_> = self.config.dims.iter().collect();
        dims.sort_by_key(|(k, _)| *k);

        for (name, value) in dims {
            lines.push(format!("    pub {}: usize, // {}", name, value));
        }
        lines.push("}".to_string());
        lines.join("\n")
    }

    fn has_gpt2_types(&self) -> bool {
        self.manifest
            .values()
            .any(|meta| gpt2::is_gpt2_type(&meta.module_type))
    }

    pub fn generate_struct(&self, model_name: &str) -> String {
        let mut code = format!("pub struct {} {{\n", model_name);

        let mut sorted_keys: Vec<_> = self.manifest.keys().collect();
        sorted_keys.sort();

        for name in sorted_keys {
            let meta = &self.manifest[name];
            if meta.is_leaf {
                let rust_type = self.map_type(&meta.module_type);
                code.push_str(&format!(
                    "    pub {}: {},\n",
                    self.sanitize_name(name),
                    rust_type
                ));
            }
        }

        code.push_str("    pub checker: Option<PyChecker>,\n");
        if self.stateful {
            code.push_str("    pub cache: std::cell::RefCell<Vec<Option<KVCache>>>,\n");
        }
        code.push_str("}\n");
        code
    }

    fn map_type(&self, py_type: &str) -> String {
        // Check GPT2 helper first
        if let Some(t) = gpt2::map_type(py_type) {
            return t;
        }

        // Core types
        match py_type {
            "Linear" => "candle_nn::Linear".to_string(),
            "Conv1d" => "candle_nn::Conv1d".to_string(),
            "LayerNorm" => "candle_nn::LayerNorm".to_string(),
            "Embedding" => "candle_nn::Embedding".to_string(),
            // Activations
            "ReLU" => "ReLU".to_string(),
            "GELU" => "GELU".to_string(),
            "Sigmoid" => "Sigmoid".to_string(),
            "Tanh" => "Tanh".to_string(),
            "ELU" => "ELU".to_string(),
            "LeakyReLU" => "LeakyReLU".to_string(),
            "Snake" => "Snake".to_string(),
            "BatchNorm1d" => "BatchNorm1d".to_string(),
            "BatchNorm2d" => "BatchNorm2d".to_string(),
            "LSTM" => "LSTM".to_string(),
            "Mish" => "Mish".to_string(),
            "SiLU" => "SiLU".to_string(),
            "CausalConv1d" => "CausalConv1d".to_string(),
            "Transpose" => "Transpose".to_string(),
            "Conv1D" => "candle_nn::Linear".to_string(),
        "Dropout" => "Dropout".to_string(),
        "NewGELUActivation" => "candle_nn::Activation".to_string(),
        "LoRACompatibleLinear" => "candle_nn::Linear".to_string(),
            "SinusoidalPosEmb" => "SinusoidalPosEmb".to_string(),
            _ => format!("() /* TODO: {} */", py_type),
        }
    }

    pub fn generate_impl(&self, model_name: &str) -> String {
        let mut code = format!("impl {} {{\n", model_name);

        // Load method
        code.push_str("    #[allow(unused_variables)]\n");
        code.push_str(&format!(
            "    pub fn load(config: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {{\n"
        ));

        if self.has_gpt2_types() {
            code.push_str(
                r#"        let gpt2_cfg = pycandle_core::gpt2::Config {
            vocab_size: config.vocab_size,
            context_length: config.context_length,
            emb_dim: config.hidden_dim,
            n_heads: config.n_head,
            n_layers: config.n_layers,
            ..Default::default()
        };
"#,
            );
        }

        let mut sorted_keys: Vec<_> = self.manifest.keys().collect();
        sorted_keys.sort();

        for name in &sorted_keys {
            let meta = self.manifest.get(*name).unwrap();
            if meta.is_leaf {
                let field = self.sanitize_name(name);
                let init = self.generate_init(name, meta);
                code.push_str(&format!("        let {} = {};\n", field, init));
            }
        }

        let mut fields = vec![];
        for name in &sorted_keys {
            if self.manifest.get(*name).unwrap().is_leaf {
                fields.push(self.sanitize_name(name));
            }
        }
        fields.push("checker".to_string());

        code.push_str(&format!("        Ok(Self {{ {}", fields.join(", ")));
        if self.stateful {
            code.push_str(", cache: std::cell::RefCell::new(Vec::new())");
        }
        code.push_str(" })\n");
        code.push_str("    }\n\n");

        // Forward methods
        if self.graph_nodes.is_empty() {
            // Sequential fallback
            code.push_str("    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {\n");
            if self.stateful {
                code.push_str(
                    "        self.forward_with_cache(xs, &mut self.cache.borrow_mut())\n",
                );
                code.push_str("    }\n\n");
                code.push_str("    pub fn forward_with_cache(&self, xs: &Tensor, cache: &mut Vec<Option<KVCache>>) -> Result<Tensor> {\n");
            }
            code.push_str("        let mut x = xs.clone();\n");

            for name in &sorted_keys {
                let meta = self.manifest.get(*name).unwrap();
                if !meta.is_leaf {
                    continue;
                }
                let clean_name = self.sanitize_name(name);
                let forward_call = if self.map_type(&meta.module_type) == "LSTM" {
                    format!("self.{}.forward(&x)?.0", clean_name)
                } else {
                    format!("self.{}.forward(&x)?", clean_name)
                };
                code.push_str(&format!("\n        // Layer: {}\n", name));
                code.push_str(&format!("        x = {};\n", forward_call));
                code.push_str(&format!(
                    "        py_check!(self.checker, \"{}\", &x);\n",
                    name
                ));
            }

            code.push_str("\n        Ok(x)\n");
            code.push_str("    }\n");
        } else {
            // DAG / torch.fx based forward
            code.push_str(&self.generate_forward_dag(&self.graph_nodes));
        }
        code.push_str("}\n");

        code
    }

    fn generate_forward_dag(&self, nodes: &[GraphNode]) -> String {
        let mut placeholders = Vec::new();
        for node in nodes {
            if node.op == "placeholder" {
                placeholders.push(node.name.clone());
            }
        }

        let mut code = String::new();
        let ret_type = self.get_forward_return_type();

        let inputs = if placeholders.len() <= 1 {
            "xs: &Tensor".to_string()
        } else {
            placeholders
                .iter()
                .enumerate()
                .map(|(i, _)| format!("xs{}: &Tensor", i))
                .collect::<Vec<_>>()
                .join(", ")
        };

        code.push_str(&format!(
            "    pub fn forward(&self, {}) -> {} {{\n",
            inputs, ret_type
        ));

        // Map python placeholder names to Rust input variables
        let mut var_map = HashMap::new();
        let mut node_types = HashMap::new();

        let mut placeholder_idx = 0;
        for node in nodes {
            match node.op.as_str() {
                "placeholder" => {
                    let var_name = if placeholders.len() <= 1 {
                        "xs".to_string()
                    } else {
                        format!("xs{}", placeholder_idx)
                    };
                    var_map.insert(node.name.clone(), var_name);
                    node_types.insert(node.name.clone(), ReturnType::Tensor);
                    placeholder_idx += 1;
                }
                "call_module" => {
                    let clean_name = self.sanitize_name(&node.target);
                    let var_name = self.sanitize_name(&node.name);
                    let input_var = if let Some(arg0) = node.args.get(0) {
                        match arg0 {
                            serde_json::Value::String(s) => {
                                var_map.get(s).cloned().unwrap_or(s.clone())
                            }
                            _ => {
                                let first_p = placeholders.get(0).and_then(|p| var_map.get(p));
                                first_p.cloned().unwrap_or("xs".to_string())
                            }
                        }
                    } else {
                        let first_p = placeholders.get(0).and_then(|p| var_map.get(p));
                        first_p.cloned().unwrap_or("xs".to_string())
                    };

                    let module_type = node.module_type.clone().unwrap_or_default();
                    let is_lstm = self.map_type(&module_type) == "LSTM";

                    let (forward_call, return_type) = if is_lstm {
                        // LSTM returns (output, (h, c))
                        (
                            format!("self.{}.forward(&{})?", clean_name, input_var),
                            ReturnType::Tuple,
                        )
                    } else {
                        let meta = self.manifest.get(&node.target);
                        let multi = meta.map(|m| m.output_shapes.len() > 1).unwrap_or(false);
                        if multi {
                            (
                                format!("self.{}.forward(&{})?", clean_name, input_var),
                                ReturnType::Tuple,
                            )
                        } else {
                            (
                                format!("self.{}.forward(&{})?", clean_name, input_var),
                                ReturnType::Tensor,
                            )
                        }
                    };

                    code.push_str(&format!("        let {} = {};\n", var_name, forward_call));

                    // Only do parity check on single Tensors for now to avoid tuple mismatch in py_check!
                    if return_type == ReturnType::Tensor {
                        code.push_str(&format!(
                            "        py_check!(self.checker, \"{}\", &{});\n",
                            node.target, var_name
                        ));
                    }

                    var_map.insert(node.name.clone(), var_name.clone());
                    node_types.insert(node.name.clone(), return_type);
                }
                "call_function" => {
                    let var_name = self.sanitize_name(&node.name);
                    let mut resolved_args = Vec::new();
                    for arg in &node.args {
                        resolved_args.push(self.resolve_fx_arg(arg, &var_map));
                    }

                    let (expr, return_type) =
                        self.map_fx_op(&node.target, &resolved_args, &var_map, &node_types);
                    code.push_str(&format!("        let {} = {};\n", var_name, expr));
                    var_map.insert(node.name.clone(), var_name);
                    node_types.insert(node.name.clone(), return_type);
                }
                "call_method" => {
                    let var_name = self.sanitize_name(&node.name);
                    let mut resolved_args = Vec::new();
                    for arg in &node.args {
                        resolved_args.push(self.resolve_fx_arg(arg, &var_map));
                    }

                    if !resolved_args.is_empty() {
                        let self_var_name = match &node.args[0] {
                            serde_json::Value::String(s) => s.clone(),
                            _ => "".to_string(),
                        };
                        let self_var = &resolved_args[0];
                        let method_args = &resolved_args[1..];
                        let (expr, return_type) = self.map_fx_method(
                            &node.target,
                            self_var,
                            &self_var_name,
                            method_args,
                            &node_types,
                        );
                        code.push_str(&format!("        let {} = {};\n", var_name, expr));
                        var_map.insert(node.name.clone(), var_name);
                        node_types.insert(node.name.clone(), return_type);
                    }
                }
                "output" => {
                    let out_var = if let Some(arg0) = node.args.get(0) {
                        match arg0 {
                            serde_json::Value::String(s) => {
                                var_map.get(s).cloned().unwrap_or(s.clone())
                            }
                            serde_json::Value::Array(arr) => {
                                let items: Vec<String> = arr
                                    .iter()
                                    .map(|v| self.resolve_fx_arg(v, &var_map))
                                    .collect();
                                format!("({})", items.join(", "))
                            }
                            _ => {
                                let first_p = placeholders.get(0).and_then(|p| var_map.get(p));
                                first_p.cloned().unwrap_or("xs".to_string())
                            }
                        }
                    } else {
                        let first_p = placeholders.get(0).and_then(|p| var_map.get(p));
                        first_p.cloned().unwrap_or("xs".to_string())
                    };
                    code.push_str(&format!("        Ok({})\n", out_var));
                }
                _ => {}
            }
        }

        code.push_str("    }\n");
        code
    }

    fn resolve_fx_arg(&self, arg: &serde_json::Value, var_map: &HashMap<String, String>) -> String {
        match arg {
            serde_json::Value::String(s) => var_map.get(s).cloned().unwrap_or(s.clone()),
            serde_json::Value::Array(arr) => {
                let items: Vec<String> = arr
                    .iter()
                    .map(|v| self.resolve_fx_arg(v, var_map))
                    .collect();
                format!("&[{}]", items.join(", "))
            }
            _ => arg.to_string(),
        }
    }

    fn map_fx_op(
        &self,
        target: &str,
        args: &[String],
        var_map: &HashMap<String, String>,
        node_types: &HashMap<String, ReturnType>,
    ) -> (String, ReturnType) {
        let target_lower = target.to_lowercase();

        // Common binary ops
        if target_lower.contains("add") && args.len() >= 2 {
            return (
                format!("(&{} + &{})?", args[0], args[1]),
                ReturnType::Tensor,
            );
        }
        if target_lower.contains("sub") && args.len() >= 2 {
            return (
                format!("(&{} - &{})?", args[0], args[1]),
                ReturnType::Tensor,
            );
        }
        if target_lower.contains("mul") && args.len() >= 2 {
            return (
                format!("(&{} * &{})?", args[0], args[1]),
                ReturnType::Tensor,
            );
        }
        if (target_lower.contains("div") || target_lower.contains("truediv")) && args.len() >= 2 {
            return (
                format!("(&{} / &{})?", args[0], args[1]),
                ReturnType::Tensor,
            );
        }

        // Functional ops
        match target {
            "torch.cat" | "cat" => {
                let dim = args.get(1).map(|s| s.as_str()).unwrap_or("1");
                let mut tensors = args[0].clone();
                if tensors.starts_with("&[") {
                    // Convert &[x, y] to &[&x, &y] for Candle's cat
                    let content = &tensors[2..tensors.len() - 1];
                    let items: Vec<String> =
                        content.split(", ").map(|s| format!("&{}", s)).collect();
                    tensors = format!("&[{}]", items.join(", "));
                }
                (
                    format!("Tensor::cat({}, {})?", tensors, dim),
                    ReturnType::Tensor,
                )
            }
            "torch.chunk" | "chunk" => {
                let chunks = args.get(1).map(|s| s.as_str()).unwrap_or("2");
                let dim = args.get(2).map(|s| s.as_str()).unwrap_or("0");
                (
                    format!("{}.chunk({}, {})?", args[0], chunks, dim),
                    ReturnType::Vec,
                )
            }
            "torch.split" | "split" => {
                let split_size = args.get(1).map(|s| s.as_str()).unwrap_or("1");
                let dim = args.get(2).map(|s| s.as_str()).unwrap_or("0");
                (
                    format!("{}.split({}, {})?", args[0], split_size, dim),
                    ReturnType::Vec,
                )
            }
            "torch.relu" | "relu" => (format!("{}.relu()?", args[0]), ReturnType::Tensor),
            "torch.sigmoid" | "sigmoid" => (
                format!("candle_nn::ops::sigmoid(&{})?", args[0]),
                ReturnType::Tensor,
            ),
            "torch.tanh" | "tanh" => (format!("{}.tanh()?", args[0]), ReturnType::Tensor),
            "torch.squeeze" | "squeeze" => {
                if args.len() > 1 {
                    (
                        format!("{}.squeeze({})?", args[0], args[1]),
                        ReturnType::Tensor,
                    )
                } else {
                    (format!("{}.squeeze(0)?", args[0]), ReturnType::Tensor)
                }
            }
            "torch.unsqueeze" | "unsqueeze" => (
                format!("{}.unsqueeze({})?", args[0], args[1]),
                ReturnType::Tensor,
            ),
            "torch.pow" | "pow" => (
                format!("{}.powf({})?", args[0], args[1]),
                ReturnType::Tensor,
            ),
            "torch.sqrt" | "sqrt" => (format!("{}.sqrt()?", args[0]), ReturnType::Tensor),
            "torch.exp" | "exp" => (format!("{}.exp()?", args[0]), ReturnType::Tensor),
            "torch.log" | "log" => (format!("{}.log()?", args[0]), ReturnType::Tensor),
            "torch.abs" | "abs" => (format!("{}.abs()?", args[0]), ReturnType::Tensor),
            "torch.sum" | "sum" => {
                if args.len() > 1 {
                    (format!("{}.sum({})?", args[0], args[1]), ReturnType::Tensor)
                } else {
                    (format!("{}.sum_all()?", args[0]), ReturnType::Tensor)
                }
            }
            "torch.mean" | "mean" => {
                if args.len() > 1 {
                    (
                        format!("{}.mean({})?", args[0], args[1]),
                        ReturnType::Tensor,
                    )
                } else {
                    (format!("{}.mean_all()?", args[0]), ReturnType::Tensor)
                }
            }
            "torch.transpose" => (
                format!("{}.transpose({}, {})?", args[0], args[1], args[2]),
                ReturnType::Tensor,
            ),
            "torch.reshape" => (
                format!("{}.reshape({})?", args[0], args[1]),
                ReturnType::Tensor,
            ),
            "torch.permute" => (
                format!("{}.permute({})?", args[0], args[1]),
                ReturnType::Tensor,
            ),
            "operator.getitem" => {
                let idx = &args[1];

                // Find the source variable name to check its type
                let src_name = var_map
                    .iter()
                    .find(|(_, v)| *v == &args[0])
                    .map(|(k, _)| k.as_str())
                    .unwrap_or(&args[0]);

                let src_type = node_types
                    .get(src_name)
                    .cloned()
                    .unwrap_or(ReturnType::Tensor);

                match src_type {
                    ReturnType::Tuple => {
                        // Tuple indexing: x.0, x.1
                        if let Ok(i) = idx.parse::<usize>() {
                            (format!("{}.{}", args[0], i), ReturnType::Tensor)
                        } else {
                            (format!("{}.get({})?", args[0], args[1]), ReturnType::Tensor)
                        }
                    }
                    ReturnType::Vec => {
                        // Vec indexing: x[0]
                        if let Ok(i) = idx.parse::<usize>() {
                            (format!("{}[{}].clone()", args[0], i), ReturnType::Tensor)
                        } else {
                            (format!("{}.get({})?", args[0], args[1]), ReturnType::Tensor)
                        }
                    }
                    ReturnType::Tensor => {
                        if idx.contains("slice(") || idx == "None" || idx.starts_with("&[") {
                            // Map to .i() for indexing/slicing
                            let mut cleaned = idx.clone();
                            if cleaned.starts_with("&[") {
                                cleaned = cleaned[2..cleaned.len() - 1].to_string();
                            }

                            let items: Vec<String> = cleaned
                                .split(",")
                                .enumerate()
                                .map(|(i, s)| self.parse_slice_item(s.trim(), &args[0], i))
                                .collect();

                            let final_idx = if items.len() == 1 {
                                items[0].clone()
                            } else {
                                format!("({})", items.join(", "))
                            };

                            (format!("{}.i({})?", args[0], final_idx), ReturnType::Tensor)
                        } else {
                            (format!("{}.get({})?", args[0], args[1]), ReturnType::Tensor)
                        }
                    }
                }
            }
            _ => {
                if target_lower.contains("add") && args.len() >= 2 {
                    return (
                        format!("(&{} + &{})?", args[0], args[1]),
                        ReturnType::Tensor,
                    );
                }
                (
                    format!("todo!(/* function: {} */)", target),
                    ReturnType::Tensor,
                )
            }
        }
    }

    fn parse_slice_item(&self, item: &str, tensor_name: &str, dim_idx: usize) -> String {
        if item == "None" {
            return "..".to_string();
        }

        // Handle single negative index
        if let Ok(val) = item.parse::<isize>() {
            if val < 0 {
                return format!("{}.dim({})? - {}", tensor_name, dim_idx, val.abs());
            }
            return item.to_string();
        }

        if !item.contains("slice(") {
            return item.to_string();
        }

        // Parse slice(start, stop, step)
        let content = item
            .strip_prefix("slice(")
            .and_then(|s| s.strip_suffix(")"))
            .unwrap_or(item);
        let parts: Vec<&str> = content.split(",").map(|s| s.trim()).collect();

        let start_str = parts.get(0).copied().unwrap_or("None");
        let stop_str = parts.get(1).copied().unwrap_or("None");

        let start = if let Ok(val) = start_str.parse::<isize>() {
            if val < 0 {
                format!("{}.dim({})? - {}", tensor_name, dim_idx, val.abs())
            } else {
                start_str.to_string()
            }
        } else {
            start_str.to_string()
        };

        let stop = if let Ok(val) = stop_str.parse::<isize>() {
            if val < 0 {
                format!("{}.dim({})? - {}", tensor_name, dim_idx, val.abs())
            } else {
                stop_str.to_string()
            }
        } else {
            stop_str.to_string()
        };

        match (start.as_str(), stop.as_str()) {
            ("None", "None") => "..".to_string(),
            ("None", stop) => format!("..{}", stop),
            (start, "None") => format!("{}..", start),
            (start, stop) => format!("{}..{}", start, stop),
        }
    }

    fn map_fx_method(
        &self,
        method: &str,
        self_var: &str,
        self_var_name: &str,
        args: &[String],
        node_types: &HashMap<String, ReturnType>,
    ) -> (String, ReturnType) {
        let _src_type = node_types
            .get(self_var_name)
            .cloned()
            .unwrap_or(ReturnType::Tensor);

        match method {
            "view" | "reshape" => {
                if args.len() == 1 && args[0].starts_with("&[") {
                    (
                        format!("{}.reshape({})?", self_var, args[0]),
                        ReturnType::Tensor,
                    )
                } else {
                    (
                        format!("{}.reshape(vec![{}])?", self_var, args.join(", ")),
                        ReturnType::Tensor,
                    )
                }
            }
            "flatten" => (format!("{}.flatten_all()?", self_var), ReturnType::Tensor),
            "transpose" => (
                format!("{}.transpose({}, {})?", self_var, args[0], args[1]),
                ReturnType::Tensor,
            ),
            "permute" => (
                format!("{}.permute({})?", self_var, args[0]),
                ReturnType::Tensor,
            ),
            "unsqueeze" => (
                format!("{}.unsqueeze({})?", self_var, args[0]),
                ReturnType::Tensor,
            ),
            "squeeze" => (
                format!("{}.squeeze({})?", self_var, args[0]),
                ReturnType::Tensor,
            ),
            "chunk" => {
                let chunks = args.get(0).map(|s| s.as_str()).unwrap_or("2");
                let dim = args.get(1).map(|s| s.as_str()).unwrap_or("0");
                (
                    format!("{}.chunk({}, {})?", self_var, chunks, dim),
                    ReturnType::Vec,
                )
            }
            "split" => {
                let split_size = args.get(0).map(|s| s.as_str()).unwrap_or("1");
                let dim = args.get(1).map(|s| s.as_str()).unwrap_or("1");
                (
                    format!("{}.split({}, {})?", self_var, split_size, dim),
                    ReturnType::Vec,
                )
            }
            "t" => (format!("{}.t()?", self_var), ReturnType::Tensor),
            "contiguous" => (format!("{}.contiguous()?", self_var), ReturnType::Tensor),
            "size" => {
                if args.is_empty() {
                    (format!("{}.dims().to_vec()", self_var), ReturnType::Tensor)
                } else {
                    (
                        format!("{}.dim({})?", self_var, args[0]),
                        ReturnType::Tensor,
                    )
                }
            }
            _ => (
                format!("todo!(/* method: {} on {} */)", method, self_var),
                ReturnType::Tensor,
            ),
        }
    }

    fn infer_linear_dims(&self, meta: &LayerMeta) -> (usize, usize) {
        let in_f = meta.config.get("in_features").and_then(|v| v.as_u64());
        let out_f = meta.config.get("out_features").and_then(|v| v.as_u64());

        if let (Some(i), Some(o)) = (in_f, out_f) {
            return (i as usize, o as usize);
        }

        // Fallback to shapes if config is missing (common in ONNX or custom layers)
        let in_shape = meta
            .input_shapes
            .first()
            .and_then(|s| s.last())
            .copied()
            .unwrap_or(0);
        let out_shape = meta
            .output_shapes
            .first()
            .and_then(|s| s.last())
            .copied()
            .unwrap_or(0);

        (in_shape, out_shape)
    }

    fn generate_init(&self, layer_name: &str, meta: &LayerMeta) -> String {
        // Check GPT2 helper first
        if let Some(init) = gpt2::generate_init(layer_name, meta, &self.config.dims) {
            return init;
        }

        // Core types
        match meta.module_type.as_str() {
            "Linear" | "LoRACompatibleLinear" | "Conv1D" => {
                let (in_f_val, out_f_val) = self.infer_linear_dims(meta);
                let in_f = self.render_dim(in_f_val, "hidden_dim");
                let out_f = self.render_dim(out_f_val, "");
                let bias = meta.config["bias"].as_bool().unwrap_or(true);

                // Check for weight shape to detect transpose needs
                let needs_transpose = meta
                    .config
                    .get("weight_shape")
                    .and_then(|v| v.as_array())
                    .map(|arr| {
                        let dims: Vec<u64> = arr.iter().filter_map(|x| x.as_u64()).collect();
                        // PyTorch Linear stores (out, in), if we see (in, out) we need transpose
                        dims.len() == 2 && dims[0] == in_f_val as u64 && dims[1] == out_f_val as u64
                    })
                    .unwrap_or(false);

                if needs_transpose {
                    format!(
                        "{{ let w = vb.pp(\"{}\").get(({}, {}), \"weight\")?.t()?; \
                         let b = {}; candle_nn::Linear::new(w, b) }}",
                        layer_name,
                        in_f,
                        out_f,
                        if bias {
                            format!("Some(vb.pp(\"{}\").get({}, \"bias\")?)", layer_name, out_f)
                        } else {
                            "None".to_string()
                        }
                    )
                } else if bias {
                    format!(
                        "candle_nn::linear({}, {}, vb.pp(\"{}\"))?",
                        in_f, out_f, layer_name
                    )
                } else {
                    format!(
                        "candle_nn::linear_no_bias({}, {}, vb.pp(\"{}\"))?",
                        in_f, out_f, layer_name
                    )
                }
            }
            "Conv1d" => {
                let in_c = self.render_dim(
                    meta.config["in_channels"].as_u64().unwrap_or(0) as usize,
                    "",
                );
                let out_c = self.render_dim(
                    meta.config["out_channels"].as_u64().unwrap_or(0) as usize,
                    "",
                );
                let k = meta.config["kernel_size"].as_u64().unwrap_or(0);
                let s = meta.config["stride"].as_u64().unwrap_or(1);
                let p = meta.config["padding"].as_u64().unwrap_or(0);
                format!(
                    "candle_nn::conv1d({}, {}, {}, candle_nn::Conv1dConfig {{ stride: {}, padding: {}, ..Default::default() }}, vb.pp(\"{}\"))?",
                    in_c, out_c, k, s, p, layer_name
                )
            }
            "LayerNorm" => {
                let shape: Vec<usize> =
                    serde_json::from_value(meta.config["normalized_shape"].clone())
                        .unwrap_or_default();
                let eps = meta.config["eps"].as_f64().unwrap_or(1e-5);
                // Use a single value if shape is [N], otherwise use a Slice
                let shape_str = if shape.len() == 1 {
                    format!("{}", shape[0])
                } else {
                    format!("Shape::from(vec!{:?})", shape)
                };
                format!(
                    "candle_nn::layer_norm({}, candle_nn::LayerNormConfig {{ eps: {:.1e}, ..Default::default() }}, vb.pp(\"{}\"))?",
                    shape_str, eps, layer_name
                )
            }
            "Embedding" => {
                let n = self.render_dim(
                    meta.config["num_embeddings"].as_u64().unwrap_or(0) as usize,
                    "vocab_size",
                );
                let d = self.render_dim(
                    meta.config["embedding_dim"].as_u64().unwrap_or(0) as usize,
                    "hidden_dim",
                );
                format!(
                    "candle_nn::embedding({}, {}, vb.pp(\"{}\"))?",
                    n, d, layer_name
                )
            }
            // Activations - stateless
            "ReLU" => "ReLU".to_string(),
            "GELU" => "GELU".to_string(),
            "Sigmoid" => "Sigmoid".to_string(),
            "Tanh" => "Tanh".to_string(),
            // Activations - parameterized
            "ELU" => {
                let alpha = meta
                    .config
                    .get("alpha")
                    .and_then(|v| v.as_f64())
                    .unwrap_or(1.0);
                format!("ELU::new({})", alpha)
            }
            "LeakyReLU" => {
                let slope = meta
                    .config
                    .get("negative_slope")
                    .and_then(|v| v.as_f64())
                    .unwrap_or(0.01);
                format!("LeakyReLU::new({})", slope)
            }
            "Snake" => {
                let in_features = meta
                    .config
                    .get("in_features")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0);
                format!("Snake::load(vb.pp(\"{}\"), {})?", layer_name, in_features)
            }
            "BatchNorm1d" => {
                let num_features = meta
                    .config
                    .get("num_features")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0) as usize;
                format!(
                    "BatchNorm1d::load(vb.pp(\"{}\"), {})?",
                    layer_name, num_features
                )
            }
            "BatchNorm2d" => {
                let num_features = meta
                    .config
                    .get("num_features")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0) as usize;
                format!(
                    "BatchNorm2d::load(vb.pp(\"{}\"), {})?",
                    layer_name, num_features
                )
            }
            "LSTM" => {
                let input_size = self.render_dim(
                    meta.config
                        .get("input_size")
                        .and_then(|v| v.as_u64())
                        .unwrap_or(0) as usize,
                    "hidden_dim",
                );
                let hidden_size = self.render_dim(
                    meta.config
                        .get("hidden_size")
                        .and_then(|v| v.as_u64())
                        .unwrap_or(0) as usize,
                    "",
                );
                let num_layers = self.render_dim(
                    meta.config
                        .get("num_layers")
                        .and_then(|v| v.as_u64())
                        .unwrap_or(1) as usize,
                    "n_layers",
                );
                format!(
                    "LSTM::load(vb.pp(\"{}\"), {}, {}, {})?",
                    layer_name, input_size, hidden_size, num_layers
                )
            }
            "CausalConv1d" => {
                let in_c = self.render_dim(
                    meta.config["in_channels"].as_u64().unwrap_or(0) as usize,
                    "",
                );
                let out_c = self.render_dim(
                    meta.config["out_channels"].as_u64().unwrap_or(0) as usize,
                    "",
                );
                let k = meta.config["kernel_size"].as_u64().unwrap_or(0);
                let s = meta.config["stride"].as_u64().unwrap_or(1);
                let bias = meta.config["bias"].as_bool().unwrap_or(true);
                format!(
                    "CausalConv1d::load(vb.pp(\"{}\"), {}, {}, {}, {}, {})?",
                    layer_name, in_c, out_c, k, s, bias
                )
            }
            "Mish" => "Mish".to_string(),
            "SiLU" => "SiLU".to_string(),
            // GPT2 specific
            "NewGELUActivation" => "candle_nn::Activation::NewGelu".to_string(),
            "Dropout" => "Dropout::new()".to_string(),
            "Transpose" => {
                let d0 = meta.config["dim0"].as_u64().unwrap_or(1);
                let d1 = meta.config["dim1"].as_u64().unwrap_or(2);
                format!("Transpose::new({}, {})", d0, d1)
            }
            "SinusoidalPosEmb" => {
                let dim = meta.output_shapes[0][1];
                format!("SinusoidalPosEmb::new({})", dim)
            }
            _ => format!(
                "todo!(\"Implement initialization for {}\")",
                meta.module_type
            ),
        }
    }

    fn get_forward_return_type(&self) -> String {
        if !self.graph_nodes.is_empty() {
            for node in &self.graph_nodes {
                if node.op == "output" {
                    if let Some(arg0) = node.args.get(0) {
                        if let Some(arr) = arg0.as_array() {
                            if arr.len() > 1 {
                                let tensors = vec!["Tensor"; arr.len()];
                                return format!("Result<({})>", tensors.join(", "));
                            }
                        }
                    }
                }
            }
        }
        "Result<Tensor>".to_string()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;

    #[test]
    fn test_sanitize_name() {
        let codegen = Codegen::new(HashMap::new(), None);

        // PyTorch names
        assert_eq!(
            codegen.sanitize_name("encoder.layers.0"),
            "encoder_layers_0"
        );
        assert_eq!(codegen.sanitize_name("node_123"), "x_123");
        assert_eq!(codegen.sanitize_name("123_invalid"), "x_123_invalid");

        // ONNX names
        assert_eq!(codegen.sanitize_name("/layers/0/Gemm_output"), "gemm");
        assert_eq!(codegen.sanitize_name("/node_456"), "x_456");
        assert_eq!(codegen.sanitize_name("/Gather_1_output"), "gather_1");
    }
}
</file>

<file path="crates/pycandle/src/main.rs">
//! PyCandle CLI
//!
//! Command-line interface for PyTorch  Candle porting.

mod dashboard;
mod init;
mod report;
mod test_gen;
mod todos;

use anyhow::{Context, Result};
use clap::{Parser, Subcommand};
use pycandle_core::LayerMeta;
use pycandle_core::codegen::Codegen;
use report::ReportGenerator;
use std::collections::HashMap;
use std::path::PathBuf;
use std::process::Command;

#[derive(Parser)]
#[command(name = "pycandle")]
#[command(about = "A tool for bit-perfect parity checking between PyTorch and Candle", long_about = None)]
struct Cli {
    /// Output in JSON format for agent consumption
    #[arg(long, global = true)]
    json: bool,

    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Record activations from a PyTorch model
    Record {
        /// Path to the Python script that defines and runs the model
        #[arg(short, long)]
        script: PathBuf,

        /// Project name for the trace
        #[arg(short, long)]
        name: String,

        /// Output directory for the trace and manifest
        #[arg(short, long, default_value = "pycandle_trace")]
        out: PathBuf,
    },
    /// Generate Candle code from a manifest
    Codegen {
        /// Path to the manifest JSON file
        #[arg(short, long)]
        manifest: PathBuf,

        /// Output path for the generated Rust file or directory
        #[arg(short, long)]
        out: PathBuf,

        /// Name of the model struct to generate
        #[arg(long, default_value = "MyModel")]
        model: String,

        /// Analyze without generating code
        #[arg(long)]
        analyze_only: bool,

        /// Generate stateful code with KV-caching support
        #[arg(long)]
        stateful: bool,
    },
    /// Extract and manage TODO markers in generated code
    Todos {
        /// Path to generated Rust file or directory
        #[arg(short, long)]
        path: PathBuf,

        /// Just check if TODOs remain (exit code 1 if any)
        #[arg(long)]
        check: bool,
    },
    /// Generate an HTML coverage report
    Report {
        /// Path to the manifest JSON file
        #[arg(short, long)]
        manifest: PathBuf,

        /// Output HTML file path
        #[arg(short, long, default_value = "pycandle_report.html")]
        out: PathBuf,
    },
    Weights {
        #[command(subcommand)]
        action: WeightActions,
    },
    /// Launch the TUI Parity Dashboard
    Dashboard {
        // Optional arguments if we want to pass filter to cargo test
        #[arg(last = true)]
        args: Vec<String>,
    },
    /// Initialize a new project with boilerplate
    Init {
        /// Optional project name
        #[arg(short, long)]
        name: Option<String>,
    },
    /// Generate automated parity test
    GenTest {
        /// Name of the model struct (must match generated code)
        #[arg(long, default_value = "MyModel")]
        model: String,

        /// Path to the manifest JSON file
        #[arg(short, long)]
        manifest: PathBuf,

        /// Output path for the generated test file
        #[arg(short, long, default_value = "tests/parity.rs")]
        out: PathBuf,
    },
    /// Convert ONNX model to PyCandle manifest
    OnnxConvert {
        /// Path to the ONNX model file
        #[arg(short = 'i', long)]
        onnx: PathBuf,

        /// Project name
        #[arg(short, long)]
        name: String,

        /// Output directory for the manifest
        #[arg(short, long, default_value = "pycandle_trace")]
        out: PathBuf,
    },
}

#[derive(Subcommand)]
enum WeightActions {
    /// Surgically extract weights used in a manifest
    Extract {
        /// Path to PyTorch checkpoint (.bin, .pt, .safetensors)
        #[arg(short, long)]
        checkpoint: PathBuf,

        /// Path to the manifest JSON file
        #[arg(short, long)]
        manifest: PathBuf,

        /// Output .safetensors path
        #[arg(short, long)]
        out: PathBuf,

        /// Optional JSON mapping file for renaming
        #[arg(long)]
        map: Option<PathBuf>,
    },
    /// Rename keys in a safetensors file using a mapping
    Map {
        /// Input .safetensors file
        #[arg(short, long)]
        input: PathBuf,

        /// Output .safetensors file
        #[arg(short, long)]
        out: PathBuf,

        /// JSON mapping file
        #[arg(short, long)]
        map: PathBuf,
    },
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Record { script, name, out } => {
            println!(
                " Recording trace for project '{}' using script '{:?}'...",
                name, script
            );

            let status = Command::new("uv")
                .arg("run")
                .arg("python")
                .arg(script)
                .spawn()
                .context("Failed to spawn uv run")?
                .wait()
                .context("Failed to wait for python process")?;

            if status.success() {
                println!(" Recording complete. Files should be in {:?}", out);
            } else {
                eprintln!(" Recording failed.");
            }
        }
        Commands::Codegen {
            manifest: start_path,
            out: out_path,
            model,
            analyze_only,
            stateful,
        } => {
            // Find manifests: if directory, glob *.json, else use file
            let manifest_files = if start_path.is_dir() {
                std::fs::read_dir(&start_path)?
                    .filter_map(|entry| {
                        let path = entry.ok()?.path();
                        if path.extension()?.to_str()? == "json"
                            && path.file_name()?.to_str()?.ends_with("_manifest.json")
                        {
                            Some(path)
                        } else {
                            None
                        }
                    })
                    .collect::<Vec<_>>()
            } else {
                vec![start_path]
            };

            if manifest_files.is_empty() {
                eprintln!(" No manifest files found.");
                return Ok(());
            }

            for manifest_path in manifest_files {
                let manifest_content = std::fs::read_to_string(&manifest_path)
                    .with_context(|| format!("Failed to read manifest at {:?}", manifest_path))?;

                // Full manifest structure including optional graph
                #[derive(serde::Deserialize)]
                struct Manifest {
                    #[serde(flatten)]
                    layers: HashMap<String, serde_json::Value>,
                    #[serde(rename = "_graph_nodes")]
                    graph_nodes: Option<Vec<pycandle_core::codegen::GraphNode>>,
                    #[serde(rename = "_graph_code")]
                    graph_code: Option<String>,
                    #[serde(rename = "_symbolic_hints")]
                    symbolic_hints: Option<HashMap<String, usize>>,
                }

                let full_manifest: Manifest = serde_json::from_str(&manifest_content)
                    .context("Failed to parse manifest JSON")?;

                // Filter out internal keys starting with "_"
                let layers: HashMap<String, LayerMeta> = full_manifest
                    .layers
                    .into_iter()
                    .filter(|(k, _)| !k.starts_with('_'))
                    .map(|(k, v)| {
                        let meta: LayerMeta = serde_json::from_value(v)
                            .with_context(|| format!("Failed to parse LayerMeta for {}", k))?;
                        Ok((k, meta))
                    })
                    .collect::<Result<_>>()?;

                let mut generator =
                    Codegen::new(layers, full_manifest.symbolic_hints).with_stateful(stateful);
                if let Some(nodes) = full_manifest.graph_nodes {
                    generator = generator.with_graph(nodes);
                }

                if analyze_only || cli.json {
                    let analysis = generator.analyze();

                    if cli.json {
                        println!(
                            "{}",
                            serde_json::to_string_pretty(&analysis)
                                .context("Failed to serialize analysis")?
                        );
                    } else {
                        println!(" Analysis of {:?}:", manifest_path);
                        println!(
                            "  Supported: {}/{} ({:.1}%)",
                            analysis.supported, analysis.total, analysis.coverage_percent
                        );
                        println!("  Unsupported: {}", analysis.unsupported);
                        if !analysis.gaps.is_empty() {
                            println!("\n  Gaps:");
                            for gap in &analysis.gaps {
                                println!(
                                    "    - {}: {} occurrence(s)  {}",
                                    gap.module_type, gap.count, gap.suggestion
                                );
                            }
                        }
                    }
                }

                if !analyze_only {
                    // Determine output path
                    let final_out = if out_path.is_dir() {
                        let stem = manifest_path.file_stem().unwrap().to_str().unwrap();
                        let name = stem.replace("_manifest", "");
                        out_path.join(format!("generated_{}.rs", name))
                    } else {
                        // If multiple manifests but one output file, this is ambiguous/wrong unless overwriting.
                        // We'll enforce directory output if input is directory.
                        out_path.clone()
                    };

                    println!(
                        " Generating Candle code from manifest '{:?}'...",
                        manifest_path
                    );

                    // Use model name from CLI args for struct name.
                    // TODO: maybe derive struct name from manifest filename too?
                    let code = generator.generate_model_rs(&model);

                    std::fs::write(&final_out, code).with_context(|| {
                        format!("Failed to write generated code to {:?}", final_out)
                    })?;

                    println!(" Code generated successfully at {:?}", final_out);
                }
            }
        }
        Commands::Todos { path, check } => {
            let files = if path.is_dir() {
                // simple recursion or flat for now? Let's just do one level or walkdir if needed.
                // For now, let's use fs::read_dir and filter .rs
                std::fs::read_dir(&path)?
                    .filter_map(|entry| {
                        let p = entry.ok()?.path();
                        if p.extension()?.to_str()? == "rs" {
                            Some(p)
                        } else {
                            None
                        }
                    })
                    .collect::<Vec<_>>()
            } else {
                vec![path]
            };

            let mut any_todos = false;

            for file_path in files {
                let content = std::fs::read_to_string(&file_path)
                    .with_context(|| format!("Failed to read file at {:?}", file_path))?;

                let todos = todos::extract_todos(&content);
                if !todos.is_empty() {
                    any_todos = true;
                }

                let report = todos::generate_report(file_path.to_str().unwrap_or("unknown"), todos);

                if cli.json {
                    println!(
                        "{}",
                        serde_json::to_string_pretty(&report)
                            .context("Failed to serialize report")?
                    );
                } else {
                    println!(" TODOs in {:?}:", file_path);
                    println!("   Total: {}", report.total);
                    if !report.by_type.is_empty() {
                        println!("\n   By type:");
                        let mut types: Vec<_> = report.by_type.iter().collect();
                        types.sort_by_key(|(_, count)| std::cmp::Reverse(*count));
                        for (t, c) in types {
                            println!("   - {}: {}", t, c);
                        }
                    }
                    if !report.todos.is_empty() {
                        println!("\n   Details:");
                        for todo in &report.todos {
                            println!(
                                "   L{}: {} ({})  {}",
                                todo.line, todo.field_name, todo.module_type, todo.suggestion
                            );
                        }
                    }
                }
            }

            if check && any_todos {
                std::process::exit(1);
            }
        }
        Commands::Report { manifest, out } => {
            let manifest_content = std::fs::read_to_string(&manifest)
                .with_context(|| format!("Failed to read manifest at {:?}", manifest))?;

            let manifest_data: HashMap<String, LayerMeta> =
                serde_json::from_str(&manifest_content).context("Failed to parse manifest JSON")?;

            let generator = ReportGenerator::new(manifest_data);
            let data = generator.analyze();
            let html = generator.generate_html(&data);

            std::fs::write(&out, html)
                .with_context(|| format!("Failed to write report to {:?}", out))?;

            println!(" Report generated: {:?}", out);
        }
        Commands::Weights { action } => match action {
            WeightActions::Extract {
                checkpoint,
                manifest,
                out,
                map,
            } => {
                println!(" Performing surgical weight extraction...");
                let mut cmd = Command::new("uv");
                cmd.arg("run")
                    .arg("python")
                    .arg("py/weight_extractor.py")
                    .arg("--checkpoint")
                    .arg(&checkpoint)
                    .arg("--manifest")
                    .arg(&manifest)
                    .arg("--out")
                    .arg(&out);

                if let Some(m) = map {
                    cmd.arg("--map").arg(m);
                }

                let status = cmd.spawn()?.wait()?;
                if status.success() {
                    println!(" Extraction complete: {:?}", out);
                } else {
                    anyhow::bail!("Weight extraction failed");
                }
            }
            WeightActions::Map { input, out, map } => {
                println!(" Renaming weights using map {:?}...", map);
                let map_content = std::fs::read_to_string(&map)?;
                let mapper = pycandle_core::WeightMapper::from_json(&map_content)?;

                let weights = candle_core::safetensors::load(&input, &candle_core::Device::Cpu)?;
                let mut renamed_weights = HashMap::new();
                for (name, tensor) in weights {
                    renamed_weights.insert(mapper.map_key(&name), tensor);
                }

                candle_core::safetensors::save(&renamed_weights, &out)?;
                println!(" Renaming complete: {:?}", out);
            }
        },
        Commands::Dashboard { args } => {
            dashboard::run_dashboard(&args)?;
        }
        Commands::Init { name } => {
            init::run_init(name)?;
        }
        Commands::GenTest {
            model,
            manifest,
            out,
        } => {
            println!(" Generating test harness for model '{}'...", model);
            let generator = test_gen::TestGenerator::new(model, manifest)?;
            let code = generator.generate_test_file();

            if let Some(parent) = out.parent() {
                std::fs::create_dir_all(parent)
                    .with_context(|| format!("Failed to create directory {:?}", parent))?;
            }

            std::fs::write(&out, code)
                .with_context(|| format!("Failed to write test file to {:?}", out))?;

            println!(" Test generated at {:?}", out);
        }
        Commands::OnnxConvert { onnx, name, out } => {
            println!(
                " Converting ONNX model '{:?}' to PyCandle manifest...",
                onnx
            );

            let status = Command::new("uv")
                .arg("run")
                .arg("--project")
                .arg("py")
                .env("PYTHONPATH", "py")
                .arg("python")
                .arg("py/onnx_to_fx.py")
                .arg("--onnx")
                .arg(&onnx)
                .arg("--name")
                .arg(&name)
                .arg("--out")
                .arg(&out)
                .spawn()
                .context("Failed to spawn uv run")?
                .wait()
                .context("Failed to wait for python process")?;

            if status.success() {
                println!(" Conversion complete. Manifest saved in {:?}", out);
            } else {
                eprintln!(" Conversion failed.");
            }
        }
    }

    Ok(())
}
</file>

<file path="py/spy.py">
import os
import json
import torch
import torch.nn as nn
from safetensors.torch import save_file
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, asdict
from collections import defaultdict

@dataclass
class LayerMeta:
    name: str
    module_type: str
    input_shapes: List[List[int]]
    output_shapes: List[List[int]]
    parameters: List[str]
    is_leaf: bool
    config: Dict[str, Any]

class GoldenRecorder:
    def __init__(self, output_dir: str = "pycandle_trace", keep_dtype: bool = False):
        self.output_dir = output_dir
        self.keep_dtype = keep_dtype
        self.records: Dict[str, torch.Tensor] = {}
        self.manifest: Dict[str, LayerMeta] = {}
        self.call_counts = defaultdict(int)
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

    def _get_module_config(self, module: nn.Module) -> Dict[str, Any]:
        cfg = {}
        if isinstance(module, nn.Linear):
            cfg = {
                "in_features": module.in_features,
                "out_features": module.out_features,
                "bias": module.bias is not None,
                # Record actual weight shape for transpose detection
                "weight_shape": list(module.weight.shape),  # [out, in] in PyTorch
            }
        elif isinstance(module, nn.Conv1d) or type(module).__name__ == "Conv1d":
            cfg = {
                "in_channels": module.in_channels,
                "out_channels": module.out_channels,
                "kernel_size": module.kernel_size[0] if isinstance(module.kernel_size, (list, tuple)) else module.kernel_size,
                "stride": module.stride[0] if isinstance(module.stride, (list, tuple)) else module.stride,
                "padding": module.padding[0] if isinstance(module.padding, (list, tuple)) else module.padding,
                "bias": module.bias is not None
            }
        # HF GPT2 often uses Conv1D
        elif type(module).__name__ == "Conv1D":
            cfg = {
                "in_features": module.weight.shape[0],
                "out_features": module.weight.shape[1],
                "bias": module.bias is not None,
                "weight_shape": list(module.weight.shape)
            }
        elif isinstance(module, nn.LayerNorm):
            cfg = {"normalized_shape": list(module.normalized_shape), "eps": module.eps}
        elif isinstance(module, nn.Embedding):
            cfg = {"num_embeddings": module.num_embeddings, "embedding_dim": module.embedding_dim}
        # Activation functions
        elif isinstance(module, nn.ELU):
            cfg = {"alpha": module.alpha}
        elif isinstance(module, nn.LeakyReLU):
            cfg = {"negative_slope": module.negative_slope}
        elif isinstance(module, nn.BatchNorm1d):
            cfg = {"num_features": module.num_features, "eps": module.eps}
        elif isinstance(module, nn.BatchNorm2d):
            cfg = {"num_features": module.num_features, "eps": module.eps}
        elif isinstance(module, nn.LSTM):
            cfg = {
                "input_size": module.input_size,
                "hidden_size": module.hidden_size,
                "num_layers": module.num_layers,
                "batch_first": module.batch_first,
                "bidirectional": module.bidirectional
            }
        # Snake activation (custom) - check for alpha parameter and in_features
        elif hasattr(module, 'alpha') and isinstance(getattr(module, 'alpha', None), torch.nn.Parameter):
            # Snake: alpha is a learnable parameter, extract in_features from its shape
            alpha = module.alpha
            if alpha.dim() >= 2:
                cfg = {"in_features": alpha.shape[1]}
            elif alpha.dim() == 1:
                cfg = {"in_features": alpha.shape[0]}
        # Custom Transpose
        elif type(module).__name__ == "Transpose":
             cfg = {
                "dim0": getattr(module, "dim0", 1),
                "dim1": getattr(module, "dim1", 2),
            }
        
        # GPT2 from HuggingFace transformers
        if hasattr(module, 'config') and hasattr(module.config, 'n_embd'):
            cfg['vocab_size'] = module.config.vocab_size
            cfg['n_positions'] = module.config.n_positions  # context_length
            cfg['n_embd'] = module.config.n_embd  # emb_dim
            cfg['n_head'] = module.config.n_head  # n_heads
            cfg['n_layer'] = module.config.n_layer  # n_layers
            cfg['resid_pdrop'] = module.config.resid_pdrop  # drop_rate
        
        return cfg

    def _tensor_to_cpu(self, t: Any) -> Optional[torch.Tensor]:
        if isinstance(t, torch.Tensor):
            if t.device.type == 'meta':
                # Return placeholder or None
                return None
            t = t.detach().clone().contiguous().cpu()
            if not self.keep_dtype:
                t = t.float()
            return t
        return None

    def _extract_shapes(self, data: Any) -> List[List[int]]:
        shapes = []
        if isinstance(data, torch.Tensor):
            shapes.append(list(data.shape))
        elif isinstance(data, (tuple, list)):
            for item in data:
                shapes.extend(self._extract_shapes(item))
        return shapes

    def hook_factory(self, name: str):
        def hook(m, inp, out):
            call_idx = self.call_counts[name]
            self.call_counts[name] += 1
            
            trace_key = f"{name}.{call_idx}" if call_idx > 0 else name
            
            # Record Inputs
            if isinstance(inp, tuple):
                for i, x in enumerate(inp):
                    cpu_x = self._tensor_to_cpu(x)
                    if cpu_x is not None:
                        self.records[f"{trace_key}.in.{i}"] = cpu_x
            
            # Record Outputs
            if isinstance(out, torch.Tensor):
                self.records[f"{trace_key}.out.0"] = self._tensor_to_cpu(out)
            elif isinstance(out, (tuple, list)):
                for i, x in enumerate(out):
                    cpu_x = self._tensor_to_cpu(x)
                    if cpu_x is not None:
                        self.records[f"{trace_key}.out.{i}"] = cpu_x

            # Record Metadata
            self.manifest[trace_key] = LayerMeta(
                name=name,
                module_type=type(m).__name__,
                input_shapes=self._extract_shapes(inp),
                output_shapes=self._extract_shapes(out),
                parameters=[n for n, _ in m.named_parameters(recurse=False)],
                is_leaf=len(list(m.children())) == 0,
                config=self._get_module_config(m)
            )
        return hook

    def record(self, model: nn.Module, *args, trace_fx: bool = False, **kwargs):
        model.eval()
        
        # Record model inputs
        for i, arg in enumerate(args):
            cpu_arg = self._tensor_to_cpu(arg)
            if cpu_arg is not None:
                self.records[f"model_input.{i}"] = cpu_arg

        hooks = []
        for name, module in model.named_modules():
            if name == "": continue 
            hooks.append(module.register_forward_hook(self.hook_factory(name)))
        
        try:
            with torch.no_grad():
                output = model(*args, **kwargs)
        finally:
            for h in hooks:
                h.remove()
        
        if trace_fx:
            self.trace_fx(model, *args, **kwargs)
            
        return output

    def trace_fx(self, model: nn.Module, *example_inputs):
        """Use torch.fx to capture the computation graph."""
        import torch.fx as fx
        
        # We use a symbolic trace to capture the graph
        traced = fx.symbolic_trace(model)
        
        def serialize_arg(arg):
            if isinstance(arg, (list, tuple)):
                return [serialize_arg(a) for a in arg]
            if hasattr(arg, "name"):
                return arg.name
            return str(arg)

        graph_nodes = []
        for node in traced.graph.nodes:
            # We want to map these nodes to the modules or functions
            node_info = {
                "name": node.name,
                "op": node.op,
                "target": str(node.target),
                "args": [serialize_arg(arg) for arg in node.args],
            }
            
            if node.op == "call_module":
                try:
                    submod = traced.get_submodule(node.target)
                    node_info["module_type"] = type(submod).__name__
                except:
                    pass
            
            graph_nodes.append(node_info)
            
        self._fx_graph = {
            "graph_nodes": graph_nodes,
            "graph_code": traced.code
        }
        return self._fx_graph

    def save(self, project_name: str, use_fx: bool = False, hints: Optional[Dict[str, int]] = None):
        tensor_path = os.path.join(self.output_dir, f"{project_name}_trace.safetensors")
        # Filter out None values (meta placeholders)
        real_records = {k: v for k, v in self.records.items() if v is not None}
        if real_records:
            save_file(real_records, tensor_path)
        else:
            print(" No real tensors recorded (Meta-only mode)")
        
        manifest_path = os.path.join(self.output_dir, f"{project_name}_manifest.json")
        manifest_data = {k: asdict(v) for k, v in self.manifest.items()}
        
        if use_fx and hasattr(self, '_fx_graph'):
            manifest_data["_graph_nodes"] = self._fx_graph["graph_nodes"]
            manifest_data["_graph_code"] = self._fx_graph["graph_code"]

        if hints:
            manifest_data["_symbolic_hints"] = hints

        with open(manifest_path, "w") as f:
            json.dump(manifest_data, f, indent=4)
        print(f" Trace and Manifest saved for {project_name}")
</file>

<file path="README.md">
# PyCandle

**Automated PyTorch  Candle porting with layer-wise parity verification.**

PyCandle captures activation traces from PyTorch models to generate verified Rust Candle code. Acting as "Chrome DevTools" for neural networks, it provides full transparency into the internal state of complex models, ensuring seamless parity across Python and Rust.

## Quick Start

### 1. Record a PyTorch model

```python
# your_model_script.py
import sys
sys.path.insert(0, "path/to/pycandle/py")

import torch
from spy import GoldenRecorder

# Your PyTorch model
model = MyModel()
model.eval()

# Create dummy input
x = torch.randn(1, 128)

# Record
recorder = GoldenRecorder(output_dir="traces")
recorder.record(model, x)
recorder.save("my_model")
```

### 2. Generate Candle code

```bash
cargo run -p pycandle -- codegen \
    --manifest traces/my_model_manifest.json \
    --out generated_my_model.rs \
    --model MyModel
```

### 3. Use generated code with parity checking

```rust
use pycandle_core::{PyChecker, py_check};

// Load golden records for verification
let checker = PyChecker::load("my_model", "traces/", &device)?;

// Use the generated model
let model = MyModel::load(vb, Some(checker))?;
let output = model.forward(&input)?;  // py_check! runs at each layer
```

## CLI Commands

### `pycandle record`
Run a Python script that uses `GoldenRecorder`.

```bash
pycandle record --script model_script.py --name my_model --out traces/
```

### `pycandle codegen`
Generate Candle Rust code from a manifest.

```bash
pycandle codegen --manifest traces/manifest.json --out generated.rs --model ModelName
```

**Flags:**
- `--analyze-only` - Show analysis without generating code
- `--json` - Output as JSON (works with all commands)

**Analysis mode example:**
```bash
# Human-readable analysis
pycandle codegen --manifest m.json --out NUL --analyze-only

# JSON output for scripting
pycandle codegen --manifest m.json --out NUL --analyze-only --json
```

### `pycandle todos`
Extract and manage TODO markers in generated code.

```bash
# List all TODOs with suggestions
pycandle todos --file generated_model.rs

# JSON output
pycandle todos --file generated_model.rs --json

# Check mode (exit code 1 if TODOs remain)
pycandle todos --file generated_model.rs --check
```

**Agent workflow example:**
```bash
# 1. Generate code
pycandle codegen --manifest m.json --out model.rs --model MyModel

# 2. Check for TODOs
if ! pycandle todos --file model.rs --check; then
    # 3. Get gaps as JSON and implement
    pycandle todos --file model.rs --json | jq '.by_type'
fi
```

## Python Spy API

```python
from spy import GoldenRecorder

recorder = GoldenRecorder(output_dir="traces")
recorder.record(model, *inputs, **kwargs)  # Runs forward pass with hooks
recorder.save("project_name")  # Saves .safetensors + _manifest.json
```

**Output files:**
- `{name}_trace.safetensors` - Activation tensors for each layer
- `{name}_manifest.json` - Module metadata (types, shapes, configs)

### Advanced: Resolving Symbolic Ambiguity (Hints)

If your model has multiple dimensions with the same size (e.g., `hidden_dim=1024` and `context_length=1024`), the symbolic propagator might pick the wrong one. You can resolve this by passing `hints` to `recorder.save()`:

```python
recorder.save("my_model", hints={
    "vocab_size": 50257,
    "hidden_dim": 768,
    "context_length": 1024
})
```

The codegen will prioritize these hints when generating the `Config` struct and mapping layer dimensions.

## Rust Verification API

```rust
use pycandle_core::{PyChecker, py_check};

// Load checker
let checker = PyChecker::load("model_name", "traces/", &device)?;

// Verify a tensor against golden record
let result = checker.verify("layer_name", &tensor)?;
println!("MSE: {}", result.mse);

// Or use the macro (embedded in generated code)
py_check!(checker, "layer_name", &tensor);
```

## Generated Code Structure

```rust
pub struct Config {
    pub vocab_size: usize,
    pub hidden_dim: usize,
}

pub struct MyModel {
    pub linear1: Linear,
    pub linear2: Linear,
    pub checker: Option<PyChecker>,
}

impl MyModel {
    pub fn load(cfg: Config, vb: VarBuilder, checker: Option<PyChecker>) -> Result<Self> {
        let linear1 = candle_nn::linear(cfg.hidden_dim, 256, vb.pp("linear1"))?;
        let linear2 = candle_nn::linear(256, cfg.vocab_size, vb.pp("linear2"))?;
        Ok(Self { linear1, linear2, checker })
    }

    pub fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        let mut x = xs.clone();
        x = self.linear1.forward(&x)?;
        py_check!(self.checker, "linear1", &x);
        x = self.linear2.forward(&x)?;
        py_check!(self.checker, "linear2", &x);
        Ok(x)
    }
}
```

## Supported Module Types

| PyTorch | Candle | Status |
|---------|--------|--------|
| `nn.Linear` | `candle_nn::linear` |  Auto (with smart transpose) |
| `nn.Conv1d` | `candle_nn::conv1d` |  Auto |
| `nn.Embedding` | `candle_nn::embedding` |  Auto |
| `nn.LayerNorm` | `candle_nn::layer_norm` |  Auto |
| `nn.BatchNorm1d` | `BatchNorm1d` |  Auto |
| `nn.BatchNorm2d` | `BatchNorm2d` |  Auto |
| `nn.LSTM` | `LSTM` |  Auto |
| `nn.ReLU/GELU/Sigmoid/Tanh` | Activations |  Auto |
| `nn.ELU/LeakyReLU` | Parameterized activations |  Auto |
| `Snake` (BigVGAN) | `Snake` |  Auto |
| Custom modules | - |  TODO marker |

## Workspace Structure

```
pycandle/
 Cargo.toml              # Workspace root
 crates/
    pycandle/           # CLI binary
       src/main.rs
    pycandle-core/      # Library (PyChecker, layers, codegen)
       src/
           lib.rs
           checker.rs
           layers.rs
           codegen/
    pycandle-audio/     # Audio ops (STFT, padding)
        src/lib.rs
 py/
     spy.py              # GoldenRecorder
```

**Using as a library:**
```toml
[dependencies]
pycandle-core = { git = "https://github.com/user/pycandle" }
# Optional audio support:
pycandle-audio = { git = "https://github.com/user/pycandle" }
```

---

## Roadmap

PyCandle has evolved into a high-fidelity transpilation framework. The following items track the transition from v0.1 to a production-grade v1.0.

###  DAG Resolver (torch.fx Tracing)
**Status:** Complete 

Handle non-sequential models with skip connections and branches:
- Use `torch.fx` to trace computation graphs automatically.
- Generate named variables based on FX graph nodes (e.g., `let x_conv1 = ...`).
- Automatic residual detection and mapping of functional ops (`add`, `cat`, `mul`).
- Mapping of `operator.getitem` to Candle `.i()` for complex slicing logic.

###  Symbolic Shape Propagation
**Status:** Complete 

Generate `Config` structs instead of hardcoded dimensions to decouple model logic from specific input sizes:
- Automatic detection of `vocab_size`, `hidden_dim`, and `context_length`.
- Config-driven initialization in the generated Rust `load` functions.

###  Visual Drift Analysis (Mechanistic Diagnostics)
**Status:** Complete 

Enhanced diagnostics for numerical drift using real-time verification data:
- **D3.js Coverage Report:** Standalone HTML report with MSE/Cosine Similarity charts.
- **Divergence Detection:** Automatic identification of the "Point of Failure" where math starts to drift.
- **TUI Dashboard:** Real-time terminal dashboard with 8x8 error heatmaps for instant visual feedback.

###  Audio-Specific Ops (pycandle-audio)
**Status:** Complete 

Bit-perfect PyTorch parity for audio preprocessing and specialized layers:
- **MelSpectrogram:** Full parity with `torchaudio` (including Slaney-scale area normalization).
- **STFT/iSTFT:** High-precision CPU-based transforms using `realfft`.
- **Specialized Layers:** Native support for `Snake` (BigVGAN), `CausalConv1d`, and `Mish`.

###  Interactive Debugger (Lock-Step)
**Status:** Complete 

Automated post-mortem tools for failed parity checks:
- **Snippet Generation:** Automatically saves `.safetensors` containing the failing Rust tensor and the Golden reference.
- **Python Debug Scripts:** Generates a ready-to-run `.py` script that loads the failure snippet into Matplotlib for visual histogram/heatmap comparison.

###  Surgical Weight Management
**Status:** Complete 

Tools to handle the "Integration Gap" between PyTorch checkpoints and Rust structs:
- **Checkpoint Mapper:** Regex-based renaming engine to map PyTorch keys to Rust fields.
- **Meta-Extractor:** CLI tool to surgically extract only the weights used in a manifest, significantly reducing checkpoint size.

###  Automated Test Generation
**Status:** Complete 

Eliminate manual test writing by generating the full Rust test harness:
- **Auto-Test CLI:** `pycandle gen-test` to generate `tests/parity.rs` automatically.
- **Data-Driven Harness:** The test will automatically load the input/output tensors from the recorded trace and run the verification loop.

###  Symbolic Ambiguity Hints
**Status:** Complete 

Refining the symbolic propagator for complex models:
- **Hint System:** Allow users to provide a `hints.json` to resolve ambiguous dimensions (e.g., when `hidden_dim` and `context_length` are both 1024).
- **Manual Overrides:** Use the Python `recorder.save(..., hints={"vocab_size": 50000})` to guide the codegen when heuristics fail.

###  Multi-Input & Complex Slicing
**Status:** Complete 

- **Multi-Input Support:** Models with multiple placeholders (e.g., TTS models) correctly generate `forward(&self, xs0: &Tensor, xs1: &Tensor, ...)` signatures.
- **Robust Slicing:** Improved handling of complex `torch.fx` slicing nodes, mapping `operator.getitem` to Candle's `.i()` with support for multi-dimensional ranges (e.g., `x.i((.., ..-1))?`).

###  Quantization Parity (GGUF/AWQ)
**Status:** Complete 

Extending the verification engine to quantized models:
- **Quantization Drift Tracking:** Measure MSE drift introduced specifically by `Q4_0`, `Q8_0`, or `AWQ` compared to the `f32` Golden Record.
- **Parity-Aware Quantization:** Identify which specific layers are most sensitive to quantization to help guide mixed-precision strategies.

---

### Summary of the "Powerful" PyCandle Vision:
1.  **Python Spy:** Captures Graph (FX) + Config + Activations + Weights.
2.  **Transpiler:** Converts FX Graph to idiomatic Rust DAG (with residuals).
3.  **Verifiable Crate:** Generated code with `py_check!` macros that "lights up" green as you implement layers.
4.  **Diagnostics:** A visual report and Python debug scripts showing exactly where the "Math Leak" is happening.
---
###  Universal ONNX Transpilation
**Status: Prototype (via `onnx2torch`) **

- **Bridge Strategy:** Automatically converts ONNX models to PyTorch in-memory, then traces them with `torch.fx` to generate idiomatic Rust.
- **CLI Integration:** `pycandle onnx-convert --onnx model.onnx --name my_model` handles the conversion pipeline automatically.
- **Dynamic Shape Inference:** Automatically detects input dimensions from the ONNX graph definition, defaulting dynamic axes to `1`.

### Technical Challenges to Watch For:
1.  **The "Opset" Nightmare:** ONNX has many versions (Opsets). Youll need to focus on the most common ones (Opset 17+).
2.  **Naming Conventions:** ONNX often renames layers to generic IDs (like `node_1`, `node_2`). v1.1 will include a "Sanitizer" pass in `codegen/mod.rs` to keep generated Rust code readable.
3.  **Complex Ops:** Some ONNX ops (like `EinsteinSum` or complex `Loop` nodes) are very hard to map to Candle.

### Should you do it?
**Yes, but as an alternative input.** 
Keep the `torch.fx` path as the "Primary" because it produces the most readable, idiomatic Rust code. Use ONNX as the "Emergency/Universal" path for when the original source code isn't available.

**PyCandle would then be:**
*   **Input:** PyTorch Code OR ONNX File.
*   **Process:** Trace + Analyze + Codegen.
*   **Output:** Verified, Production-Grade Rust.

---

## License

MIT
</file>

</files>
